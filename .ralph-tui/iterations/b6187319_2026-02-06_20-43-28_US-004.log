# Iteration 4 Log

## Metadata

- **Task ID**: US-004
- **Task Title**: Make Retry and Re-send Idempotent
- **Description**: As a user, I want retry operations to avoid duplicates so that failed/retried messages do not create conflicting states.
- **Status**: completed
- **Task Completed**: Yes
- **Promise Detected**: Yes
- **Started At**: 2026-02-07T01:43:28.076Z
- **Ended At**: 2026-02-07T01:52:51.387Z
- **Duration**: 9m 23s
- **Agent**: opencode
- **Sandbox Mode**: auto
- **Sandbox Network**: Enabled
--- RAW OUTPUT ---
{"type":"step_start","timestamp":1770428612301,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c4becc001DsVxKjUuOQRCg3","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4b8b9001k2AwOwUcwEEgp7","type":"step-start","snapshot":"1627c01e9506b019b61567e096c210e4d8a63e73"}}
{"type":"tool_use","timestamp":1770428617044,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c4ca4d001XV6Wq418pmmGzn","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4b8b9001k2AwOwUcwEEgp7","type":"tool","callID":"call_UhHSseFVn8I9tKS5LsOHw7bm","tool":"todowrite","state":{"status":"completed","input":{"todos":[{"id":"t1","content":"Review progress context and existing retry/send flow for idempotency gaps","status":"in_progress","priority":"high"},{"id":"t2","content":"Implement idempotent retry/re-send semantics and inflight protection","status":"pending","priority":"high"},{"id":"t3","content":"Add tests for repeated retries, quick taps, and network flap recovery","status":"pending","priority":"high"},{"id":"t4","content":"Run lint, typecheck, and test suite","status":"pending","priority":"high"},{"id":"t5","content":"Append US-004 update and learnings to .ralph-tui/progress.md","status":"pending","priority":"medium"}]},"output":"[\n  {\n    \"id\": \"t1\",\n    \"content\": \"Review progress context and existing retry/send flow for idempotency gaps\",\n    \"status\": \"in_progress\",\n    \"priority\": \"high\"\n  },\n  {\n    \"id\": \"t2\",\n    \"content\": \"Implement idempotent retry/re-send semantics and inflight protection\",\n    \"status\": \"pending\",\n    \"priority\": \"high\"\n  },\n  {\n    \"id\": \"t3\",\n    \"content\": \"Add tests for repeated retries, quick taps, and network flap recovery\",\n    \"status\": \"pending\",\n    \"priority\": \"high\"\n  },\n  {\n    \"id\": \"t4\",\n    \"content\": \"Run lint, typecheck, and test suite\",\n    \"status\": \"pending\",\n    \"priority\": \"high\"\n  },\n  {\n    \"id\": \"t5\",\n    \"content\": \"Append US-004 update and learnings to .ralph-tui/progress.md\",\n    \"status\": \"pending\",\n    \"priority\": \"medium\"\n  }\n]","title":"5 todos","metadata":{"todos":[{"id":"t1","content":"Review progress context and existing retry/send flow for idempotency gaps","status":"in_progress","priority":"high"},{"id":"t2","content":"Implement idempotent retry/re-send semantics and inflight protection","status":"pending","priority":"high"},{"id":"t3","content":"Add tests for repeated retries, quick taps, and network flap recovery","status":"pending","priority":"high"},{"id":"t4","content":"Run lint, typecheck, and test suite","status":"pending","priority":"high"},{"id":"t5","content":"Append US-004 update and learnings to .ralph-tui/progress.md","status":"pending","priority":"medium"}],"truncated":false},"time":{"start":1770428617038,"end":1770428617042}},"metadata":{"openai":{"itemId":"fc_00a58635ff083dac01698698c726bc8190b51ea964b330a8d5"}}}}
{"type":"step_finish","timestamp":1770428617176,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c4d1ac001pKBUUT1UZMgJLk","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4b8b9001k2AwOwUcwEEgp7","type":"step-finish","reason":"tool-calls","snapshot":"1627c01e9506b019b61567e096c210e4d8a63e73","cost":0,"tokens":{"input":18044,"output":272,"reasoning":105,"cache":{"read":0,"write":0}}}}
{"type":"step_start","timestamp":1770428617855,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c4d47e001D2FC55g3eUMH4B","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4d208001AroK7xhHQwM22M","type":"step-start","snapshot":"1627c01e9506b019b61567e096c210e4d8a63e73"}}
{"type":"tool_use","timestamp":1770428620530,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c4deea001UBTXripp2mCURh","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4d208001AroK7xhHQwM22M","type":"tool","callID":"call_nDJnv3aJY3g1puuDy13HjTC3","tool":"read","state":{"status":"completed","input":{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/.ralph-tui/progress.md"},"output":"<file>\n00001| # Ralph Progress Log\n00002| \n00003| This file tracks progress across iterations. Agents update this file\n00004| after each iteration and it's included in prompts for context.\n00005| \n00006| ## Codebase Patterns (Study These First)\n00007| \n00008| *Add reusable patterns discovered during development here.*\n00009| \n00010| - Concurrency audits should use a stable schema per entry: `Race Class`, `Vulnerable Flow`, `Modules/Files`, `Severity`, `Reproducibility`, and `Owner Subsystem`, plus class-level fixed evidence gates to make remediation traceable.\n00011| - For async workflows, compose a local trio per scope: `createSequenceGuard` to gate commits, `createAbortManager` to cancel superseded work, and `createIdempotencyRegistry` with deterministic keys to dedupe in-flight side effects.\n00012| - For overlapping chat sends, assign a new sequence token per send and require all stream-side callbacks/state commits (chunks, errors, provider switches, completion) to pass a shared `canMutateState` gate built from token freshness + abort/cancel flags.\n00013| \n00014| ---\n00015| \n00016| ## 2026-02-06 - US-001\n00017| - What was implemented\n00018|   - Added a repository-wide concurrency taxonomy and audit baseline covering stale-response overwrite, double-submit, out-of-order stream events, fallback duplication, hydration/write conflicts, and cancellation leaks.\n00019|   - Produced an inventory of vulnerable flows mapped to files across `app/`, `hooks/`, `stores/`, `providers/`, `db/`, and `lib/`, each tagged with severity, reproducibility, and owner subsystem.\n00020|   - Defined fixed evidence requirements per race class for remediation closure.\n00021| - Files changed\n00022|   - `docs/concurrency-taxonomy-audit-baseline.md`\n00023|   - `.ralph-tui/progress.md`\n00024| - **Learnings:**\n00025|   - Patterns discovered\n00026|     - Chat flow already has partial stale-load protection (`loadIdRef`) in route-based loading, but streaming and fallback paths need equivalent generation/idempotency controls.\n00027|     - Persisted Zustand stores and runtime DB synchronization create repeated hydration precedence risks unless authority order is explicit and tested.\n00028|   - Gotchas encountered\n00029|     - Stream lifecycle utilities define robust transitions, but integration gaps can still produce out-of-order completion semantics if chunk/done/completed markers are not consistently emitted.\n00030|     - New-chat persistence relies on runtime guards rather than DB constraints, so duplicate insert races remain plausible under timing pressure.\n00031| ---\n00032| \n00033| ## 2026-02-06 - US-002\n00034| - What was implemented\n00035|   - Added shared concurrency primitives in `lib/concurrency.ts` for sequence guards, abort lifecycle management, abort error detection, deterministic idempotency keys, and in-flight idempotency registries.\n00036|   - Introduced typed contracts in `types/concurrency.types.ts` and exported them via `types/index.ts` for use by hooks/providers/stores.\n00037|   - Added contributor-facing usage rules and an integration recipe in `docs/concurrency-primitives.md`.\n00038|   - Added unit tests covering stale token rejection, out-of-order completion gating, superseded abort behavior, and idempotent in-flight deduplication.\n00039| - Files changed\n00040|   - `lib/concurrency.ts`\n00041|   - `lib/__tests__/concurrency.test.ts`\n00042|   - `types/concurrency.types.ts`\n00043|   - `types/index.ts`\n00044|   - `docs/concurrency-primitives.md`\n00045|   - `.ralph-tui/progress.md`\n00046| - **Learnings:**\n00047|   - Patterns discovered\n00048|     - Sequence guards are most reliable when every async request gets a fresh token at launch and every commit path checks token freshness right before mutation.\n00049|     - Abort managers and idempotency registries should be scoped per workflow (not global) to avoid cross-feature cancellation and dedupe collisions.\n00050|   - Gotchas encountered\n00051|     - Deduplication should only cover in-flight work; keeping completed promises in a registry can suppress legitimate retries.\n00052|     - Abort handling is most maintainable when abort outcomes are normalized (`AbortError`) and filtered from fallback/error UX flows.\n00053| ---\n00054| \n00055| ## 2026-02-06 - US-003\n00056| - What was implemented\n00057|   - Hardened `useChat` send lifecycle ordering by introducing per-send sequence tokens and guarding all async completion paths so stale sends cannot flip stream state or trigger completion callbacks.\n00058|   - Added mutation gating plumbing (`canMutateState`) to `useChatStreaming` so text/reasoning chunks, callbacks, and error-content writes are ignored after cancellation or when a send becomes stale.\n00059|   - Updated cancel behavior to invalidate active sequence tokens and immediately clear streaming/thinking UI state, preventing post-cancel completion races.\n00060|   - Added deterministic concurrency tests covering rapid send overlap ordering, post-cancel stale callback suppression, stale chunk gating, and abort-driven stop/start behavior.\n00061| - Files changed\n00062|   - `hooks/chat/useChat.ts`\n00063|   - `hooks/chat/useChatStreaming.ts`\n00064|   - `hooks/chat/__tests__/useChat.test.ts`\n00065|   - `hooks/chat/__tests__/useChatStreaming.test.ts`\n00066|   - `.ralph-tui/progress.md`\n00067| - **Learnings:**\n00068|   - Patterns discovered\n00069|     - A single `canMutateState` gate shared between orchestrator (`useChat`) and stream worker (`useChatStreaming`) is an effective seam for enforcing ordering without tightly coupling hook internals.\n00070|     - Cancel semantics are safer when cancellation both aborts transport and invalidates sequencing tokens, so late async work self-rejects even if already in flight.\n00071|   - Gotchas encountered\n00072|     - Guarding stale completion paths can accidentally leave `isStreaming` stuck `true` unless cancel explicitly clears UI stream flags.\n00073|     - Mocked streaming tests need deferred promises and captured callback options to deterministically reproduce overlap/cancel races.\n00074| ---\n00075| \n\n(End of file - total 75 lines)\n</file>","title":".ralph-tui/progress.md","metadata":{"preview":"# Ralph Progress Log\n\nThis file tracks progress across iterations. Agents update this file\nafter each iteration and it's included in prompts for context.\n\n## Codebase Patterns (Study These First)\n\n*Add reusable patterns discovered during development here.*\n\n- Concurrency audits should use a stable schema per entry: `Race Class`, `Vulnerable Flow`, `Modules/Files`, `Severity`, `Reproducibility`, and `Owner Subsystem`, plus class-level fixed evidence gates to make remediation traceable.\n- For async workflows, compose a local trio per scope: `createSequenceGuard` to gate commits, `createAbortManager` to cancel superseded work, and `createIdempotencyRegistry` with deterministic keys to dedupe in-flight side effects.\n- For overlapping chat sends, assign a new sequence token per send and require all stream-side callbacks/state commits (chunks, errors, provider switches, completion) to pass a shared `canMutateState` gate built from token freshness + abort/cancel flags.\n\n---\n\n## 2026-02-06 - US-001\n- What was implemented\n  - Added a repository-wide concurrency taxonomy and audit baseline covering stale-response overwrite, double-submit, out-of-order stream events, fallback duplication, hydration/write conflicts, and cancellation leaks.\n  - Produced an inventory of vulnerable flows mapped to files across `app/`, `hooks/`, `stores/`, `providers/`, `db/`, and `lib/`, each tagged with severity, reproducibility, and owner subsystem.\n  - Defined fixed evidence requirements per race class for remediation closure.","truncated":false},"time":{"start":1770428620525,"end":1770428620529}},"metadata":{"openai":{"itemId":"fc_04d8d3b63e7556e801698698cc717c8194b24d0df854a9cedc"}}}}
{"type":"tool_use","timestamp":1770428620557,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c4def0001IkaZLOwbxAJtg8","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4d208001AroK7xhHQwM22M","type":"tool","callID":"call_AV1yTUvfcCiH6E4egISuZZqv","tool":"glob","state":{"status":"completed","input":{"pattern":"**/*useChat*.ts*","path":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2"},"output":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChatStreaming.test.ts\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChatStreaming.ts\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/useChatState.ts\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/__tests__/useChatState.test.ts","title":"","metadata":{"count":6,"truncated":false},"time":{"start":1770428620536,"end":1770428620556}},"metadata":{"openai":{"itemId":"fc_04d8d3b63e7556e801698698cc719481949837aeaf7a8c2a64"}}}}
{"type":"tool_use","timestamp":1770428620566,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c4defe001PQEa05XazrVrT3","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4d208001AroK7xhHQwM22M","type":"tool","callID":"call_TQJTDHj5mw0NhBjmQ8J2wLQG","tool":"grep","state":{"status":"completed","input":{"pattern":"retry|resend|inflight|inFlight|sendMessage|failed","path":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2","include":"*.{ts,tsx}"},"output":"Found 100 matches\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChatStreaming.test.ts:\n  Line 39:   let failedProvidersRef: { current: ProviderId[] };\n  Line 45:     failedProvidersRef = { current: [] };\n  Line 210:       retryConfig: {},\n  Line 230:           failedProvidersRef\n  Line 262:           failedProvidersRef\n  Line 284:           failedProvidersRef\n  Line 321:           failedProvidersRef\n  Line 360:           failedProvidersRef\n  Line 407:           failedProvidersRef\n  Line 432:           failedProvidersRef\n  Line 444:     it('should handle streaming with retry when enabled and retry fails', async () => {\n  Line 459:           message: 'Retry failed',\n  Line 481:           failedProvidersRef\n  Line 487:       expect(failedProvidersRef.current).toContain('openai');\n  Line 492:     it('should handle streaming with retry when no fallback available', async () => {\n  Line 497:       // Mock retry failure that should trigger error handling\n  Line 506:           message: 'Retry failed',\n  Line 524:           failedProvidersRef\n  Line 534:     it('should handle unexpected errors without retry enabled', async () => {\n  Line 562:           failedProvidersRef\n  Line 568:       expect(failedProvidersRef.current).toContain('openai');\n  Line 573:     it('should use custom retry config when provided', async () => {\n  Line 592:             retryConfig: customRetryConfig,\n  Line 597:           failedProvidersRef\n  Line 610:     it('should not modify failed providers when fallback succeeds with new provider', async () => {\n  Line 614:       failedProvidersRef.current = [...initialFailedProviders];\n  Line 643:           failedProvidersRef\n  Line 647:       // Should add the failed provider to the list\n  Line 648:       expect(failedProvidersRef.current).toEqual([...initialFailedProviders, 'openai']);\n  Line 660:           failedProvidersRef\n  Line 698:           failedProvidersRef\n  Line 722:           failedProvidersRef\n  Line 758:           failedProvidersRef\n  Line 776:       // First attempt fails with retry\n  Line 807:             retryConfig: {},\n  Line 817:           failedProvidersRef\n  Line 825:       expect(failedProvidersRef.current).toContain('openai');\n\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:\n  Line 113:         await result.current.sendMessage('');\n  Line 128:         await result.current.sendMessage();\n  Line 145:         await result.current.sendMessage();\n  Line 186:         sendPromise = result.current.sendMessage();\n  Line 211:         await result.current.sendMessage();\n  Line 227:         await result.current.sendMessage();\n  Line 245:         await result.current.sendMessage('Override text');\n  Line 263:         await result.current.sendMessage();\n  Line 354:         await result.current.sendMessage(123 as any);\n  Line 384:         firstSend = result.current.sendMessage('first');\n  Line 388:         secondSend = result.current.sendMessage('second');\n  Line 435:         sendPromise = result.current.sendMessage('cancel-me');\n\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:\n  Line 19:  * • Error handling with automatic retry mechanisms\n  Line 93:     sendMessage: (overrideText?: string) => Promise<void>;\n  Line 110:     /** Retry the last failed message */\n  Line 111:     retryLastMessage: () => Promise<void>;\n  Line 112:     /** Whether retry is available for the last message */\n  Line 156:         enableRetry = true,               // Enable automatic retry\n  Line 157:         retryConfig = {},                 // Custom retry configuration\n  Line 211:     const failedProvidersRef = useRef<ProviderId[]>([]);     // Track failed providers for fallback\n  Line 214:     const lastUserMessageRef = useRef<string | null>(null); // Store last user message for retry\n  Line 215:     const [canRetry, setCanRetry] = useState<boolean>(false); // Whether retry is available\n  Line 229:     // Merge user-provided retry configuration with system defaults to create\n  Line 232:     const mergedRetryConfig: RetryConfig = { ...DEFAULT_RETRY_CONFIG, ...retryConfig };\n  Line 330:             failedProvidersRef.current = [];\n  Line 358:         failedProvidersRef.current = [];         // Clear failed providers list\n  Line 359:         lastUserMessageRef.current = null;       // Clear retry message\n  Line 360:         setCanRetry(false);                      // Disable retry capability\n  Line 382:     // This is the heart of the chat functionality. The sendMessage function:\n  Line 386:     // 4. Handles fallback and retry logic\n  Line 401:     const sendMessage = useCallback(\n  Line 420:             setCanRetry(false);                     // Disable retry until needed\n  Line 421:             lastUserMessageRef.current = content;   // Store for retry capability\n  Line 502:                     attemptedProviders: failedProvidersRef.current,\n  Line 505:                 retryConfig: mergedRetryConfig,\n  Line 552:                 failedProvidersRef\n  Line 567:                 await sendMessage(content);\n  Line 606:     // Retry functionality allows users to resend their last message when the\n  Line 607:     // AI response failed or was incomplete. This involves:\n  Line 608:     // 1. Removing the failed assistant response\n  Line 613:      * Retry the last failed message\n  Line 615:      * This function enables users to retry their last message when the AI\n  Line 616:      * response failed or was cut off. It cleans up the conversation history\n  Line 617:      * and resends the original message with fresh streaming state.\n  Line 619:     const retryLastMessage = useCallback(async () => {\n  Line 620:         // Guard against invalid retry attempts\n  Line 623:         // Remove the failed assistant message from history\n  Line 637:         // Remove the original user message (we'll resend it fresh)\n  Line 651:         // Reset retry state and clear error message\n  Line 654:         await sendMessage(lastUserMessageRef.current);\n  Line 655:     }, [canRetry, sendMessage]);\n  Line 682:         sendMessage,                    // Send message\n  Line 703:         retryLastMessage,               // Retry last message\n  Line 704:         canRetry,                       // Whether retry is available\n  Line 749:  * • Automatic retry with configurable backoff\n\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChatStreaming.ts:\n  Line 3:  * @purpose Streaming text logic with fallback and retry handling\n  Line 15:  * failures through intelligent retry mechanisms and provider fallback chains.\n  Line 27:  * 3. **Automatic Retry**: Implements exponential backoff retry logic for transient\n  Line 28:  *    errors, with configurable retry attempts, delays, and backoff multipliers.\n  Line 53:  * - **useErrorRecovery**: Provides retry logic with exponential backoff\n  Line 59:  * 3. If error occurs → classify error → attempt retry (if enabled)\n  Line 60:  * 4. If retry fails → attempt fallback to next provider\n  Line 82:  *   failedProvidersRef\n\n(Results are truncated. Consider using a more specific path or pattern.)","title":"retry|resend|inflight|inFlight|sendMessage|failed","metadata":{"matches":100,"truncated":true},"time":{"start":1770428620542,"end":1770428620566}},"metadata":{"openai":{"itemId":"fc_04d8d3b63e7556e801698698cc71a481948401a1e696dc0b3f"}}}}
{"type":"step_finish","timestamp":1770428620648,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c4df3b001roQngzFwJSaDmu","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4d208001AroK7xhHQwM22M","type":"step-finish","reason":"tool-calls","snapshot":"1627c01e9506b019b61567e096c210e4d8a63e73","cost":0,"tokens":{"input":508,"output":169,"reasoning":16,"cache":{"read":18048,"write":0}}}}
{"type":"step_start","timestamp":1770428621547,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c4e2ea001Q2EQJKDAXnSqd3","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4df98001KPqKaAkoN0rQHR","type":"step-start","snapshot":"1627c01e9506b019b61567e096c210e4d8a63e73"}}
{"type":"tool_use","timestamp":1770428623669,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c4eb1c001fkPiwzRqKhsdsf","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4df98001KPqKaAkoN0rQHR","type":"tool","callID":"call_qBOfbu6okWaLhPfIbWlXwUIp","tool":"read","state":{"status":"completed","input":{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts"},"output":"<file>\n00001| /**\n00002|  * @file useChat.ts\n00003|  * @purpose Main chat orchestrator with comprehensive state management\n00004|  * @connects-to useChatStreaming, useTitleGeneration, useChatState\n00005|  * \n00006|  * =============================================================================\n00007|  * COMPREHENSIVE HOOK OVERVIEW\n00008|  * =============================================================================\n00009|  * \n00010|  * useChat is the central hook that manages all chat functionality in the seabreeze\n00011|  * application. It orchestrates message handling, streaming responses, provider\n00012|  * management, fallback mechanisms, title generation, and error recovery.\n00013|  * \n00014|  * KEY RESPONSIBILITIES:\n00015|  * ────────────────────────────────────────────────────────────────────────\n00016|  * • Message state management (input text, message history)\n00017|  * • Streaming response handling with real-time updates\n00018|  * • AI provider and model management with fallback support\n00019|  * • Error handling with automatic retry mechanisms\n00020|  * • Chat title generation based on conversation content\n00021|  * • Persistent chat state across app sessions\n00022|  * \n00023|  * ARCHITECTURAL PATTERNS:\n00024|  * ────────────────────────────────────────────────────────────────────────\n00025|  * • Composition over inheritance - combines specialized hooks\n00026|  * • Unidirectional data flow - state flows down, actions flow up\n00027|  * • Immutable state updates - ensures React re-renders correctly\n00028|  * • Referential stability - uses useCallback/useMemo for performance\n00029|  * \n00030|  * PROVIDER ECOSYSTEM:\n00031|  * ────────────────────────────────────────────────────────────────────────\n00032|  * Supports Apple Intelligence, OpenAI, OpenRouter, and Ollama providers with:\n00033|  * • Automatic fallback on failures\n00034|  * • Model caching for performance\n00035|  * • Per-chat provider overrides\n00036|  * • Retry with exponential backoff\n00037|  * \n00038|  * =============================================================================\n00039|  */\n00040| \n00041| import { useCallback, useState, useRef, useEffect, useMemo } from \"react\";\n00042| import type { LanguageModel, ModelMessage } from \"ai\";\n00043| import { ProviderId } from \"@/types/provider.types\";\n00044| import { getProviderModel } from \"@/providers/provider-factory\";\n00045| import { getCachedModel } from \"@/providers/provider-cache\";\n00046| import { type FallbackResult } from \"@/providers/fallback-chain\";\n00047| import { executeWithRetry, DEFAULT_RETRY_CONFIG, type RetryConfig } from \"@/hooks/useErrorRecovery\";\n00048| import { useChatState } from \"@/hooks/useChatState\";\n00049| import { useTitleGeneration } from \"./useTitleGeneration\";\n00050| import { useChatStreaming } from \"./useChatStreaming\";\n00051| import { useStreamLifecycle } from \"./useStreamLifecycle\";\n00052| import type { UseChatOptions, StreamState } from \"@/types/chat.types\";\n00053| import { createSequenceGuard } from \"@/lib/concurrency\";\n00054| \n00055| type ChunkHandler = (chunk: string, accumulated: string) => void;\n00056| \n00057| const DEFAULT_PLACEHOLDER_TEXT = \"...\";\n00058| \n00059| // =============================================================================\n00060| // TYPE DEFINITIONS\n00061| // =============================================================================\n00062| // \n00063| // These types define the public interface of the useChat hook, ensuring type\n00064| // safety for all returned values and callbacks.\n00065| \n00066| /**\n00067|  * Return type for the useChat hook\n00068|  * \n00069|  * This interface defines all the values and functions that the hook exposes to\n00070|  * consuming components. Each property serves a specific purpose in the chat\n00071|  * interaction flow.\n00072|  */\n00073| export interface UseChatReturn {\n00074|     /** Current input text in the chat field */\n00075|     text: string;\n00076|     /** Function to update the input text */\n00077|     setText: (value: string) => void;\n00078|     /** Array of all messages in the conversation */\n00079|     messages: ModelMessage[];\n00080|     /** Function to update the messages array */\n00081|     setMessages: React.Dispatch<React.SetStateAction<ModelMessage[]>>;\n00082|     /** Array of reasoning output aligned with messages */\n00083|     thinkingOutput: string[];\n00084|     /** Function to update the thinking output array */\n00085|     setThinkingOutput: React.Dispatch<React.SetStateAction<string[]>>;\n00086|     /** Whether the AI is currently streaming reasoning text */\n00087|     isThinking: boolean;\n00088|     /** Whether the AI is currently streaming a response */\n00089|     isStreaming: boolean;\n00090|     /** Current stream state for lifecycle tracking */\n00091|     streamState: StreamState;\n00092|     /** Send a message to the AI (optionally override current text) */\n00093|     sendMessage: (overrideText?: string) => Promise<void>;\n00094|     /** Cancel the current streaming response */\n00095|     cancel: () => void;\n00096|     /** Reset all chat state to initial values */\n00097|     reset: () => void;\n00098|     /** Current chat title (generated from conversation) */\n00099|     title: string;\n00100|     /** Function to update the chat title */\n00101|     setTitle: (title: string) => void;\n00102|     /** Generate a new title based on conversation content */\n00103|     generateTitle: () => Promise<string>;\n00104|     /** Currently active AI provider */\n00105|     currentProvider: ProviderId;\n00106|     /** Currently active model within the provider */\n00107|     currentModel: string;\n00108|     /** Whether we're currently using a fallback provider */\n00109|     isUsingFallback: boolean;\n00110|     /** Retry the last failed message */\n00111|     retryLastMessage: () => Promise<void>;\n00112|     /** Whether retry is available for the last message */\n00113|     canRetry: boolean;\n00114|     /** Error message for display when stream fails */\n00115|     errorMessage: string | null;\n00116| }\n00117| \n00118| // =============================================================================\n00119| // MAIN HOOK IMPLEMENTATION\n00120| // =============================================================================\n00121| \n00122| /**\n00123|  * Main useChat hook - orchestrates all chat functionality\n00124|  * \n00125|  * This hook serves as the central hub for chat operations, combining message\n00126|  * management, AI provider handling, streaming responses, and error recovery into\n00127|  * a cohesive interface.\n00128|  * \n00129|  * @param options - Configuration options for the chat instance\n00130|  * @returns Complete chat interface with state and actions\n00131|  */\n00132| export default function useChat(options: UseChatOptions = {}): UseChatReturn {\n00133|     // =============================================================================\n00134|     // OPTIONS DESTRUCTURING AND DEFAULTS\n00135|     // =============================================================================\n00136|     // \n00137|     // Extract all options with sensible defaults. The hook is designed to work\n00138|     // out-of-the-box with minimal configuration while allowing deep customization.\n00139|     \n00140|     const {\n00141|         initialMessages = [],              // Start with empty message history\n00142|         initialText = \"\",                  // Start with empty input field\n00143|         placeholder = true,                // Enable placeholder for AI responses\n00144|         providerId: legacyProviderId,      // Deprecated: use chatId instead\n00145|         modelId: legacyModelId,           // Deprecated: use chatId instead\n00146|         chatId,                           // Modern unified state management\n00147|         model: providedModel,             // Direct model injection (testing)\n00148|         onChunk,                          // Callback for streaming chunks\n00149|         onThinkingChunk,                  // Callback for streaming thinking chunks\n00150|         enableThinking = true,            // Enable thinking output updates\n00151|         thinkingLevel,                    // Control reasoning effort when supported\n00152|         onError,                          // Error handling callback\n00153|         onComplete,                       // Completion callback\n00154|         onFallback,                       // Provider fallback notification\n00155|         enableFallback = true,            // Enable automatic fallback\n00156|         enableRetry = true,               // Enable automatic retry\n00157|         retryConfig = {},                 // Custom retry configuration\n00158|     } = options;\n00159| \n00160|     // =============================================================================\n00161|     // CHAT STATE MANAGEMENT\n00162|     // =============================================================================\n00163|     // \n00164|     // Initialize chat state management. This handles both the new unified approach\n00165|     // (using chatId) and legacy providerId/modelId for backward compatibility.\n00166|     \n00167|     const chatState = useChatState(chatId || null);\n00168|     \n00169|     // Resolve effective provider/model based on whether we're using unified state\n00170|     // or legacy direct provider specification\n00171|     const effectiveProviderId = chatId \n00172|         ? chatState.provider                    // Use unified chat state\n00173|         : (legacyProviderId || \"apple\");       // Fallback to legacy or default\n00174|     const effectiveModelId = chatId \n00175|         ? chatState.model                      // Use unified chat state  \n00176|         : (legacyModelId || \"system-default\"); // Fallback to legacy or default\n00177| \n00178|     // =============================================================================\n00179|     // CORE REACT STATE\n00180|     // =============================================================================\n00181|     // \n00182|     // These are the fundamental React state variables that drive the chat interface.\n00183|     // Each piece of state has a specific responsibility in the chat flow.\n00184|     \n00185|     const [text, setText] = useState<string>(initialText);           // Input field content\n00186|     const [messages, setMessages] = useState<ModelMessage[]>(initialMessages); // Message history\n00187|     const [thinkingOutput, setThinkingOutput] = useState<string[]>(\n00188|         () => initialMessages.map(() => \"\")\n00189|     );\n00190|     const [isThinking, setIsThinking] = useState<boolean>(false);\n00191|     const [isStreaming, setIsStreaming] = useState<boolean>(false);  // Streaming status\n00192|     \n00193|     // =============================================================================\n00194|     // PROVIDER AND FALLBACK STATE\n00195|     // =============================================================================\n00196|     // \n00197|     // These state variables manage the AI provider ecosystem, including fallback\n00198|     // handling and provider switching during failures.\n00199|     \n00200|     const [activeProvider, setActiveProvider] = useState<ProviderId>(effectiveProviderId);\n00201|     const [activeModel, setActiveModel] = useState<string>(effectiveModelId);\n00202|     const [isUsingFallback, setIsUsingFallback] = useState<boolean>(false);\n00203|     \n00204|     // =============================================================================\n00205|     // REFERENCES FOR STABLE OPERATIONS\n00206|     // =============================================================================\n00207|     // \n00208|     // useRef values that persist across re-renders without triggering them.\n00209|     // These are used for tracking operation state and maintaining data integrity.\n00210|     \n00211|     const failedProvidersRef = useRef<ProviderId[]>([]);     // Track failed providers for fallback\n00212|     \n00213|     // Retry and cancellation tracking\n00214|     const lastUserMessageRef = useRef<string | null>(null); // Store last user message for retry\n00215|     const [canRetry, setCanRetry] = useState<boolean>(false); // Whether retry is available\n00216|     const [errorMessage, setErrorMessage] = useState<string | null>(null); // Error message for display\n00217|     const canceledRef = useRef<boolean>(false);             // Track if streaming was canceled\n00218|     const messagesRef = useRef<ModelMessage[]>(initialMessages);\n00219|     const sendSequenceGuardRef = useRef(createSequenceGuard(`chat-send-${chatId ?? \"default\"}`));\n00220| \n00221|     useEffect(() => {\n00222|         messagesRef.current = messages;\n00223|     }, [messages]);\n00224| \n00225|     // =============================================================================\n00226|     // CONFIGURATION MERGING\n00227|     // =============================================================================\n00228|     // \n00229|     // Merge user-provided retry configuration with system defaults to create\n00230|     // the final configuration used throughout the hook.\n00231|     \n00232|     const mergedRetryConfig: RetryConfig = { ...DEFAULT_RETRY_CONFIG, ...retryConfig };\n00233|     const placeholderText = placeholder ? DEFAULT_PLACEHOLDER_TEXT : \"\";\n00234| \n00235|         // =============================================================================\n00236|     // MODEL RESOLUTION AND CACHING\n00237|     // =============================================================================\n00238|     // \n00239|     // Resolve the actual AI model to use for chat operations. This involves:\n00240|     // 1. Using directly provided model (for testing/special cases)\n00241|     // 2. Looking up cached model for performance\n00242|     // 3. Creating new model instance if needed\n00243|     // \n00244|     // The useMemo ensures we only recompute when provider/model actually changes.\n00245|     \n00246|     const model: LanguageModel | null = useMemo(() => {\n00247|         // Direct model injection takes precedence (useful for testing)\n00248|         if (providedModel) {\n00249|             return providedModel as LanguageModel;\n00250|         }\n00251| \n00252|         // Try to get cached model for performance\n00253|         const cachedModel = getCachedModel(\n00254|             activeProvider,\n00255|             activeModel,\n00256|             () => getProviderModel(activeProvider, activeModel).model\n00257|         );\n00258| \n00259|         return cachedModel || null;\n00260|     }, [providedModel, activeProvider, activeModel]);\n00261| \n00262|     // =============================================================================\n00263|     // TITLE GENERATION INTEGRATION\n00264|     // =============================================================================\n00265|     // \n00266|     // Connect to the title generation subsystem. Titles are automatically\n00267|     // generated based on conversation content and used for chat identification\n00268|     // in the UI and database storage.\n00269|     \n00270|     const { title, setTitle, generateTitle } = useTitleGeneration(\n00271|         messages.map(m => ({ role: m.role, content: typeof m.content === 'string' ? m.content : '' })),\n00272|         model,\n00273|         enableRetry,\n00274|         mergedRetryConfig\n00275|     );\n00276| \n00277|     // =============================================================================\n00278|     // STREAMING INFRASTRUCTURE\n00279|     // =============================================================================\n00280|     // \n00281|     // Connect to the streaming subsystem that handles real-time AI responses.\n00282|     // This provides the core functionality for streaming text from AI providers.\n00283|     \n00284|     const { executeStreaming, handleStreamingError } = useChatStreaming();\n00285| \n00286|     // =============================================================================\n00287|     // STREAM LIFECYCLE MANAGEMENT\n00288|     // =============================================================================\n00289|     // \n00290|     // Manages stream state transitions, timeout detection, and cleanup.\n00291|     // Ensures streams always complete fully and handles edge cases like\n00292|     // app backgrounding and navigation away.\n00293|     \n00294|     const {\n00295|         streamState,\n00296|         isStreaming: isStreamLifecycleStreaming,\n00297|         abortController,\n00298|         initializeStream,\n00299|         markChunkReceived,\n00300|         markDoneSignalReceived,\n00301|         markCompleting,\n00302|         markCompleted,\n00303|         markError,\n00304|         cancelStream,\n00305|     } = useStreamLifecycle({\n00306|         timeoutMs: 30000, // 30 second fallback timeout\n00307|         backgroundBehavior: \"cancel\",\n00308|         enableLogging: __DEV__,\n00309|         onError: (error) => {\n00310|             console.error(\"[StreamLifecycle] Error:\", error.message);\n00311|             onError?.(error);\n00312|         },\n00313|     });\n00314| \n00315|         // =============================================================================\n00316|     // PROVIDER RESET EFFECT\n00317|     // =============================================================================\n00318|     // \n00319|     // This effect ensures that when streaming completes (either successfully or\n00320|     // with failure), we reset the provider state to the originally intended\n00321|     // provider/model. This prevents fallback state from persisting between\n00322|     // messages.\n00323|     \n00324|     useEffect(() => {\n00325|         // Only reset when not actively streaming to avoid race conditions\n00326|         if (!isStreaming) {\n00327|             setActiveProvider(effectiveProviderId);\n00328|             setActiveModel(effectiveModelId);\n00329|             setIsUsingFallback(false);\n00330|             failedProvidersRef.current = [];\n00331|         }\n00332|     }, [effectiveProviderId, effectiveModelId, isStreaming]);\n00333| \n00334|     // =============================================================================\n00335|     // UTILITY FUNCTIONS\n00336|     // =============================================================================\n00337|     // \n00338|     // Core utility functions that control chat state and flow. These are\n00339|     // memoized with useCallback to maintain referential stability and prevent\n00340|     // unnecessary re-renders in child components.\n00341| \n00342|     /**\n00343|      * Reset all chat state to initial values\n00344|      * \n00345|      * This function completely clears the chat history, resets the input field,\n00346|      * restores the original title, and resets all provider and fallback state.\n00347|      * It's typically used when starting a new chat conversation.\n00348|      */\n00349|     const reset = useCallback(() => {\n00350|         setText(\"\");                              // Clear input field\n00351|         setMessages([]);                          // Clear message history\n00352|         setThinkingOutput([]);                    // Clear reasoning output\n00353|         setIsThinking(false);                     // Clear thinking state\n00354|         setTitle(\"Chat\");                         // Reset to default title\n00355|         setActiveProvider(effectiveProviderId);   // Reset to intended provider\n00356|         setActiveModel(effectiveModelId);        // Reset to intended model\n00357|         setIsUsingFallback(false);                // Clear fallback state\n00358|         failedProvidersRef.current = [];         // Clear failed providers list\n00359|         lastUserMessageRef.current = null;       // Clear retry message\n00360|         setCanRetry(false);                      // Disable retry capability\n00361|         setErrorMessage(null);                   // Clear error message\n00362|     }, [effectiveProviderId, effectiveModelId, setTitle]);\n00363| \n00364|     /**\n00365|      * Cancel the current streaming operation\n00366|      *\n00367|      * Sets a flag that the streaming loop checks to determine if it should\n00368|      * stop processing chunks. This provides a clean way to interrupt AI responses.\n00369|      */\n00370|     const cancel = useCallback(() => {\n00371|         canceledRef.current = true;\n00372|         sendSequenceGuardRef.current.next();\n00373|         setIsStreaming(false);\n00374|         setIsThinking(false);\n00375|         cancelStream(); // Use stream lifecycle cancel for comprehensive cancellation\n00376|     }, [cancelStream]);\n00377| \n00378|         // =============================================================================\n00379|     // CORE MESSAGE SENDING LOGIC\n00380|     // =============================================================================\n00381|     // \n00382|     // This is the heart of the chat functionality. The sendMessage function:\n00383|     // 1. Validates and prepares the user message\n00384|     // 2. Updates the message history\n00385|     // 3. Initiates streaming with the AI provider\n00386|     // 4. Handles fallback and retry logic\n00387|     // 5. Manages the complete message flow lifecycle\n00388| \n00389|     /**\n00390|      * Send a message to the AI and initiate streaming response\n00391|      * \n00392|      * @param overrideText - Optional text to send instead of current input\n00393|      * \n00394|      * This function orchestrates the complete message sending flow:\n00395|      * 1. Input validation and preprocessing\n00396|      * 2. Message history updates\n00397|      * 3. AI provider streaming initiation\n00398|      * 4. Error handling with fallback mechanisms\n00399|      * 5. Completion callbacks\n00400|      */\n00401|     const sendMessage = useCallback(\n00402|         async (overrideText?: string) => {\n00403|             // ────────────────────────────────────────────────────────────────\n00404|             // INPUT VALIDATION AND PREPARATION\n00405|             // ────────────────────────────────────────────────────────────────\n00406|             const rawValue: unknown = overrideText ?? (text as unknown);\n00407|             const content = typeof rawValue === \"string\" ? rawValue.trim() : \"\";\n00408|             \n00409|             // Exit early if no valid content to send\n00410|             if (!content) return;\n00411| \n00412|             const sendToken = sendSequenceGuardRef.current.next();\n00413| \n00414|             // ────────────────────────────────────────────────────────────────\n00415|             // STATE INITIALIZATION\n00416|             // ────────────────────────────────────────────────────────────────\n00417|             setIsStreaming(true);                    // Start streaming state\n00418|             setIsThinking(false);                    // Reset thinking state\n00419|             canceledRef.current = false;            // Clear cancellation flag\n00420|             setCanRetry(false);                     // Disable retry until needed\n00421|             lastUserMessageRef.current = content;   // Store for retry capability\n00422|             \n00423|             // Initialize stream lifecycle management\n00424|             const streamController = initializeStream();\n00425|             const abortSignal = streamController.signal;\n00426|             const canMutateForCurrentSend = (): boolean => (\n00427|                 sendSequenceGuardRef.current.isCurrent(sendToken)\n00428|                 && !canceledRef.current\n00429|                 && !abortSignal.aborted\n00430|             );\n00431| \n00432|             // ────────────────────────────────────────────────────────────────\n00433|             // MESSAGE HISTORY MANAGEMENT\n00434|             // ────────────────────────────────────────────────────────────────\n00435|             const userMessage: ModelMessage = { role: \"user\", content };\n00436|             const updatedMessages = [...messagesRef.current, userMessage];\n00437|             setMessages(updatedMessages);\n00438|             setThinkingOutput((prev) => [...prev, \"\"]);\n00439| \n00440|             // Clear input field if we're using the current text (not override)\n00441|             if (overrideText === undefined) {\n00442|                 setText(\"\");\n00443|             }\n00444| \n00445|             // Add placeholder for assistant response\n00446|             const assistantIndex = updatedMessages.length;\n00447|             setMessages((prev) => [\n00448|                 ...prev,\n00449|                 {\n00450|                     role: \"assistant\",\n00451|                     content: placeholderText,\n00452|                 },\n00453|             ]);\n00454|             setThinkingOutput((prev) => [...prev, \"\"]);\n00455| \n00456|             // ────────────────────────────────────────────────────────────────\n00457|             // MODEL VALIDATION\n00458|             // ────────────────────────────────────────────────────────────────\n00459|             if (!model) {\n00460|                 // Show helpful error message when no provider is configured\n00461|                 setMessages((prev) => {\n00462|                     const next = [...prev];\n00463|                     next[assistantIndex] = {\n00464|                         role: \"assistant\",\n00465|                         content: \"**Setup Required**\\n\\nNo AI provider configured. Please set up a provider in settings.\\n\\n*Go to Settings to configure an AI provider.*\",\n00466|                     };\n00467|                     return next;\n00468|                 });\n00469|                 \n00470|                 onError?.(new Error(\"No AI provider configured\"));\n00471|                 setIsStreaming(false);\n00472|                 setIsThinking(false);\n00473|                 onComplete?.();\n00474|                 return;\n00475|             }\n00476| \n00477|             // ────────────────────────────────────────────────────────────────\n00478|             // STREAMING CONFIGURATION\n00479|             // ────────────────────────────────────────────────────────────────\n00480|             const handleThinkingChunk = enableThinking\n00481|                 ? (chunk: string, accumulated: string) => {\n00482|                     if (!canMutateForCurrentSend()) {\n00483|                         return;\n00484|                     }\n00485| \n00486|                     setIsThinking(true);\n00487|                     setThinkingOutput((prev) => {\n00488|                         const next = [...prev];\n00489|                         next[assistantIndex] = accumulated;\n00490|                         return next;\n00491|                     });\n00492|                     onThinkingChunk?.(chunk, accumulated);\n00493|                 }\n00494|                 : undefined;\n00495| \n00496|             const streamingOptions = {\n00497|                 model: {\n00498|                     model,\n00499|                     provider: activeProvider,\n00500|                     modelId: activeModel,\n00501|                     isOriginal: !isUsingFallback,\n00502|                     attemptedProviders: failedProvidersRef.current,\n00503|                 } as FallbackResult,\n00504|                 enableRetry,\n00505|                 retryConfig: mergedRetryConfig,\n00506|                 enableFallback,\n00507|                 activeProvider,\n00508|                 effectiveProviderId,\n00509|                 thinkingLevel,\n00510|                 abortSignal,\n00511|                 onChunk,\n00512|                 onThinkingChunk: handleThinkingChunk,\n00513|                 canMutateState: canMutateForCurrentSend,\n00514|                 onError: (error: unknown) => {\n00515|                     if (!canMutateForCurrentSend()) {\n00516|                         return;\n00517|                     }\n00518| \n00519|                     if (error instanceof Error) {\n00520|                         markError(error);\n00521|                         setErrorMessage(error.message);\n00522|                         setCanRetry(true);\n00523|                         onError?.(error);\n00524|                     } else {\n00525|                         const wrappedError = new Error(String(error));\n00526|                         markError(wrappedError);\n00527|                         setErrorMessage(wrappedError.message);\n00528|                         setCanRetry(true);\n00529|                         onError?.(wrappedError);\n00530|                     }\n00531|                 },\n00532|                 onFallback,\n00533|                 onProviderChange: (provider: ProviderId, model: string, isFallback: boolean) => {\n00534|                     if (!canMutateForCurrentSend()) {\n00535|                         return;\n00536|                     }\n00537| \n00538|                     setActiveProvider(provider);\n00539|                     setActiveModel(model);\n00540|                     setIsUsingFallback(isFallback);\n00541|                 },\n00542|             };\n00543| \n00544|             // ────────────────────────────────────────────────────────────────\n00545|             // STREAMING EXECUTION\n00546|             // ────────────────────────────────────────────────────────────────\n00547|             const result = await executeStreaming(\n00548|                 streamingOptions,\n00549|                 updatedMessages,\n00550|                 setMessages,\n00551|                 assistantIndex,\n00552|                 failedProvidersRef\n00553|             );\n00554| \n00555|             if (!sendSequenceGuardRef.current.isCurrent(sendToken)) {\n00556|                 return;\n00557|             }\n00558| \n00559|             // ────────────────────────────────────────────────────────────────\n00560|             // FALLBACK RETRY LOGIC\n00561|             // ────────────────────────────────────────────────────────────────\n00562|             if (result.shouldRetryWithFallback && !canceledRef.current) {\n00563|                 setIsStreaming(false);\n00564|                 setIsThinking(false);\n00565|                 // Small delay to ensure clean state transition\n00566|                 await new Promise(resolve => setTimeout(resolve, 100));\n00567|                 await sendMessage(content);\n00568|                 return;\n00569|             }\n00570| \n00571|             // ────────────────────────────────────────────────────────────────\n00572|             // COMPLETION\n00573|             // ────────────────────────────────────────────────────────────────\n00574|             if (canMutateForCurrentSend()) {\n00575|                 setIsStreaming(false);\n00576|                 setIsThinking(false);\n00577|                 onComplete?.();\n00578|             }\n00579|         },\n00580|         [\n00581|             text, \n00582|             placeholderText, \n00583|             model, \n00584|             activeProvider, \n00585|             activeModel, \n00586|             isUsingFallback,\n00587|             enableRetry, \n00588|             mergedRetryConfig,\n00589|             executeStreaming,\n00590|             onChunk, \n00591|             onThinkingChunk,\n00592|             onComplete, \n00593|             onError, \n00594|             onFallback,\n00595|             effectiveProviderId,\n00596|             enableThinking,\n00597|             thinkingLevel,\n00598|             onThinkingChunk\n00599|         ],\n00600|     );\n00601| \n00602|         // =============================================================================\n00603|     // RETRY FUNCTIONALITY\n00604|     // =============================================================================\n00605|     // \n00606|     // Retry functionality allows users to resend their last message when the\n00607|     // AI response failed or was incomplete. This involves:\n00608|     // 1. Removing the failed assistant response\n00609|     // 2. Optionally removing the user message (if they want to edit)\n00610|     // 3. Resending the original message with fresh state\n00611| \n00612|     /**\n00613|      * Retry the last failed message\n00614|      * \n00615|      * This function enables users to retry their last message when the AI\n00616|      * response failed or was cut off. It cleans up the conversation history\n00617|      * and resends the original message with fresh streaming state.\n00618|      */\n00619|     const retryLastMessage = useCallback(async () => {\n00620|         // Guard against invalid retry attempts\n00621|         if (!lastUserMessageRef.current || !canRetry) return;\n00622|         \n00623|         // Remove the failed assistant message from history\n00624|         setMessages((prev) => {\n00625|             if (prev.length >= 2 && prev[prev.length - 1].role === \"assistant\") {\n00626|                 return prev.slice(0, -1);\n00627|             }\n00628|             return prev;\n00629|         });\n00630|         setThinkingOutput((prev) => {\n00631|             if (prev.length >= 1) {\n00632|                 return prev.slice(0, -1);\n00633|             }\n00634|             return prev;\n00635|         });\n00636| \n00637|         // Remove the original user message (we'll resend it fresh)\n00638|         setMessages((prev) => {\n00639|             if (prev.length >= 1 && prev[prev.length - 1].role === \"user\") {\n00640|                 return prev.slice(0, -1);\n00641|             }\n00642|             return prev;\n00643|         });\n00644|         setThinkingOutput((prev) => {\n00645|             if (prev.length >= 1) {\n00646|                 return prev.slice(0, -1);\n00647|             }\n00648|             return prev;\n00649|         });\n00650| \n00651|         // Reset retry state and clear error message\n00652|         setCanRetry(false);\n00653|         setErrorMessage(null);\n00654|         await sendMessage(lastUserMessageRef.current);\n00655|     }, [canRetry, sendMessage]);\n00656| \n00657|     // =============================================================================\n00658|     // PUBLIC INTERFACE\n00659|     // =============================================================================\n00660|     // \n00661|     // Return the complete chat interface. All values are stable references\n00662|     // where appropriate to prevent unnecessary re-renders in consuming components.\n00663|     // The interface provides both state accessors and action functions.\n00664| \n00665|     return {\n00666|         // ────────────────────────────────────────────────────────────────\n00667|         // CORE CHAT STATE\n00668|         // ────────────────────────────────────────────────────────────────\n00669|         text,                           // Current input text\n00670|         setText,                        // Update input text\n00671|         messages,                       // Message history\n00672|         setMessages,                    // Update message history\n00673|         thinkingOutput,                 // Reasoning output\n00674|         setThinkingOutput,              // Update reasoning output\n00675|         isThinking,                     // Thinking status\n00676|         isStreaming,                    // Streaming status\n00677|         streamState,                    // Stream lifecycle state (streaming | completing | completed | error)\n00678| \n00679|         // ────────────────────────────────────────────────────────────────\n00680|         // ACTIONS\n00681|         // ────────────────────────────────────────────────────────────────\n00682|         sendMessage,                    // Send message\n00683|         cancel,                         // Cancel streaming\n00684|         reset,                          // Reset all state\n00685| \n00686|         // ────────────────────────────────────────────────────────────────\n00687|         // TITLE MANAGEMENT\n00688|         // ────────────────────────────────────────────────────────────────\n00689|         title,                          // Current title\n00690|         setTitle,                       // Update title\n00691|         generateTitle,                  // Generate new title\n00692| \n00693|         // ────────────────────────────────────────────────────────────────\n00694|         // PROVIDER STATE\n00695|         // ────────────────────────────────────────────────────────────────\n00696|         currentProvider: activeProvider, // Active AI provider\n00697|         currentModel: activeModel,      // Active model\n00698|         isUsingFallback,                // Fallback status\n00699| \n00700|         // ────────────────────────────────────────────────────────────────\n00701|         // RETRY FUNCTIONALITY\n00702|         // ────────────────────────────────────────────────────────────────\n00703|         retryLastMessage,               // Retry last message\n00704|         canRetry,                       // Whether retry is available\n00705|         errorMessage,                   // Error message for display\n00706|     };\n00707| }\n00708| \n00709| /*\n00710|  * =============================================================================\n00711|  * HOOK COMPREHENSIVE DOCUMENTATION\n00712|  * =============================================================================\n00713|  * \n00714|  * ARCHITECTURAL SUMMARY:\n00715|  * ────────────────────────────────────────────────────────────────────────\n00716|  * useChat is a sophisticated hook that combines multiple concerns into a\n00717|  * cohesive chat interface. It follows the composition pattern, building upon\n00718|  * specialized hooks for different aspects of chat functionality.\n00719|  * \n00720|  * KEY PRINCIPLES:\n00721|  * ────────────────────────────────────────────────────────────────────────\n00722|  * 1. Separation of Concerns: Different aspects (streaming, title generation,\n00723|  *    state management) are handled by dedicated hooks\n00724|  * 2. Referential Stability: useCallback and useMemo prevent unnecessary re-renders\n00725|  * 3. Unidirectional Data Flow: State flows down, actions flow up\n00726|  * 4. Error Resilience: Multiple layers of error handling and fallback\n00727|  * 5. Performance Optimization: Caching, memoization, and efficient updates\n00728|  * \n00729|  * PROVIDER ECOSYSTEM INTEGRATION:\n00730|  * ────────────────────────────────────────────────────────────────────────\n00731|  * The hook integrates with a robust provider system that supports:\n00732|  * • Multiple AI providers (Apple, OpenAI, OpenRouter, Ollama)\n00733|  * • Automatic fallback on failures\n00734|  * • Model caching for performance\n00735|  * • Per-chat provider overrides\n00736|  * • Retry with exponential backoff\n00737|  * \n00738|  * STATE MANAGEMENT STRATEGY:\n00739|  * ────────────────────────────────────────────────────────────────────────\n00740|  * • Local React state for immediate UI updates\n00741|  * • Zustand stores for persistent data\n00742|  * • Refs for operation tracking without re-renders\n00743|  * • Unified chat state system for consistency\n00744|  * \n00745|  * ERROR HANDLING APPROACH:\n00746|  * ────────────────────────────────────────────────────────────────────────\n00747|  * • Graceful degradation when providers fail\n00748|  * • User-friendly error messages\n00749|  * • Automatic retry with configurable backoff\n00750|  * • Fallback chain through multiple providers\n00751|  * • Recovery mechanisms for common failure scenarios\n00752|  * \n00753|  * PERFORMANCE OPTIMIZATIONS:\n00754|  * ────────────────────────────────────────────────────────────────────────\n00755|  * • Model caching to avoid repeated initialization\n00756|  * • Memoized callbacks to prevent child re-renders\n00757|  * • Efficient state updates with minimal re-renders\n00758|  * • Lazy loading of provider resources\n00759|  * • Streaming to provide immediate feedback\n00760|  * \n00761|  * =============================================================================\n00762|  */\n00763| \n\n(End of file - total 763 lines)\n</file>","title":"hooks/chat/useChat.ts","metadata":{"preview":"/**\n * @file useChat.ts\n * @purpose Main chat orchestrator with comprehensive state management\n * @connects-to useChatStreaming, useTitleGeneration, useChatState\n * \n * =============================================================================\n * COMPREHENSIVE HOOK OVERVIEW\n * =============================================================================\n * \n * useChat is the central hook that manages all chat functionality in the seabreeze\n * application. It orchestrates message handling, streaming responses, provider\n * management, fallback mechanisms, title generation, and error recovery.\n * \n * KEY RESPONSIBILITIES:\n * ────────────────────────────────────────────────────────────────────────\n * • Message state management (input text, message history)\n * • Streaming response handling with real-time updates\n * • AI provider and model management with fallback support\n * • Error handling with automatic retry mechanisms\n * • Chat title generation based on conversation content","truncated":false},"time":{"start":1770428623662,"end":1770428623668}},"metadata":{"openai":{"itemId":"fc_06bdbe3071b4c33a01698698cf9b288190ba03a71b172a9cbc"}}}}
{"type":"tool_use","timestamp":1770428623699,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c4eb4c001Jj33xUOYgD21NX","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4df98001KPqKaAkoN0rQHR","type":"tool","callID":"call_yjsS2UjI3mko81vqceeUtaCY","tool":"read","state":{"status":"completed","input":{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts"},"output":"<file>\n00001| import { describe, it, expect, beforeEach, jest } from '@jest/globals';\n00002| import { renderHook, act } from '@testing-library/react-native';\n00003| import useChat from '../useChat';\n00004| \n00005| const mockExecuteStreaming = jest.fn();\n00006| \n00007| interface Deferred<T> {\n00008|   promise: Promise<T>;\n00009|   resolve: (value: T) => void;\n00010| }\n00011| \n00012| const createDeferred = <T,>(): Deferred<T> => {\n00013|   let resolve!: (value: T) => void;\n00014|   const promise = new Promise<T>((innerResolve) => {\n00015|     resolve = innerResolve;\n00016|   });\n00017| \n00018|   return { promise, resolve };\n00019| };\n00020| \n00021| // Mock all dependencies with simpler mocks\n00022| jest.mock('@/hooks/useChatState', () => ({\n00023|   useChatState: jest.fn(() => ({\n00024|     provider: 'apple',\n00025|     model: 'gpt-4',\n00026|     isOverridden: false,\n00027|     globalProvider: 'apple',\n00028|     globalModel: 'gpt-4',\n00029|     setOverride: jest.fn(),\n00030|     clearOverride: jest.fn(),\n00031|     syncFromDatabase: jest.fn(),\n00032|     hasOverride: false,\n00033|   })),\n00034| }));\n00035| \n00036| jest.mock('../useTitleGeneration', () => {\n00037|   const mockTitleState = {\n00038|     title: 'Test Chat',\n00039|     setTitle: jest.fn(),\n00040|     generateTitle: jest.fn(async () => 'Generated Title'),\n00041|     resetTitle: jest.fn(),\n00042|   };\n00043| \n00044|   return {\n00045|     useTitleGeneration: jest.fn(() => mockTitleState),\n00046|   };\n00047| });\n00048| \n00049| jest.mock('../useChatStreaming', () => ({\n00050|   useChatStreaming: jest.fn(() => ({\n00051|     executeStreaming: (...args: any[]) => mockExecuteStreaming(...args),\n00052|     handleStreamingError: jest.fn(),\n00053|   })),\n00054| }));\n00055| \n00056| jest.mock('@/providers/provider-cache', () => ({\n00057|   getCachedModel: jest.fn(() => ({\n00058|     provider: 'openai',\n00059|     modelId: 'gpt-4',\n00060|   })),\n00061| }));\n00062| \n00063| describe('useChat', () => {\n00064|   beforeEach(() => {\n00065|     jest.clearAllMocks();\n00066|     mockExecuteStreaming.mockImplementation(async (options: any) => {\n00067|       const onThinkingChunk = options?.onThinkingChunk as ((chunk: string, accumulated: string) => void) | undefined;\n00068|       onThinkingChunk?.('Thinking', 'Thinking');\n00069|       return {\n00070|         success: true,\n00071|         shouldRetryWithFallback: false,\n00072|         accumulated: 'Test response',\n00073|       };\n00074|     });\n00075|   });\n00076| \n00077|   describe('basic functionality', () => {\n00078|     it('should initialize with default values', () => {\n00079|       const { result } = renderHook(() => useChat({}));\n00080| \n00081|       expect(result.current.text).toBe('');\n00082|       expect(result.current.messages).toEqual([]);\n00083|       expect(result.current.thinkingOutput).toEqual([]);\n00084|       expect(result.current.isThinking).toBe(false);\n00085|       expect(result.current.isStreaming).toBe(false);\n00086|       expect(result.current.title).toBe('Test Chat');\n00087|       expect(result.current.currentProvider).toBe('apple');\n00088|       expect(result.current.currentModel).toBe('system-default'); // Default when no chatId\n00089|       expect(result.current.isUsingFallback).toBe(false);\n00090|       expect(result.current.canRetry).toBe(false);\n00091|     });\n00092| \n00093|     it('should initialize with provided initial text', () => {\n00094|       const { result } = renderHook(() => useChat({ initialText: 'Hello' }));\n00095| \n00096|       expect(result.current.text).toBe('Hello');\n00097|     });\n00098| \n00099|     it('should update text when setText is called', () => {\n00100|       const { result } = renderHook(() => useChat({}));\n00101| \n00102|       act(() => {\n00103|         result.current.setText('New text');\n00104|       });\n00105| \n00106|       expect(result.current.text).toBe('New text');\n00107|     });\n00108| \n00109|     it('should not send empty message', async () => {\n00110|       const { result } = renderHook(() => useChat({}));\n00111| \n00112|       await act(async () => {\n00113|         await result.current.sendMessage('');\n00114|       });\n00115| \n00116|       expect(result.current.messages).toEqual([]);\n00117|       expect(result.current.isStreaming).toBe(false);\n00118|     });\n00119| \n00120|     it('should not send whitespace-only message', async () => {\n00121|       const { result } = renderHook(() => useChat({}));\n00122| \n00123|       act(() => {\n00124|         result.current.setText('   \\n\\t  ');\n00125|       });\n00126| \n00127|       await act(async () => {\n00128|         await result.current.sendMessage();\n00129|       });\n00130| \n00131|       expect(result.current.messages).toEqual([]);\n00132|       expect(result.current.isStreaming).toBe(false);\n00133|     });\n00134|   });\n00135| \n00136|   describe('message sending', () => {\n00137|     it('should send message and add to history', async () => {\n00138|       const { result } = renderHook(() => useChat({}));\n00139| \n00140|       act(() => {\n00141|         result.current.setText('Hello, world!');\n00142|       });\n00143| \n00144|       await act(async () => {\n00145|         await result.current.sendMessage();\n00146|       });\n00147| \n00148|       expect(result.current.messages).toHaveLength(2);\n00149|       expect(result.current.messages[0]).toEqual({\n00150|         role: 'user',\n00151|         content: 'Hello, world!',\n00152|       });\n00153|       expect(result.current.messages[1]).toEqual({\n00154|         role: 'assistant',\n00155|         content: '...',\n00156|       });\n00157|       expect(result.current.thinkingOutput).toEqual(['', 'Thinking']);\n00158|       expect(result.current.text).toBe('');\n00159|       expect(result.current.isThinking).toBe(false);\n00160|       expect(result.current.isStreaming).toBe(false); // Streaming completes after act\n00161|     });\n00162| \n00163|     it('should set isThinking while reasoning streams', async () => {\n00164|       let resolveStreaming: (() => void) | null = null;\n00165|       mockExecuteStreaming.mockImplementation(async (options: any) => {\n00166|         const onThinkingChunk = options?.onThinkingChunk as ((chunk: string, accumulated: string) => void) | undefined;\n00167|         onThinkingChunk?.('Thinking', 'Thinking');\n00168|         await new Promise<void>((resolve) => {\n00169|           resolveStreaming = resolve;\n00170|         });\n00171|         return {\n00172|           success: true,\n00173|           shouldRetryWithFallback: false,\n00174|           accumulated: 'Test response',\n00175|         };\n00176|       });\n00177| \n00178|       const { result } = renderHook(() => useChat({}));\n00179| \n00180|       act(() => {\n00181|         result.current.setText('Hello, world!');\n00182|       });\n00183| \n00184|       let sendPromise = Promise.resolve();\n00185|       act(() => {\n00186|         sendPromise = result.current.sendMessage();\n00187|       });\n00188| \n00189|       expect(result.current.isThinking).toBe(true);\n00190| \n00191|       await act(async () => {\n00192|         resolveStreaming?.();\n00193|         await sendPromise;\n00194|       });\n00195| \n00196|       expect(result.current.isThinking).toBe(false);\n00197|     });\n00198| \n00199|     it('should ignore thinking output when disabled', async () => {\n00200|       const onThinkingChunk = jest.fn();\n00201|       const { result } = renderHook(() => useChat({\n00202|         enableThinking: false,\n00203|         onThinkingChunk,\n00204|       }));\n00205| \n00206|       act(() => {\n00207|         result.current.setText('Hello, world!');\n00208|       });\n00209| \n00210|       await act(async () => {\n00211|         await result.current.sendMessage();\n00212|       });\n00213| \n00214|       expect(result.current.thinkingOutput).toEqual(['', '']);\n00215|       expect(result.current.isThinking).toBe(false);\n00216|       expect(onThinkingChunk).not.toHaveBeenCalled();\n00217|     });\n00218| \n00219|     it('should skip placeholder text when disabled', async () => {\n00220|       const { result } = renderHook(() => useChat({ placeholder: false }));\n00221| \n00222|       act(() => {\n00223|         result.current.setText('Hello, world!');\n00224|       });\n00225| \n00226|       await act(async () => {\n00227|         await result.current.sendMessage();\n00228|       });\n00229| \n00230|       expect(result.current.messages).toHaveLength(2);\n00231|       expect(result.current.messages[1]).toEqual({\n00232|         role: 'assistant',\n00233|         content: '',\n00234|       });\n00235|     });\n00236| \n00237|     it('should handle message with override text', async () => {\n00238|       const { result } = renderHook(() => useChat({}));\n00239| \n00240|       act(() => {\n00241|         result.current.setText('Original text');\n00242|       });\n00243| \n00244|       await act(async () => {\n00245|         await result.current.sendMessage('Override text');\n00246|       });\n00247| \n00248|       expect(result.current.messages[0]).toEqual({\n00249|         role: 'user',\n00250|         content: 'Override text',\n00251|       });\n00252|       expect(result.current.text).toBe('Original text'); // Should not clear when using override\n00253|     });\n00254| \n00255|     it('should pass thinking level to streaming options', async () => {\n00256|       const { result } = renderHook(() => useChat({ thinkingLevel: 'high' }));\n00257| \n00258|       act(() => {\n00259|         result.current.setText('Hello, world!');\n00260|       });\n00261| \n00262|       await act(async () => {\n00263|         await result.current.sendMessage();\n00264|       });\n00265| \n00266|       expect(mockExecuteStreaming).toHaveBeenCalled();\n00267|       const [options] = mockExecuteStreaming.mock.calls[0] as [{ thinkingLevel?: string }];\n00268|       expect(options.thinkingLevel).toBe('high');\n00269|     });\n00270|   });\n00271| \n00272|   describe('state management', () => {\n00273|     it('should reset all state to initial values', () => {\n00274|       const { result } = renderHook(() => useChat({}));\n00275| \n00276|       // Modify some state\n00277|       act(() => {\n00278|         result.current.setText('Some text');\n00279|       });\n00280| \n00281|       // Reset\n00282|       act(() => {\n00283|         result.current.reset();\n00284|       });\n00285| \n00286|       expect(result.current.text).toBe('');\n00287|       expect(result.current.messages).toEqual([]);\n00288|       expect(result.current.thinkingOutput).toEqual([]);\n00289|       expect(result.current.isThinking).toBe(false);\n00290|       expect(result.current.isUsingFallback).toBe(false);\n00291|       expect(result.current.canRetry).toBe(false);\n00292|     });\n00293| \n00294|     it('should not throw when cancel is called', () => {\n00295|       const { result } = renderHook(() => useChat({}));\n00296| \n00297|       expect(() => result.current.cancel()).not.toThrow();\n00298|     });\n00299|   });\n00300| \n00301|   describe('provider configuration', () => {\n00302|     it('should use legacy provider when no chatId provided', () => {\n00303|       const { result } = renderHook(() => useChat({\n00304|         providerId: 'openai' as any,\n00305|         modelId: 'gpt-3.5',\n00306|       }));\n00307| \n00308|       expect(result.current.currentProvider).toBe('openai');\n00309|       expect(result.current.currentModel).toBe('gpt-3.5');\n00310|     });\n00311| \n00312|     it('should use chat state when chatId is provided', () => {\n00313|       const { result } = renderHook(() => useChat({\n00314|         chatId: '123',\n00315|         providerId: 'openai' as any, // Should be ignored\n00316|         modelId: 'gpt-3.5',        // Should be ignored\n00317|       }));\n00318| \n00319|       expect(result.current.currentProvider).toBe('apple');\n00320|       expect(result.current.currentModel).toBe('gpt-4');\n00321|     });\n00322|   });\n00323| \n00324|   describe('title functionality', () => {\n00325|     it('should update title when setTitle is called', () => {\n00326|       const { result } = renderHook(() => useChat({}));\n00327| \n00328|       act(() => {\n00329|         result.current.setTitle('New Title');\n00330|       });\n00331| \n00332|       const { useTitleGeneration } = require('../useTitleGeneration');\n00333|       expect(useTitleGeneration().setTitle).toHaveBeenCalledWith('New Title');\n00334|     });\n00335| \n00336|     it('should generate title when generateTitle is called', async () => {\n00337|       const { result } = renderHook(() => useChat({}));\n00338| \n00339|       await act(async () => {\n00340|         const title = await result.current.generateTitle();\n00341|         expect(title).toBe('Generated Title');\n00342|       });\n00343| \n00344|       const { useTitleGeneration } = require('../useTitleGeneration');\n00345|       expect(useTitleGeneration().generateTitle).toHaveBeenCalled();\n00346|     });\n00347|   });\n00348| \n00349|   describe('edge cases', () => {\n00350|     it('should handle non-string input gracefully', async () => {\n00351|       const { result } = renderHook(() => useChat({}));\n00352| \n00353|       await act(async () => {\n00354|         await result.current.sendMessage(123 as any);\n00355|       });\n00356| \n00357|       expect(result.current.messages).toEqual([]);\n00358|       expect(result.current.isStreaming).toBe(false);\n00359|     });\n00360| \n00361|     it('keeps completion ordering stable under rapid sends', async () => {\n00362|       const onComplete = jest.fn();\n00363|       const first = createDeferred<{\n00364|         success: boolean;\n00365|         shouldRetryWithFallback: boolean;\n00366|         accumulated: string;\n00367|       }>();\n00368|       const second = createDeferred<{\n00369|         success: boolean;\n00370|         shouldRetryWithFallback: boolean;\n00371|         accumulated: string;\n00372|       }>();\n00373| \n00374|       mockExecuteStreaming\n00375|         .mockImplementationOnce(() => first.promise)\n00376|         .mockImplementationOnce(() => second.promise);\n00377| \n00378|       const { result } = renderHook(() => useChat({ onComplete }));\n00379| \n00380|       let firstSend = Promise.resolve();\n00381|       let secondSend = Promise.resolve();\n00382| \n00383|       act(() => {\n00384|         firstSend = result.current.sendMessage('first');\n00385|       });\n00386| \n00387|       act(() => {\n00388|         secondSend = result.current.sendMessage('second');\n00389|       });\n00390| \n00391|       await act(async () => {\n00392|         first.resolve({\n00393|           success: true,\n00394|           shouldRetryWithFallback: false,\n00395|           accumulated: 'first-response',\n00396|         });\n00397|         await firstSend;\n00398|       });\n00399| \n00400|       expect(result.current.isStreaming).toBe(true);\n00401|       expect(onComplete).toHaveBeenCalledTimes(0);\n00402| \n00403|       await act(async () => {\n00404|         second.resolve({\n00405|           success: true,\n00406|           shouldRetryWithFallback: false,\n00407|           accumulated: 'second-response',\n00408|         });\n00409|         await secondSend;\n00410|       });\n00411| \n00412|       expect(result.current.isStreaming).toBe(false);\n00413|       expect(onComplete).toHaveBeenCalledTimes(1);\n00414|     });\n00415| \n00416|     it('prevents post-cancel error mutation from stale stream callbacks', async () => {\n00417|       const onError = jest.fn();\n00418|       const pending = createDeferred<{\n00419|         success: boolean;\n00420|         shouldRetryWithFallback: boolean;\n00421|         accumulated: string;\n00422|       }>();\n00423|       let capturedOptions: { onError?: (error: unknown) => void } | null = null;\n00424| \n00425|       mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n00426|         capturedOptions = options;\n00427|         return pending.promise;\n00428|       });\n00429| \n00430|       const { result } = renderHook(() => useChat({ onError }));\n00431| \n00432|       let sendPromise = Promise.resolve();\n00433| \n00434|       act(() => {\n00435|         sendPromise = result.current.sendMessage('cancel-me');\n00436|       });\n00437| \n00438|       act(() => {\n00439|         result.current.cancel();\n00440|       });\n00441| \n00442|       await act(async () => {\n00443|         capturedOptions?.onError?.(new Error('late error'));\n00444|         pending.resolve({\n00445|           success: true,\n00446|           shouldRetryWithFallback: false,\n00447|           accumulated: '',\n00448|         });\n00449|         await sendPromise;\n00450|       });\n00451| \n00452|       expect(result.current.errorMessage).toBeNull();\n00453|       expect(result.current.canRetry).toBe(false);\n00454|       expect(onError).toHaveBeenCalledTimes(0);\n00455|     });\n00456|   });\n00457| });\n00458| \n\n(End of file - total 458 lines)\n</file>","title":"hooks/chat/__tests__/useChat.test.ts","metadata":{"preview":"import { describe, it, expect, beforeEach, jest } from '@jest/globals';\nimport { renderHook, act } from '@testing-library/react-native';\nimport useChat from '../useChat';\n\nconst mockExecuteStreaming = jest.fn();\n\ninterface Deferred<T> {\n  promise: Promise<T>;\n  resolve: (value: T) => void;\n}\n\nconst createDeferred = <T,>(): Deferred<T> => {\n  let resolve!: (value: T) => void;\n  const promise = new Promise<T>((innerResolve) => {\n    resolve = innerResolve;\n  });\n\n  return { promise, resolve };\n};\n","truncated":false},"time":{"start":1770428623697,"end":1770428623699}},"metadata":{"openai":{"itemId":"fc_06bdbe3071b4c33a01698698cf9b3c819083f121aab512b411"}}}}
{"type":"step_finish","timestamp":1770428623904,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c4ebf6001BnQUKkvJUyGin1","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4df98001KPqKaAkoN0rQHR","type":"step-finish","reason":"tool-calls","snapshot":"1627c01e9506b019b61567e096c210e4d8a63e73","cost":0,"tokens":{"input":3758,"output":120,"reasoning":26,"cache":{"read":18432,"write":0}}}}
{"type":"step_start","timestamp":1770428628137,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c4fca8001Pbj8kMim2wWhj9","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4ec50001YSQAS00sElMfqB","type":"step-start","snapshot":"1627c01e9506b019b61567e096c210e4d8a63e73"}}
{"type":"tool_use","timestamp":1770428631344,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c50929001UCiy3s82GztR31","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4ec50001YSQAS00sElMfqB","type":"tool","callID":"call_zdJrhlzAZPF6fW4JQpnQlS1k","tool":"read","state":{"status":"completed","input":{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/concurrency.types.ts"},"output":"<file>\n00001| export interface RequestToken {\n00002|   scope: string;\n00003|   sequence: number;\n00004|   createdAt: number;\n00005| }\n00006| \n00007| export interface SequenceGuard {\n00008|   next(): RequestToken;\n00009|   current(): RequestToken | null;\n00010|   isCurrent(token: RequestToken): boolean;\n00011| }\n00012| \n00013| export interface AbortLease {\n00014|   signal: AbortSignal;\n00015|   abort(reason?: string): void;\n00016|   isAborted(): boolean;\n00017| }\n00018| \n00019| export interface AbortManager {\n00020|   begin(reason?: string): AbortLease;\n00021|   abortActive(reason?: string): void;\n00022|   withAbort<T>(runner: (signal: AbortSignal) => Promise<T>): Promise<T>;\n00023|   hasActive(): boolean;\n00024| }\n00025| \n00026| export type IdempotencyPart = string | number | boolean | null | undefined;\n00027| \n00028| export interface IdempotencyRegistry<T> {\n00029|   run(key: string, task: () => Promise<T>): Promise<T>;\n00030|   has(key: string): boolean;\n00031|   clear(key?: string): void;\n00032|   size(): number;\n00033| }\n00034| \n\n(End of file - total 34 lines)\n</file>","title":"types/concurrency.types.ts","metadata":{"preview":"export interface RequestToken {\n  scope: string;\n  sequence: number;\n  createdAt: number;\n}\n\nexport interface SequenceGuard {\n  next(): RequestToken;\n  current(): RequestToken | null;\n  isCurrent(token: RequestToken): boolean;\n}\n\nexport interface AbortLease {\n  signal: AbortSignal;\n  abort(reason?: string): void;\n  isAborted(): boolean;\n}\n\nexport interface AbortManager {\n  begin(reason?: string): AbortLease;","truncated":false},"time":{"start":1770428631337,"end":1770428631344}},"metadata":{"openai":{"itemId":"fc_0b456ea3ec5dc05601698698d733748195be94f1b7ef25f7b1"}}}}
{"type":"tool_use","timestamp":1770428631345,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c5092c00162yJWIkJZn8qQQ","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4ec50001YSQAS00sElMfqB","type":"tool","callID":"call_kkH3qtZEtNJFg2WEBZphLiGS","tool":"read","state":{"status":"completed","input":{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChatStreaming.ts"},"output":"<file>\n00001| /**\n00002|  * @file useChatStreaming.ts\n00003|  * @purpose Streaming text logic with fallback and retry handling\n00004|  * @connects-to useChat, provider-factory, fallback-chain\n00005|  * \n00006|  * =============================================================================\n00007|  * COMPREHENSIVE HOOK OVERVIEW\n00008|  * =============================================================================\n00009|  * \n00010|  * Purpose:\n00011|  * -------\n00012|  * The useChatStreaming hook is a critical component of the Seabreeze chat application\n00013|  * that manages real-time AI text generation with robust error handling. It provides\n00014|  * seamless streaming responses from multiple AI providers while automatically handling\n00015|  * failures through intelligent retry mechanisms and provider fallback chains.\n00016|  * \n00017|  * Core Responsibilities:\n00018|  * ----------------------\n00019|  * 1. **Real-time Streaming**: Processes AI-generated text chunks and updates the UI\n00020|  *    in real-time as the response is being generated, providing immediate feedback\n00021|  *    to users rather than waiting for the complete response.\n00022|  * \n00023|  * 2. **Error Classification**: Analyzes errors from AI providers to determine if\n00024|  *    they are transient (network issues, rate limits) or permanent (configuration\n00025|  *    errors), enabling appropriate handling strategies.\n00026|  * \n00027|  * 3. **Automatic Retry**: Implements exponential backoff retry logic for transient\n00028|  *    errors, with configurable retry attempts, delays, and backoff multipliers.\n00029|  * \n00030|  * 4. **Provider Fallback**: Automatically switches to alternative AI providers\n00031|  *    when the current provider fails, following a priority order (Apple → OpenAI → \n00032|  *    OpenRouter → Ollama) to maximize service availability.\n00033|  * \n00034|  * 5. **User Experience**: Provides user-friendly error messages with actionable\n00035|  *    tips, maintains conversation context during failures, and preserves partial\n00036|  *    responses when possible.\n00037|  * \n00038|  * Key Features:\n00039|  * ------------\n00040|  * - **Streaming Text Generation**: Uses AI SDK's streamText for real-time responses\n00041|  * - **Intelligent Error Handling**: Classifies errors and applies appropriate strategies\n00042|  * - **Provider Resilience**: Automatic fallback ensures service continuity\n00043|  * - **Configurable Behavior**: Retry and fallback can be enabled/disabled per request\n00044|  * - **Real-time UI Updates**: Callbacks for chunk-by-chunk response updates\n00045|  * - **Comprehensive Callbacks**: Events for errors, fallbacks, and provider changes\n00046|  * \n00047|  * Integration Points:\n00048|  * -------------------\n00049|  * - **useChat**: Main orchestrator that calls this hook for message streaming\n00050|  * - **provider-factory**: Supplies AI models and handles provider initialization\n00051|  * - **fallback-chain**: Manages provider priority and error classification\n00052|  * - **error-messages**: Formats user-friendly error messages and hints\n00053|  * - **useErrorRecovery**: Provides retry logic with exponential backoff\n00054|  * \n00055|  * Flow Overview:\n00056|  * --------------\n00057|  * 1. User sends message → useChat calls executeStreaming()\n00058|  * 2. Stream operation begins with current provider\n00059|  * 3. If error occurs → classify error → attempt retry (if enabled)\n00060|  * 4. If retry fails → attempt fallback to next provider\n00061|  * 5. Update UI in real-time throughout the process\n00062|  * 6. Handle final success or display user-friendly error\n00063|  * \n00064|  * Usage Pattern:\n00065|  * --------------\n00066|  * ```typescript\n00067|  * const { executeStreaming, handleStreamingError } = useChatStreaming();\n00068|  * \n00069|  * const result = await executeStreaming(\n00070|  *   {\n00071|  *     model: fallbackResult,\n00072|  *     enableRetry: true,\n00073|  *     enableFallback: true,\n00074|  *     activeProvider: 'openai',\n00075|  *     onChunk: (chunk, accumulated) => updateUI(accumulated),\n00076|  *     onError: (error) => showError(error),\n00077|  *     onFallback: (from, to, reason) => notifyFallback(from, to, reason)\n00078|  *   },\n00079|  *   messages,\n00080|  *   setMessages,\n00081|  *   assistantIndex,\n00082|  *   failedProvidersRef\n00083|  * );\n00084|  * ```\n00085|  * \n00086|  * Error Handling Strategy:\n00087|  * -----------------------\n00088|  * 1. **Transient Errors** (network, rate limits, server errors): Retry with backoff\n00089|  * 2. **Configuration Errors** (API keys, model not found): Skip retry, attempt fallback\n00090|  * 3. **Unknown Errors**: Fallback to next provider if available\n00091|  * 4. **No Fallback Available**: Display user-friendly error with troubleshooting tips\n00092|  * \n00093|  * Performance Considerations:\n00094|  * ---------------------------\n00095|  * - Uses React.useCallback for function memoization to prevent unnecessary re-renders\n00096|  * - Efficient message array updates preserve conversation context\n00097|  * - Streaming reduces perceived latency by showing responses as they generate\n00098|  * - Failed providers tracking prevents repeated attempts at broken providers\n00099|  * =============================================================================\n00100|  */\n00101| \n00102| // Core React hooks for memoization\n00103| import { useCallback } from \"react\";\n00104| // AI SDK for streaming text generation and type definitions\n00105| import { streamText, type LanguageModel, type ModelMessage } from \"ai\";\n00106| // Provider type definitions for the fallback system\n00107| import { isThinkingCapableModel, type ProviderId } from \"@/types/provider.types\";\n00108| import type { ThinkingLevel } from \"@/types/chat.types\";\n00109| // Fallback chain utilities for provider switching and error classification\n00110| import { getModelWithFallback, getNextFallbackProvider, classifyError, hasFallbackAvailable, type FallbackResult } from \"@/providers/fallback-chain\";\n00111| // Error message formatting utilities for user-friendly error display\n00112| import { formatErrorForChat, getProviderErrorHint, shouldShowRetry } from \"@/lib/error-messages\";\n00113| // Retry mechanism with exponential backoff for handling transient errors\n00114| import { executeWithRetry, DEFAULT_RETRY_CONFIG, type RetryConfig } from \"@/hooks/useErrorRecovery\";\n00115| \n00116| /**\n00117|  * Configuration options for the streaming operation\n00118|  */\n00119| export interface StreamingOptions {\n00120|     /** The resolved model to use for streaming (may be a fallback) */\n00121|     model: FallbackResult;\n00122|     /** Whether to enable automatic retry on transient errors */\n00123|     enableRetry: boolean;\n00124|     /** Custom retry configuration to override defaults */\n00125|     retryConfig: Partial<RetryConfig>;\n00126|     /** Whether to enable automatic fallback to other providers on errors */\n00127|     enableFallback: boolean;\n00128|     /** The currently selected provider from user preferences */\n00129|     activeProvider: ProviderId;\n00130|     /** The effective provider ID actually being used (may differ due to fallback) */\n00131|     effectiveProviderId: ProviderId;\n00132|     /** Callback fired when a new text chunk is received */\n00133|     onChunk?: (chunk: string, accumulated: string) => void;\n00134|     /** Callback fired when a new thinking/reasoning chunk is received */\n00135|     onThinkingChunk?: (chunk: string, accumulated: string) => void;\n00136|     /** Control reasoning effort for supported providers */\n00137|     thinkingLevel?: ThinkingLevel;\n00138|     /** Callback fired when an error occurs during streaming */\n00139|     onError?: (error: unknown) => void;\n00140|     /** Callback fired when falling back to another provider */\n00141|     onFallback?: (from: ProviderId, to: ProviderId, reason: string) => void;\n00142|     /** Callback fired when the provider changes (due to fallback or explicit change) */\n00143|     onProviderChange?: (provider: ProviderId, model: string, isFallback: boolean) => void;\n00144|     /** Abort signal for cancelling the stream */\n00145|     abortSignal?: AbortSignal;\n00146|     /** Gate used to block stale/cancelled state mutation */\n00147|     canMutateState?: () => boolean;\n00148| }\n00149| \n00150| /**\n00151|  * Result of a streaming operation\n00152|  */\n00153| export interface StreamingResult {\n00154|     /** Whether the streaming completed successfully without needing fallback */\n00155|     success: boolean;\n00156|     /** Whether the operation should be retried with a different provider */\n00157|     shouldRetryWithFallback: boolean;\n00158|     /** The complete accumulated text from the stream */\n00159|     accumulated: string;\n00160|     /** Whether the stream was cancelled */\n00161|     wasCancelled: boolean;\n00162| }\n00163| \n00164| export function useChatStreaming() {\n00165|     /**\n00166|      * Handles streaming errors by determining if fallback should be attempted\n00167|      * \n00168|      * This function implements the core error handling logic for streaming operations.\n00169|      * It classifies the error to determine if it's suitable for fallback, finds the next\n00170|      * available provider, and triggers the appropriate callbacks.\n00171|      * \n00172|      * @param error - The error that occurred during streaming\n00173|      * @param activeProvider - The provider that was being used when the error occurred\n00174|      * @param enableFallback - Whether fallback is enabled for this operation\n00175|      * @param onError - Callback to trigger when error cannot be handled by fallback\n00176|      * @param onFallback - Callback to trigger when fallback is being attempted\n00177|      * @param onProviderChange - Callback to trigger when switching to a new provider\n00178|      * @param failedProviders - List of providers that have already failed in this session\n00179|      * @returns Promise resolving to whether retry should be attempted and with which provider\n00180|      */\n00181|     const handleStreamingError = useCallback(async (\n00182|         error: unknown,\n00183|         activeProvider: ProviderId,\n00184|         enableFallback: boolean,\n00185|         onError?: (error: unknown) => void,\n00186|         onFallback?: (from: ProviderId, to: ProviderId, reason: string) => void,\n00187|         onProviderChange?: (provider: ProviderId, model: string, isFallback: boolean) => void,\n00188|         failedProviders?: ProviderId[]\n00189|     ): Promise<{ \n00190|         shouldRetry: boolean; \n00191|         nextProvider?: ProviderId; \n00192|         nextModel?: string;\n00193|     }> => {\n00194|         // Classify the error to determine appropriate handling strategy\n00195|         const classification = classifyError(error);\n00196| \n00197|         // If fallback is enabled and the error type warrants fallback\n00198|         if (enableFallback && classification.shouldFallback) {\n00199|             // Find the next available provider that hasn't failed yet\n00200|             const nextProvider = getNextFallbackProvider(\n00201|                 activeProvider,\n00202|                 failedProviders || [],\n00203|                 error\n00204|             );\n00205| \n00206|             // If we found a suitable fallback provider\n00207|             if (nextProvider) {\n00208|                 // Notify the UI that we're switching providers\n00209|                 onProviderChange?.(nextProvider.provider, nextProvider.model, true);\n00210|                 // Notify the UI that fallback is happening\n00211|                 onFallback?.(activeProvider, nextProvider.provider, classification.message);\n00212|                 return { \n00213|                     shouldRetry: true,\n00214|                     nextProvider: nextProvider.provider,\n00215|                     nextModel: nextProvider.model\n00216|                 };\n00217|             }\n00218|         }\n00219| \n00220|         // No fallback possible or enabled, trigger error callback\n00221|         onError?.(error);\n00222|         return { shouldRetry: false };\n00223|     }, []);\n00224| \n00225|     /**\n00226|      * Executes a streaming operation with retry logic and fallback handling\n00227|      * \n00228|      * This is the core streaming function that manages the entire lifecycle of a chat message:\n00229|      * 1. Sets up the streaming operation with the provided model and messages\n00230|      * 2. Handles real-time text generation and UI updates\n00231|      * 3. Implements retry logic for transient errors\n00232|      * 4. Falls back to alternative providers when appropriate\n00233|      * 5. Formats and displays user-friendly error messages\n00234|      * \n00235|      * @param options - Configuration for the streaming operation\n00236|      * @param messages - Current conversation history\n00237|      * @param setMessages - State setter to update the conversation in real-time\n00238|      * @param assistantIndex - Index in messages array where the assistant response should go\n00239|      * @param failedProvidersRef - Ref tracking providers that have already failed\n00240|      * @returns Promise resolving to the streaming result\n00241|      */\n00242|     const executeStreaming = useCallback(async (\n00243|         options: StreamingOptions,\n00244|         messages: ModelMessage[],\n00245|         setMessages: React.Dispatch<React.SetStateAction<ModelMessage[]>>,\n00246|         assistantIndex: number,\n00247|         failedProvidersRef: React.MutableRefObject<ProviderId[]>\n00248|     ): Promise<StreamingResult> => {\n00249|         // Extract options for easier access\n00250|         const {\n00251|             model: currentModel,\n00252|             enableRetry,\n00253|             retryConfig,\n00254|             enableFallback,\n00255|             activeProvider,\n00256|             effectiveProviderId,\n00257|             onChunk,\n00258|             onThinkingChunk,\n00259|             thinkingLevel,\n00260|             onError,\n00261|             onFallback,\n00262|             onProviderChange,\n00263|             abortSignal,\n00264|             canMutateState,\n00265|         } = options;\n00266| \n00267|         const canCommit = (): boolean => {\n00268|             if (abortSignal?.aborted) {\n00269|                 return false;\n00270|             }\n00271| \n00272|             return canMutateState ? canMutateState() : true;\n00273|         };\n00274| \n00275|         const updateAssistantMessage = (content: string): void => {\n00276|             if (!canCommit()) {\n00277|                 return;\n00278|             }\n00279| \n00280|             setMessages((prev) => {\n00281|                 const next = [...prev];\n00282|                 next[assistantIndex] = {\n00283|                     role: \"assistant\",\n00284|                     content,\n00285|                 };\n00286|                 return next;\n00287|             });\n00288|         };\n00289| \n00290|         // Accumulator for the complete response text\n00291|         let accumulated = \"\";\n00292|         // Accumulator for the complete reasoning output\n00293|         let reasoningAccumulated = \"\";\n00294|         // Flag indicating whether we should retry with a different provider\n00295|         let shouldRetryWithFallback = false;\n00296| \n00297|         // Merge default retry config with any custom overrides\n00298|         const mergedRetryConfig: RetryConfig = { ...DEFAULT_RETRY_CONFIG, ...retryConfig };\n00299| \n00300|         /**\n00301|          * Core streaming operation that handles the AI text generation\n00302|          * This function processes the text stream and updates the UI in real-time\n00303|          */\n00304|         const streamOperation = async () => {\n00305|             const canModelThink = currentModel.provider === \"ollama\"\n00306|                 || isThinkingCapableModel(\n00307|                     currentModel.provider,\n00308|                     currentModel.modelId ?? \"\",\n00309|                 );\n00310|             const thinkingChunkHandler = canModelThink ? onThinkingChunk : undefined;\n00311|             const shouldRequestThinking = Boolean(thinkingChunkHandler);\n00312|             const effectiveThinkingLevel: ThinkingLevel = thinkingLevel ?? \"medium\";\n00313|             let providerOptions: Parameters<typeof streamText>[0][\"providerOptions\"];\n00314| \n00315|             if (shouldRequestThinking && currentModel.provider === \"openai\") {\n00316|                 providerOptions = {\n00317|                     openai: {\n00318|                         reasoningEffort: effectiveThinkingLevel,\n00319|                         reasoningSummary: \"auto\",\n00320|                     },\n00321|                 };\n00322|             } else if (shouldRequestThinking && currentModel.provider === \"openrouter\") {\n00323|                 providerOptions = {\n00324|                     openrouter: {\n00325|                         includeReasoning: true,\n00326|                         reasoning: {\n00327|                             effort: effectiveThinkingLevel,\n00328|                         },\n00329|                     },\n00330|                 };\n00331|             } else if (shouldRequestThinking && currentModel.provider === \"ollama\") {\n00332|                 providerOptions = {\n00333|                     ollama: {\n00334|                         think: true,\n00335|                     },\n00336|                 };\n00337|             }\n00338|             // Initialize the streaming text generation\n00339|             const result = streamText({\n00340|                 model: currentModel.model!,\n00341|                 messages: messages,\n00342|                 providerOptions,\n00343|             });\n00344| \n00345|             if (result.fullStream) {\n00346|                 for await (const part of result.fullStream) {\n00347|                     // Check for abort signal\n00348|                     if (abortSignal?.aborted) {\n00349|                         return;\n00350|                     }\n00351| \n00352|                     if (part.type === \"reasoning-delta\") {\n00353|                         if (!thinkingChunkHandler) {\n00354|                             continue;\n00355|                         }\n00356|                         const reasoningDelta = typeof (part as { text?: unknown }).text === \"string\"\n00357|                             ? (part as { text: string }).text\n00358|                             : typeof (part as { delta?: unknown }).delta === \"string\"\n00359|                                 ? (part as { delta?: string }).delta ?? \"\"\n00360|                                 : \"\";\n00361| \n00362|                         if (!reasoningDelta) {\n00363|                             continue;\n00364|                         }\n00365| \n00366|                         reasoningAccumulated += reasoningDelta;\n00367|                         if (canCommit()) {\n00368|                             thinkingChunkHandler?.(reasoningDelta, reasoningAccumulated);\n00369|                         }\n00370|                         continue;\n00371|                     }\n00372| \n00373|                     if (part.type === \"text-delta\") {\n00374|                         accumulated += part.text;\n00375|                         updateAssistantMessage(accumulated);\n00376| \n00377|                         if (canCommit()) {\n00378|                             onChunk?.(part.text, accumulated);\n00379|                         }\n00380|                     }\n00381|                 }\n00382|                 return;\n00383|             }\n00384| \n00385|             // Fallback for older SDKs without fullStream\n00386|             for await (const chunk of result.textStream) {\n00387|                 // Check for abort signal\n00388|                 if (abortSignal?.aborted) {\n00389|                     return;\n00390|                 }\n00391| \n00392|                 accumulated += chunk;\n00393|                 updateAssistantMessage(accumulated);\n00394| \n00395|                 if (canCommit()) {\n00396|                     onChunk?.(chunk, accumulated);\n00397|                 }\n00398|             }\n00399|         };\n00400| \n00401|         try {\n00402|             // If retry is enabled, wrap the stream operation with retry logic\n00403|             if (enableRetry) {\n00404|                 const retryResult = await executeWithRetry(\n00405|                     streamOperation,\n00406|                     mergedRetryConfig\n00407|                 );\n00408| \n00409|                 // If retry failed but we have an error to handle\n00410|                 if (!retryResult.success && retryResult.error) {\n00411|                     // Log detailed error info for debugging\n00412|                     console.error(\"[useChatStreaming] Streaming error after retries:\", {\n00413|                         provider: effectiveProviderId,\n00414|                         model: currentModel.modelId,\n00415|                         errorType: retryResult.error.category,\n00416|                         errorMessage: retryResult.error.message,\n00417|                         attempts: retryResult.attempts,\n00418|                         accumulatedLength: accumulated.length,\n00419|                         timestamp: new Date().toISOString(),\n00420|                         hasFallbackAvailable: enableFallback,\n00421|                     });\n00422| \n00423|                     const errorResult = await handleStreamingError(\n00424|                         retryResult.error,\n00425|                         activeProvider,\n00426|                         enableFallback,\n00427|                         onError,\n00428|                         onFallback,\n00429|                         onProviderChange,\n00430|                         failedProvidersRef.current\n00431|                     );\n00432| \n00433|                     if (errorResult.shouldRetry) {\n00434|                         // If we have a fallback provider available\n00435|                         if (errorResult.nextProvider) {\n00436|                             // Mark current provider as failed\n00437|                             failedProvidersRef.current.push(activeProvider);\n00438|                             shouldRetryWithFallback = true;\n00439|                             \n00440|                             console.log(\"[useChatStreaming] Falling back to provider:\", {\n00441|                                 from: activeProvider,\n00442|                                 to: errorResult.nextProvider,\n00443|                                 reason: retryResult.error.message,\n00444|                                 timestamp: new Date().toISOString(),\n00445|                             });\n00446|                         } else {\n00447|                             // No fallback available, show user-friendly error\n00448|                             const errorMessage = formatErrorForChat(retryResult.error, activeProvider);\n00449|                             const providerHint = getProviderErrorHint(retryResult.error, activeProvider);\n00450|                             const fullErrorMessage = providerHint \n00451|                                 ? `${errorMessage}\\n\\n*Tip: ${providerHint}*`\n00452|                                 : errorMessage;\n00453| \n00454|                             // Preserve partial content and append error message\n00455|                             const partialContent = accumulated.length > 0 \n00456|                                 ? `${accumulated}\\n\\n---\\n\\n**Error:** ${fullErrorMessage}`\n00457|                                 : fullErrorMessage;\n00458| \n00459|                             updateAssistantMessage(partialContent);\n00460|                         }\n00461|                     }\n00462|                 }\n00463|             } else {\n00464|                 // No retry enabled, execute the stream operation directly\n00465|                 await streamOperation();\n00466|             }\n00467|         } catch (err) {\n00468|             // Log detailed error info for debugging\n00469|             const classification = classifyError(err);\n00470|             console.error(\"[useChatStreaming] Unexpected streaming error:\", {\n00471|                 provider: effectiveProviderId,\n00472|                 model: currentModel.modelId,\n00473|                 errorType: classification.category,\n00474|                 errorMessage: classification.message,\n00475|                 accumulatedLength: accumulated.length,\n00476|                 timestamp: new Date().toISOString(),\n00477|                 stack: err instanceof Error ? err.stack : undefined,\n00478|             });\n00479| \n00480|             // Handle unexpected errors that weren't caught by the retry mechanism\n00481|             const errorResult = await handleStreamingError(\n00482|                 err,\n00483|                 activeProvider,\n00484|                 enableFallback,\n00485|                 onError,\n00486|                 onFallback,\n00487|                 onProviderChange,\n00488|                 failedProvidersRef.current\n00489|             );\n00490| \n00491|             if (errorResult.shouldRetry && errorResult.nextProvider) {\n00492|                 // We have a fallback provider available\n00493|                 failedProvidersRef.current.push(activeProvider);\n00494|                 shouldRetryWithFallback = true;\n00495|                 \n00496|                 console.log(\"[useChatStreaming] Falling back to provider after error:\", {\n00497|                     from: activeProvider,\n00498|                     to: errorResult.nextProvider,\n00499|                     reason: classification.message,\n00500|                     timestamp: new Date().toISOString(),\n00501|                 });\n00502|             } else {\n00503|                 // No fallback available, format and display the error\n00504|                 const errorMessage = formatErrorForChat(err, activeProvider);\n00505|                 const providerHint = getProviderErrorHint(err, activeProvider);\n00506|                 const fullErrorMessage = providerHint \n00507|                     ? `${errorMessage}\\n\\n*Tip: ${providerHint}*`\n00508|                     : errorMessage;\n00509| \n00510|                 // Preserve partial content and append error message\n00511|                 const partialContent = accumulated.length > 0 \n00512|                     ? `${accumulated}\\n\\n---\\n\\n**Error:** ${fullErrorMessage}`\n00513|                     : fullErrorMessage;\n00514| \n00515|                 updateAssistantMessage(partialContent);\n00516|             }\n00517|         }\n00518| \n00519|         return {\n00520|             success: !shouldRetryWithFallback,\n00521|             shouldRetryWithFallback,\n00522|             accumulated,\n00523|             wasCancelled: options.abortSignal?.aborted ?? false,\n00524|         };\n00525|     }, [handleStreamingError]);\n00526| \n00527|     return {\n00528|         executeStreaming,\n00529|         handleStreamingError,\n00530|     };\n00531| }\n00532| \n\n(End of file - total 532 lines)\n</file>","title":"hooks/chat/useChatStreaming.ts","metadata":{"preview":"/**\n * @file useChatStreaming.ts\n * @purpose Streaming text logic with fallback and retry handling\n * @connects-to useChat, provider-factory, fallback-chain\n * \n * =============================================================================\n * COMPREHENSIVE HOOK OVERVIEW\n * =============================================================================\n * \n * Purpose:\n * -------\n * The useChatStreaming hook is a critical component of the Seabreeze chat application\n * that manages real-time AI text generation with robust error handling. It provides\n * seamless streaming responses from multiple AI providers while automatically handling\n * failures through intelligent retry mechanisms and provider fallback chains.\n * \n * Core Responsibilities:\n * ----------------------\n * 1. **Real-time Streaming**: Processes AI-generated text chunks and updates the UI\n *    in real-time as the response is being generated, providing immediate feedback","truncated":false},"time":{"start":1770428631340,"end":1770428631344}},"metadata":{"openai":{"itemId":"fc_0b456ea3ec5dc05601698698d7337c8195836568ca11a02e98"}}}}
{"type":"tool_use","timestamp":1770428631346,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c509230019eFnoJIl71ZSe4","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4ec50001YSQAS00sElMfqB","type":"tool","callID":"call_MKvJFKKKZNpD41NxPhq2ke6v","tool":"read","state":{"status":"completed","input":{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/lib/concurrency.ts"},"output":"<file>\n00001| /**\n00002|  * @file concurrency.ts\n00003|  * @purpose Shared concurrency primitives for sequencing, cancellation, and idempotency.\n00004|  */\n00005| \n00006| import type {\n00007|   AbortLease,\n00008|   AbortManager,\n00009|   IdempotencyPart,\n00010|   IdempotencyRegistry,\n00011|   RequestToken,\n00012|   SequenceGuard,\n00013| } from \"@/types/concurrency.types\";\n00014| \n00015| const DEFAULT_ABORT_REASON = \"superseded-by-new-request\";\n00016| \n00017| export function createSequenceGuard(scope: string): SequenceGuard {\n00018|   let currentToken: RequestToken | null = null;\n00019| \n00020|   return {\n00021|     next(): RequestToken {\n00022|       const sequence = (currentToken?.sequence ?? 0) + 1;\n00023|       currentToken = {\n00024|         scope,\n00025|         sequence,\n00026|         createdAt: Date.now(),\n00027|       };\n00028|       return currentToken;\n00029|     },\n00030|     current(): RequestToken | null {\n00031|       return currentToken;\n00032|     },\n00033|     isCurrent(token: RequestToken): boolean {\n00034|       if (!currentToken) {\n00035|         return false;\n00036|       }\n00037| \n00038|       return token.scope === scope && token.sequence === currentToken.sequence;\n00039|     },\n00040|   };\n00041| }\n00042| \n00043| export function createAbortError(message = \"Request aborted\"): Error {\n00044|   const error = new Error(message);\n00045|   error.name = \"AbortError\";\n00046|   return error;\n00047| }\n00048| \n00049| export function isAbortError(error: unknown): boolean {\n00050|   return error instanceof Error && error.name === \"AbortError\";\n00051| }\n00052| \n00053| function createAbortLease(controller: AbortController): AbortLease {\n00054|   return {\n00055|     signal: controller.signal,\n00056|     abort(reason = DEFAULT_ABORT_REASON): void {\n00057|       controller.abort(reason);\n00058|     },\n00059|     isAborted(): boolean {\n00060|       return controller.signal.aborted;\n00061|     },\n00062|   };\n00063| }\n00064| \n00065| export function createAbortManager(): AbortManager {\n00066|   let activeController: AbortController | null = null;\n00067| \n00068|   return {\n00069|     begin(reason = DEFAULT_ABORT_REASON): AbortLease {\n00070|       if (activeController && !activeController.signal.aborted) {\n00071|         activeController.abort(reason);\n00072|       }\n00073| \n00074|       const controller = new AbortController();\n00075|       activeController = controller;\n00076|       return createAbortLease(controller);\n00077|     },\n00078|     abortActive(reason = DEFAULT_ABORT_REASON): void {\n00079|       if (activeController && !activeController.signal.aborted) {\n00080|         activeController.abort(reason);\n00081|       }\n00082|       activeController = null;\n00083|     },\n00084|     async withAbort<T>(runner: (signal: AbortSignal) => Promise<T>): Promise<T> {\n00085|       const lease = this.begin();\n00086| \n00087|       try {\n00088|         return await runner(lease.signal);\n00089|       } finally {\n00090|         if (activeController?.signal === lease.signal) {\n00091|           activeController = null;\n00092|         }\n00093|       }\n00094|     },\n00095|     hasActive(): boolean {\n00096|       return Boolean(activeController && !activeController.signal.aborted);\n00097|     },\n00098|   };\n00099| }\n00100| \n00101| export function createIdempotencyKey(scope: string, parts: IdempotencyPart[]): string {\n00102|   const serializedParts = parts.map((part) => {\n00103|     if (part === null) {\n00104|       return \"null\";\n00105|     }\n00106| \n00107|     if (part === undefined) {\n00108|       return \"undefined\";\n00109|     }\n00110| \n00111|     return String(part);\n00112|   });\n00113| \n00114|   return `${scope}:${serializedParts.join(\"|\")}`;\n00115| }\n00116| \n00117| export function createIdempotencyRegistry<T>(): IdempotencyRegistry<T> {\n00118|   const inFlight = new Map<string, Promise<T>>();\n00119| \n00120|   return {\n00121|     run(key: string, task: () => Promise<T>): Promise<T> {\n00122|       const existing = inFlight.get(key);\n00123|       if (existing) {\n00124|         return existing;\n00125|       }\n00126| \n00127|       const promise = Promise.resolve()\n00128|         .then(task)\n00129|         .finally(() => {\n00130|           inFlight.delete(key);\n00131|         });\n00132| \n00133|       inFlight.set(key, promise);\n00134|       return promise;\n00135|     },\n00136|     has(key: string): boolean {\n00137|       return inFlight.has(key);\n00138|     },\n00139|     clear(key?: string): void {\n00140|       if (key) {\n00141|         inFlight.delete(key);\n00142|         return;\n00143|       }\n00144| \n00145|       inFlight.clear();\n00146|     },\n00147|     size(): number {\n00148|       return inFlight.size;\n00149|     },\n00150|   };\n00151| }\n00152| \n\n(End of file - total 152 lines)\n</file>","title":"lib/concurrency.ts","metadata":{"preview":"/**\n * @file concurrency.ts\n * @purpose Shared concurrency primitives for sequencing, cancellation, and idempotency.\n */\n\nimport type {\n  AbortLease,\n  AbortManager,\n  IdempotencyPart,\n  IdempotencyRegistry,\n  RequestToken,\n  SequenceGuard,\n} from \"@/types/concurrency.types\";\n\nconst DEFAULT_ABORT_REASON = \"superseded-by-new-request\";\n\nexport function createSequenceGuard(scope: string): SequenceGuard {\n  let currentToken: RequestToken | null = null;\n\n  return {","truncated":false},"time":{"start":1770428631334,"end":1770428631345}},"metadata":{"openai":{"itemId":"fc_0b456ea3ec5dc05601698698d733648195b016ce67c84acdb1"}}}}
{"type":"step_finish","timestamp":1770428631568,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c509e10012kcohmEbprPeNe","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c4ec50001YSQAS00sElMfqB","type":"step-finish","reason":"tool-calls","snapshot":"1627c01e9506b019b61567e096c210e4d8a63e73","cost":0,"tokens":{"input":17434,"output":173,"reasoning":49,"cache":{"read":17920,"write":0}}}}
{"type":"step_start","timestamp":1770428632295,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c50ce60014WkXeDN1UV9pbB","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c50a42001CfifBfrqyjOmft","type":"step-start","snapshot":"1627c01e9506b019b61567e096c210e4d8a63e73"}}
{"type":"tool_use","timestamp":1770428695626,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c5bfea001ZOHCV9etTaM2PB","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c50a42001CfifBfrqyjOmft","type":"tool","callID":"call_vnr66bK8qXPTvfH8H8WwXTJ2","tool":"apply_patch","state":{"status":"completed","input":{"patchText":"*** Begin Patch\n*** Update File: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n@@\n-import { createSequenceGuard } from \"@/lib/concurrency\";\n+import {\n+    createIdempotencyKey,\n+    createIdempotencyRegistry,\n+    createSequenceGuard,\n+} from \"@/lib/concurrency\";\n@@\n type ChunkHandler = (chunk: string, accumulated: string) => void;\n+\n+interface RetryableOperation {\n+    operationKey: string;\n+    content: string;\n+}\n@@\n     const messagesRef = useRef<ModelMessage[]>(initialMessages);\n     const sendSequenceGuardRef = useRef(createSequenceGuard(`chat-send-${chatId ?? \"default\"}`));\n+    const retryOperationRegistryRef = useRef(createIdempotencyRegistry<void>());\n+    const lastRetryableOperationRef = useRef<RetryableOperation | null>(null);\n@@\n         setCanRetry(false);                      // Disable retry capability\n         setErrorMessage(null);                   // Clear error message\n+        lastRetryableOperationRef.current = null;\n+        retryOperationRegistryRef.current.clear();\n     }, [effectiveProviderId, effectiveModelId, setTitle]);\n@@\n             const sendToken = sendSequenceGuardRef.current.next();\n+            const sendOperationKey = createIdempotencyKey(\"chat-send\", [\n+                chatId ?? \"default\",\n+                sendToken.sequence,\n+                content,\n+            ]);\n@@\n             setCanRetry(false);                     // Disable retry until needed\n+            lastRetryableOperationRef.current = null;\n             lastUserMessageRef.current = content;   // Store for retry capability\n@@\n                         setErrorMessage(error.message);\n                         setCanRetry(true);\n+                        lastRetryableOperationRef.current = {\n+                            operationKey: sendOperationKey,\n+                            content,\n+                        };\n                         onError?.(error);\n                     } else {\n                         const wrappedError = new Error(String(error));\n                         markError(wrappedError);\n                         setErrorMessage(wrappedError.message);\n                         setCanRetry(true);\n+                        lastRetryableOperationRef.current = {\n+                            operationKey: sendOperationKey,\n+                            content,\n+                        };\n                         onError?.(wrappedError);\n                     }\n                 },\n@@\n             thinkingLevel,\n             onThinkingChunk\n         ],\n     );\n@@\n     const retryLastMessage = useCallback(async () => {\n-        // Guard against invalid retry attempts\n-        if (!lastUserMessageRef.current || !canRetry) return;\n-        \n-        // Remove the failed assistant message from history\n-        setMessages((prev) => {\n-            if (prev.length >= 2 && prev[prev.length - 1].role === \"assistant\") {\n-                return prev.slice(0, -1);\n-            }\n-            return prev;\n-        });\n-        setThinkingOutput((prev) => {\n-            if (prev.length >= 1) {\n-                return prev.slice(0, -1);\n-            }\n-            return prev;\n-        });\n-\n-        // Remove the original user message (we'll resend it fresh)\n-        setMessages((prev) => {\n-            if (prev.length >= 1 && prev[prev.length - 1].role === \"user\") {\n-                return prev.slice(0, -1);\n-            }\n-            return prev;\n-        });\n-        setThinkingOutput((prev) => {\n-            if (prev.length >= 1) {\n-                return prev.slice(0, -1);\n-            }\n-            return prev;\n-        });\n-\n-        // Reset retry state and clear error message\n-        setCanRetry(false);\n-        setErrorMessage(null);\n-        await sendMessage(lastUserMessageRef.current);\n-    }, [canRetry, sendMessage]);\n+        const retryableOperation = lastRetryableOperationRef.current;\n+\n+        // Guard against invalid retry attempts\n+        if (!lastUserMessageRef.current || !canRetry || !retryableOperation) return;\n+\n+        const retryOperationKey = createIdempotencyKey(\"chat-retry\", [\n+            retryableOperation.operationKey,\n+            retryableOperation.content,\n+        ]);\n+\n+        await retryOperationRegistryRef.current.run(retryOperationKey, async () => {\n+            const currentMessages = messagesRef.current;\n+            let nextMessages = [...currentMessages];\n+            let removedCount = 0;\n+\n+            if (nextMessages.length > 0 && nextMessages[nextMessages.length - 1].role === \"assistant\") {\n+                nextMessages = nextMessages.slice(0, -1);\n+                removedCount += 1;\n+            }\n+\n+            const lastMessage = nextMessages[nextMessages.length - 1];\n+            if (\n+                lastMessage\n+                && lastMessage.role === \"user\"\n+                && typeof lastMessage.content === \"string\"\n+                && lastMessage.content === retryableOperation.content\n+            ) {\n+                nextMessages = nextMessages.slice(0, -1);\n+                removedCount += 1;\n+            }\n+\n+            messagesRef.current = nextMessages;\n+            setMessages(nextMessages);\n+            setThinkingOutput((prev) => prev.slice(0, Math.max(0, prev.length - removedCount)));\n+\n+            // Reset retry state and clear error message\n+            setCanRetry(false);\n+            setErrorMessage(null);\n+            lastRetryableOperationRef.current = null;\n+\n+            await sendMessage(retryableOperation.content);\n+        });\n+    }, [canRetry, sendMessage]);\n*** End Patch"},"output":"Success. Updated the following files:\nM hooks/chat/useChat.ts","title":"Success. Updated the following files:\nM hooks/chat/useChat.ts","metadata":{"diff":"Index: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n===================================================================\n--- /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n+++ /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n@@ -49,12 +49,21 @@\n import { useTitleGeneration } from \"./useTitleGeneration\";\n import { useChatStreaming } from \"./useChatStreaming\";\n import { useStreamLifecycle } from \"./useStreamLifecycle\";\n import type { UseChatOptions, StreamState } from \"@/types/chat.types\";\n-import { createSequenceGuard } from \"@/lib/concurrency\";\n+import {\n+    createIdempotencyKey,\n+    createIdempotencyRegistry,\n+    createSequenceGuard,\n+} from \"@/lib/concurrency\";\n \n type ChunkHandler = (chunk: string, accumulated: string) => void;\n \n+interface RetryableOperation {\n+    operationKey: string;\n+    content: string;\n+}\n+\n const DEFAULT_PLACEHOLDER_TEXT = \"...\";\n \n // =============================================================================\n // TYPE DEFINITIONS\n@@ -216,8 +225,10 @@\n     const [errorMessage, setErrorMessage] = useState<string | null>(null); // Error message for display\n     const canceledRef = useRef<boolean>(false);             // Track if streaming was canceled\n     const messagesRef = useRef<ModelMessage[]>(initialMessages);\n     const sendSequenceGuardRef = useRef(createSequenceGuard(`chat-send-${chatId ?? \"default\"}`));\n+    const retryOperationRegistryRef = useRef(createIdempotencyRegistry<void>());\n+    const lastRetryableOperationRef = useRef<RetryableOperation | null>(null);\n \n     useEffect(() => {\n         messagesRef.current = messages;\n     }, [messages]);\n@@ -358,8 +369,10 @@\n         failedProvidersRef.current = [];         // Clear failed providers list\n         lastUserMessageRef.current = null;       // Clear retry message\n         setCanRetry(false);                      // Disable retry capability\n         setErrorMessage(null);                   // Clear error message\n+        lastRetryableOperationRef.current = null;\n+        retryOperationRegistryRef.current.clear();\n     }, [effectiveProviderId, effectiveModelId, setTitle]);\n \n     /**\n      * Cancel the current streaming operation\n@@ -409,16 +422,22 @@\n             // Exit early if no valid content to send\n             if (!content) return;\n \n             const sendToken = sendSequenceGuardRef.current.next();\n+            const sendOperationKey = createIdempotencyKey(\"chat-send\", [\n+                chatId ?? \"default\",\n+                sendToken.sequence,\n+                content,\n+            ]);\n \n             // ────────────────────────────────────────────────────────────────\n             // STATE INITIALIZATION\n             // ────────────────────────────────────────────────────────────────\n             setIsStreaming(true);                    // Start streaming state\n             setIsThinking(false);                    // Reset thinking state\n             canceledRef.current = false;            // Clear cancellation flag\n             setCanRetry(false);                     // Disable retry until needed\n+            lastRetryableOperationRef.current = null;\n             lastUserMessageRef.current = content;   // Store for retry capability\n             \n             // Initialize stream lifecycle management\n             const streamController = initializeStream();\n@@ -519,14 +538,22 @@\n                     if (error instanceof Error) {\n                         markError(error);\n                         setErrorMessage(error.message);\n                         setCanRetry(true);\n+                        lastRetryableOperationRef.current = {\n+                            operationKey: sendOperationKey,\n+                            content,\n+                        };\n                         onError?.(error);\n                     } else {\n                         const wrappedError = new Error(String(error));\n                         markError(wrappedError);\n                         setErrorMessage(wrappedError.message);\n                         setCanRetry(true);\n+                        lastRetryableOperationRef.current = {\n+                            operationKey: sendOperationKey,\n+                            content,\n+                        };\n                         onError?.(wrappedError);\n                     }\n                 },\n                 onFallback,\n@@ -616,43 +643,50 @@\n      * response failed or was cut off. It cleans up the conversation history\n      * and resends the original message with fresh streaming state.\n      */\n     const retryLastMessage = useCallback(async () => {\n+        const retryableOperation = lastRetryableOperationRef.current;\n+\n         // Guard against invalid retry attempts\n-        if (!lastUserMessageRef.current || !canRetry) return;\n-        \n-        // Remove the failed assistant message from history\n-        setMessages((prev) => {\n-            if (prev.length >= 2 && prev[prev.length - 1].role === \"assistant\") {\n-                return prev.slice(0, -1);\n+        if (!lastUserMessageRef.current || !canRetry || !retryableOperation) return;\n+\n+        const retryOperationKey = createIdempotencyKey(\"chat-retry\", [\n+            retryableOperation.operationKey,\n+            retryableOperation.content,\n+        ]);\n+\n+        await retryOperationRegistryRef.current.run(retryOperationKey, async () => {\n+            const currentMessages = messagesRef.current;\n+            let nextMessages = [...currentMessages];\n+            let removedCount = 0;\n+\n+            if (nextMessages.length > 0 && nextMessages[nextMessages.length - 1].role === \"assistant\") {\n+                nextMessages = nextMessages.slice(0, -1);\n+                removedCount += 1;\n             }\n-            return prev;\n-        });\n-        setThinkingOutput((prev) => {\n-            if (prev.length >= 1) {\n-                return prev.slice(0, -1);\n-            }\n-            return prev;\n-        });\n \n-        // Remove the original user message (we'll resend it fresh)\n-        setMessages((prev) => {\n-            if (prev.length >= 1 && prev[prev.length - 1].role === \"user\") {\n-                return prev.slice(0, -1);\n+            const lastMessage = nextMessages[nextMessages.length - 1];\n+            if (\n+                lastMessage\n+                && lastMessage.role === \"user\"\n+                && typeof lastMessage.content === \"string\"\n+                && lastMessage.content === retryableOperation.content\n+            ) {\n+                nextMessages = nextMessages.slice(0, -1);\n+                removedCount += 1;\n             }\n-            return prev;\n-        });\n-        setThinkingOutput((prev) => {\n-            if (prev.length >= 1) {\n-                return prev.slice(0, -1);\n-            }\n-            return prev;\n-        });\n \n-        // Reset retry state and clear error message\n-        setCanRetry(false);\n-        setErrorMessage(null);\n-        await sendMessage(lastUserMessageRef.current);\n+            messagesRef.current = nextMessages;\n+            setMessages(nextMessages);\n+            setThinkingOutput((prev) => prev.slice(0, Math.max(0, prev.length - removedCount)));\n+\n+            // Reset retry state and clear error message\n+            setCanRetry(false);\n+            setErrorMessage(null);\n+            lastRetryableOperationRef.current = null;\n+\n+            await sendMessage(retryableOperation.content);\n+        });\n     }, [canRetry, sendMessage]);\n \n     // =============================================================================\n     // PUBLIC INTERFACE\n\n","files":[{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts","relativePath":"hooks/chat/useChat.ts","type":"update","diff":"Index: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n===================================================================\n--- /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n+++ /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n@@ -49,12 +49,21 @@\n import { useTitleGeneration } from \"./useTitleGeneration\";\n import { useChatStreaming } from \"./useChatStreaming\";\n import { useStreamLifecycle } from \"./useStreamLifecycle\";\n import type { UseChatOptions, StreamState } from \"@/types/chat.types\";\n-import { createSequenceGuard } from \"@/lib/concurrency\";\n+import {\n+    createIdempotencyKey,\n+    createIdempotencyRegistry,\n+    createSequenceGuard,\n+} from \"@/lib/concurrency\";\n \n type ChunkHandler = (chunk: string, accumulated: string) => void;\n \n+interface RetryableOperation {\n+    operationKey: string;\n+    content: string;\n+}\n+\n const DEFAULT_PLACEHOLDER_TEXT = \"...\";\n \n // =============================================================================\n // TYPE DEFINITIONS\n@@ -216,8 +225,10 @@\n     const [errorMessage, setErrorMessage] = useState<string | null>(null); // Error message for display\n     const canceledRef = useRef<boolean>(false);             // Track if streaming was canceled\n     const messagesRef = useRef<ModelMessage[]>(initialMessages);\n     const sendSequenceGuardRef = useRef(createSequenceGuard(`chat-send-${chatId ?? \"default\"}`));\n+    const retryOperationRegistryRef = useRef(createIdempotencyRegistry<void>());\n+    const lastRetryableOperationRef = useRef<RetryableOperation | null>(null);\n \n     useEffect(() => {\n         messagesRef.current = messages;\n     }, [messages]);\n@@ -358,8 +369,10 @@\n         failedProvidersRef.current = [];         // Clear failed providers list\n         lastUserMessageRef.current = null;       // Clear retry message\n         setCanRetry(false);                      // Disable retry capability\n         setErrorMessage(null);                   // Clear error message\n+        lastRetryableOperationRef.current = null;\n+        retryOperationRegistryRef.current.clear();\n     }, [effectiveProviderId, effectiveModelId, setTitle]);\n \n     /**\n      * Cancel the current streaming operation\n@@ -409,16 +422,22 @@\n             // Exit early if no valid content to send\n             if (!content) return;\n \n             const sendToken = sendSequenceGuardRef.current.next();\n+            const sendOperationKey = createIdempotencyKey(\"chat-send\", [\n+                chatId ?? \"default\",\n+                sendToken.sequence,\n+                content,\n+            ]);\n \n             // ────────────────────────────────────────────────────────────────\n             // STATE INITIALIZATION\n             // ────────────────────────────────────────────────────────────────\n             setIsStreaming(true);                    // Start streaming state\n             setIsThinking(false);                    // Reset thinking state\n             canceledRef.current = false;            // Clear cancellation flag\n             setCanRetry(false);                     // Disable retry until needed\n+            lastRetryableOperationRef.current = null;\n             lastUserMessageRef.current = content;   // Store for retry capability\n             \n             // Initialize stream lifecycle management\n             const streamController = initializeStream();\n@@ -519,14 +538,22 @@\n                     if (error instanceof Error) {\n                         markError(error);\n                         setErrorMessage(error.message);\n                         setCanRetry(true);\n+                        lastRetryableOperationRef.current = {\n+                            operationKey: sendOperationKey,\n+                            content,\n+                        };\n                         onError?.(error);\n                     } else {\n                         const wrappedError = new Error(String(error));\n                         markError(wrappedError);\n                         setErrorMessage(wrappedError.message);\n                         setCanRetry(true);\n+                        lastRetryableOperationRef.current = {\n+                            operationKey: sendOperationKey,\n+                            content,\n+                        };\n                         onError?.(wrappedError);\n                     }\n                 },\n                 onFallback,\n@@ -616,43 +643,50 @@\n      * response failed or was cut off. It cleans up the conversation history\n      * and resends the original message with fresh streaming state.\n      */\n     const retryLastMessage = useCallback(async () => {\n+        const retryableOperation = lastRetryableOperationRef.current;\n+\n         // Guard against invalid retry attempts\n-        if (!lastUserMessageRef.current || !canRetry) return;\n-        \n-        // Remove the failed assistant message from history\n-        setMessages((prev) => {\n-            if (prev.length >= 2 && prev[prev.length - 1].role === \"assistant\") {\n-                return prev.slice(0, -1);\n+        if (!lastUserMessageRef.current || !canRetry || !retryableOperation) return;\n+\n+        const retryOperationKey = createIdempotencyKey(\"chat-retry\", [\n+            retryableOperation.operationKey,\n+            retryableOperation.content,\n+        ]);\n+\n+        await retryOperationRegistryRef.current.run(retryOperationKey, async () => {\n+            const currentMessages = messagesRef.current;\n+            let nextMessages = [...currentMessages];\n+            let removedCount = 0;\n+\n+            if (nextMessages.length > 0 && nextMessages[nextMessages.length - 1].role === \"assistant\") {\n+                nextMessages = nextMessages.slice(0, -1);\n+                removedCount += 1;\n             }\n-            return prev;\n-        });\n-        setThinkingOutput((prev) => {\n-            if (prev.length >= 1) {\n-                return prev.slice(0, -1);\n-            }\n-            return prev;\n-        });\n \n-        // Remove the original user message (we'll resend it fresh)\n-        setMessages((prev) => {\n-            if (prev.length >= 1 && prev[prev.length - 1].role === \"user\") {\n-                return prev.slice(0, -1);\n+            const lastMessage = nextMessages[nextMessages.length - 1];\n+            if (\n+                lastMessage\n+                && lastMessage.role === \"user\"\n+                && typeof lastMessage.content === \"string\"\n+                && lastMessage.content === retryableOperation.content\n+            ) {\n+                nextMessages = nextMessages.slice(0, -1);\n+                removedCount += 1;\n             }\n-            return prev;\n-        });\n-        setThinkingOutput((prev) => {\n-            if (prev.length >= 1) {\n-                return prev.slice(0, -1);\n-            }\n-            return prev;\n-        });\n \n-        // Reset retry state and clear error message\n-        setCanRetry(false);\n-        setErrorMessage(null);\n-        await sendMessage(lastUserMessageRef.current);\n+            messagesRef.current = nextMessages;\n+            setMessages(nextMessages);\n+            setThinkingOutput((prev) => prev.slice(0, Math.max(0, prev.length - removedCount)));\n+\n+            // Reset retry state and clear error message\n+            setCanRetry(false);\n+            setErrorMessage(null);\n+            lastRetryableOperationRef.current = null;\n+\n+            await sendMessage(retryableOperation.content);\n+        });\n     }, [canRetry, sendMessage]);\n \n     // =============================================================================\n     // PUBLIC INTERFACE\n","before":"/**\n * @file useChat.ts\n * @purpose Main chat orchestrator with comprehensive state management\n * @connects-to useChatStreaming, useTitleGeneration, useChatState\n * \n * =============================================================================\n * COMPREHENSIVE HOOK OVERVIEW\n * =============================================================================\n * \n * useChat is the central hook that manages all chat functionality in the seabreeze\n * application. It orchestrates message handling, streaming responses, provider\n * management, fallback mechanisms, title generation, and error recovery.\n * \n * KEY RESPONSIBILITIES:\n * ────────────────────────────────────────────────────────────────────────\n * • Message state management (input text, message history)\n * • Streaming response handling with real-time updates\n * • AI provider and model management with fallback support\n * • Error handling with automatic retry mechanisms\n * • Chat title generation based on conversation content\n * • Persistent chat state across app sessions\n * \n * ARCHITECTURAL PATTERNS:\n * ────────────────────────────────────────────────────────────────────────\n * • Composition over inheritance - combines specialized hooks\n * • Unidirectional data flow - state flows down, actions flow up\n * • Immutable state updates - ensures React re-renders correctly\n * • Referential stability - uses useCallback/useMemo for performance\n * \n * PROVIDER ECOSYSTEM:\n * ────────────────────────────────────────────────────────────────────────\n * Supports Apple Intelligence, OpenAI, OpenRouter, and Ollama providers with:\n * • Automatic fallback on failures\n * • Model caching for performance\n * • Per-chat provider overrides\n * • Retry with exponential backoff\n * \n * =============================================================================\n */\n\nimport { useCallback, useState, useRef, useEffect, useMemo } from \"react\";\nimport type { LanguageModel, ModelMessage } from \"ai\";\nimport { ProviderId } from \"@/types/provider.types\";\nimport { getProviderModel } from \"@/providers/provider-factory\";\nimport { getCachedModel } from \"@/providers/provider-cache\";\nimport { type FallbackResult } from \"@/providers/fallback-chain\";\nimport { executeWithRetry, DEFAULT_RETRY_CONFIG, type RetryConfig } from \"@/hooks/useErrorRecovery\";\nimport { useChatState } from \"@/hooks/useChatState\";\nimport { useTitleGeneration } from \"./useTitleGeneration\";\nimport { useChatStreaming } from \"./useChatStreaming\";\nimport { useStreamLifecycle } from \"./useStreamLifecycle\";\nimport type { UseChatOptions, StreamState } from \"@/types/chat.types\";\nimport { createSequenceGuard } from \"@/lib/concurrency\";\n\ntype ChunkHandler = (chunk: string, accumulated: string) => void;\n\nconst DEFAULT_PLACEHOLDER_TEXT = \"...\";\n\n// =============================================================================\n// TYPE DEFINITIONS\n// =============================================================================\n// \n// These types define the public interface of the useChat hook, ensuring type\n// safety for all returned values and callbacks.\n\n/**\n * Return type for the useChat hook\n * \n * This interface defines all the values and functions that the hook exposes to\n * consuming components. Each property serves a specific purpose in the chat\n * interaction flow.\n */\nexport interface UseChatReturn {\n    /** Current input text in the chat field */\n    text: string;\n    /** Function to update the input text */\n    setText: (value: string) => void;\n    /** Array of all messages in the conversation */\n    messages: ModelMessage[];\n    /** Function to update the messages array */\n    setMessages: React.Dispatch<React.SetStateAction<ModelMessage[]>>;\n    /** Array of reasoning output aligned with messages */\n    thinkingOutput: string[];\n    /** Function to update the thinking output array */\n    setThinkingOutput: React.Dispatch<React.SetStateAction<string[]>>;\n    /** Whether the AI is currently streaming reasoning text */\n    isThinking: boolean;\n    /** Whether the AI is currently streaming a response */\n    isStreaming: boolean;\n    /** Current stream state for lifecycle tracking */\n    streamState: StreamState;\n    /** Send a message to the AI (optionally override current text) */\n    sendMessage: (overrideText?: string) => Promise<void>;\n    /** Cancel the current streaming response */\n    cancel: () => void;\n    /** Reset all chat state to initial values */\n    reset: () => void;\n    /** Current chat title (generated from conversation) */\n    title: string;\n    /** Function to update the chat title */\n    setTitle: (title: string) => void;\n    /** Generate a new title based on conversation content */\n    generateTitle: () => Promise<string>;\n    /** Currently active AI provider */\n    currentProvider: ProviderId;\n    /** Currently active model within the provider */\n    currentModel: string;\n    /** Whether we're currently using a fallback provider */\n    isUsingFallback: boolean;\n    /** Retry the last failed message */\n    retryLastMessage: () => Promise<void>;\n    /** Whether retry is available for the last message */\n    canRetry: boolean;\n    /** Error message for display when stream fails */\n    errorMessage: string | null;\n}\n\n// =============================================================================\n// MAIN HOOK IMPLEMENTATION\n// =============================================================================\n\n/**\n * Main useChat hook - orchestrates all chat functionality\n * \n * This hook serves as the central hub for chat operations, combining message\n * management, AI provider handling, streaming responses, and error recovery into\n * a cohesive interface.\n * \n * @param options - Configuration options for the chat instance\n * @returns Complete chat interface with state and actions\n */\nexport default function useChat(options: UseChatOptions = {}): UseChatReturn {\n    // =============================================================================\n    // OPTIONS DESTRUCTURING AND DEFAULTS\n    // =============================================================================\n    // \n    // Extract all options with sensible defaults. The hook is designed to work\n    // out-of-the-box with minimal configuration while allowing deep customization.\n    \n    const {\n        initialMessages = [],              // Start with empty message history\n        initialText = \"\",                  // Start with empty input field\n        placeholder = true,                // Enable placeholder for AI responses\n        providerId: legacyProviderId,      // Deprecated: use chatId instead\n        modelId: legacyModelId,           // Deprecated: use chatId instead\n        chatId,                           // Modern unified state management\n        model: providedModel,             // Direct model injection (testing)\n        onChunk,                          // Callback for streaming chunks\n        onThinkingChunk,                  // Callback for streaming thinking chunks\n        enableThinking = true,            // Enable thinking output updates\n        thinkingLevel,                    // Control reasoning effort when supported\n        onError,                          // Error handling callback\n        onComplete,                       // Completion callback\n        onFallback,                       // Provider fallback notification\n        enableFallback = true,            // Enable automatic fallback\n        enableRetry = true,               // Enable automatic retry\n        retryConfig = {},                 // Custom retry configuration\n    } = options;\n\n    // =============================================================================\n    // CHAT STATE MANAGEMENT\n    // =============================================================================\n    // \n    // Initialize chat state management. This handles both the new unified approach\n    // (using chatId) and legacy providerId/modelId for backward compatibility.\n    \n    const chatState = useChatState(chatId || null);\n    \n    // Resolve effective provider/model based on whether we're using unified state\n    // or legacy direct provider specification\n    const effectiveProviderId = chatId \n        ? chatState.provider                    // Use unified chat state\n        : (legacyProviderId || \"apple\");       // Fallback to legacy or default\n    const effectiveModelId = chatId \n        ? chatState.model                      // Use unified chat state  \n        : (legacyModelId || \"system-default\"); // Fallback to legacy or default\n\n    // =============================================================================\n    // CORE REACT STATE\n    // =============================================================================\n    // \n    // These are the fundamental React state variables that drive the chat interface.\n    // Each piece of state has a specific responsibility in the chat flow.\n    \n    const [text, setText] = useState<string>(initialText);           // Input field content\n    const [messages, setMessages] = useState<ModelMessage[]>(initialMessages); // Message history\n    const [thinkingOutput, setThinkingOutput] = useState<string[]>(\n        () => initialMessages.map(() => \"\")\n    );\n    const [isThinking, setIsThinking] = useState<boolean>(false);\n    const [isStreaming, setIsStreaming] = useState<boolean>(false);  // Streaming status\n    \n    // =============================================================================\n    // PROVIDER AND FALLBACK STATE\n    // =============================================================================\n    // \n    // These state variables manage the AI provider ecosystem, including fallback\n    // handling and provider switching during failures.\n    \n    const [activeProvider, setActiveProvider] = useState<ProviderId>(effectiveProviderId);\n    const [activeModel, setActiveModel] = useState<string>(effectiveModelId);\n    const [isUsingFallback, setIsUsingFallback] = useState<boolean>(false);\n    \n    // =============================================================================\n    // REFERENCES FOR STABLE OPERATIONS\n    // =============================================================================\n    // \n    // useRef values that persist across re-renders without triggering them.\n    // These are used for tracking operation state and maintaining data integrity.\n    \n    const failedProvidersRef = useRef<ProviderId[]>([]);     // Track failed providers for fallback\n    \n    // Retry and cancellation tracking\n    const lastUserMessageRef = useRef<string | null>(null); // Store last user message for retry\n    const [canRetry, setCanRetry] = useState<boolean>(false); // Whether retry is available\n    const [errorMessage, setErrorMessage] = useState<string | null>(null); // Error message for display\n    const canceledRef = useRef<boolean>(false);             // Track if streaming was canceled\n    const messagesRef = useRef<ModelMessage[]>(initialMessages);\n    const sendSequenceGuardRef = useRef(createSequenceGuard(`chat-send-${chatId ?? \"default\"}`));\n\n    useEffect(() => {\n        messagesRef.current = messages;\n    }, [messages]);\n\n    // =============================================================================\n    // CONFIGURATION MERGING\n    // =============================================================================\n    // \n    // Merge user-provided retry configuration with system defaults to create\n    // the final configuration used throughout the hook.\n    \n    const mergedRetryConfig: RetryConfig = { ...DEFAULT_RETRY_CONFIG, ...retryConfig };\n    const placeholderText = placeholder ? DEFAULT_PLACEHOLDER_TEXT : \"\";\n\n        // =============================================================================\n    // MODEL RESOLUTION AND CACHING\n    // =============================================================================\n    // \n    // Resolve the actual AI model to use for chat operations. This involves:\n    // 1. Using directly provided model (for testing/special cases)\n    // 2. Looking up cached model for performance\n    // 3. Creating new model instance if needed\n    // \n    // The useMemo ensures we only recompute when provider/model actually changes.\n    \n    const model: LanguageModel | null = useMemo(() => {\n        // Direct model injection takes precedence (useful for testing)\n        if (providedModel) {\n            return providedModel as LanguageModel;\n        }\n\n        // Try to get cached model for performance\n        const cachedModel = getCachedModel(\n            activeProvider,\n            activeModel,\n            () => getProviderModel(activeProvider, activeModel).model\n        );\n\n        return cachedModel || null;\n    }, [providedModel, activeProvider, activeModel]);\n\n    // =============================================================================\n    // TITLE GENERATION INTEGRATION\n    // =============================================================================\n    // \n    // Connect to the title generation subsystem. Titles are automatically\n    // generated based on conversation content and used for chat identification\n    // in the UI and database storage.\n    \n    const { title, setTitle, generateTitle } = useTitleGeneration(\n        messages.map(m => ({ role: m.role, content: typeof m.content === 'string' ? m.content : '' })),\n        model,\n        enableRetry,\n        mergedRetryConfig\n    );\n\n    // =============================================================================\n    // STREAMING INFRASTRUCTURE\n    // =============================================================================\n    // \n    // Connect to the streaming subsystem that handles real-time AI responses.\n    // This provides the core functionality for streaming text from AI providers.\n    \n    const { executeStreaming, handleStreamingError } = useChatStreaming();\n\n    // =============================================================================\n    // STREAM LIFECYCLE MANAGEMENT\n    // =============================================================================\n    // \n    // Manages stream state transitions, timeout detection, and cleanup.\n    // Ensures streams always complete fully and handles edge cases like\n    // app backgrounding and navigation away.\n    \n    const {\n        streamState,\n        isStreaming: isStreamLifecycleStreaming,\n        abortController,\n        initializeStream,\n        markChunkReceived,\n        markDoneSignalReceived,\n        markCompleting,\n        markCompleted,\n        markError,\n        cancelStream,\n    } = useStreamLifecycle({\n        timeoutMs: 30000, // 30 second fallback timeout\n        backgroundBehavior: \"cancel\",\n        enableLogging: __DEV__,\n        onError: (error) => {\n            console.error(\"[StreamLifecycle] Error:\", error.message);\n            onError?.(error);\n        },\n    });\n\n        // =============================================================================\n    // PROVIDER RESET EFFECT\n    // =============================================================================\n    // \n    // This effect ensures that when streaming completes (either successfully or\n    // with failure), we reset the provider state to the originally intended\n    // provider/model. This prevents fallback state from persisting between\n    // messages.\n    \n    useEffect(() => {\n        // Only reset when not actively streaming to avoid race conditions\n        if (!isStreaming) {\n            setActiveProvider(effectiveProviderId);\n            setActiveModel(effectiveModelId);\n            setIsUsingFallback(false);\n            failedProvidersRef.current = [];\n        }\n    }, [effectiveProviderId, effectiveModelId, isStreaming]);\n\n    // =============================================================================\n    // UTILITY FUNCTIONS\n    // =============================================================================\n    // \n    // Core utility functions that control chat state and flow. These are\n    // memoized with useCallback to maintain referential stability and prevent\n    // unnecessary re-renders in child components.\n\n    /**\n     * Reset all chat state to initial values\n     * \n     * This function completely clears the chat history, resets the input field,\n     * restores the original title, and resets all provider and fallback state.\n     * It's typically used when starting a new chat conversation.\n     */\n    const reset = useCallback(() => {\n        setText(\"\");                              // Clear input field\n        setMessages([]);                          // Clear message history\n        setThinkingOutput([]);                    // Clear reasoning output\n        setIsThinking(false);                     // Clear thinking state\n        setTitle(\"Chat\");                         // Reset to default title\n        setActiveProvider(effectiveProviderId);   // Reset to intended provider\n        setActiveModel(effectiveModelId);        // Reset to intended model\n        setIsUsingFallback(false);                // Clear fallback state\n        failedProvidersRef.current = [];         // Clear failed providers list\n        lastUserMessageRef.current = null;       // Clear retry message\n        setCanRetry(false);                      // Disable retry capability\n        setErrorMessage(null);                   // Clear error message\n    }, [effectiveProviderId, effectiveModelId, setTitle]);\n\n    /**\n     * Cancel the current streaming operation\n     *\n     * Sets a flag that the streaming loop checks to determine if it should\n     * stop processing chunks. This provides a clean way to interrupt AI responses.\n     */\n    const cancel = useCallback(() => {\n        canceledRef.current = true;\n        sendSequenceGuardRef.current.next();\n        setIsStreaming(false);\n        setIsThinking(false);\n        cancelStream(); // Use stream lifecycle cancel for comprehensive cancellation\n    }, [cancelStream]);\n\n        // =============================================================================\n    // CORE MESSAGE SENDING LOGIC\n    // =============================================================================\n    // \n    // This is the heart of the chat functionality. The sendMessage function:\n    // 1. Validates and prepares the user message\n    // 2. Updates the message history\n    // 3. Initiates streaming with the AI provider\n    // 4. Handles fallback and retry logic\n    // 5. Manages the complete message flow lifecycle\n\n    /**\n     * Send a message to the AI and initiate streaming response\n     * \n     * @param overrideText - Optional text to send instead of current input\n     * \n     * This function orchestrates the complete message sending flow:\n     * 1. Input validation and preprocessing\n     * 2. Message history updates\n     * 3. AI provider streaming initiation\n     * 4. Error handling with fallback mechanisms\n     * 5. Completion callbacks\n     */\n    const sendMessage = useCallback(\n        async (overrideText?: string) => {\n            // ────────────────────────────────────────────────────────────────\n            // INPUT VALIDATION AND PREPARATION\n            // ────────────────────────────────────────────────────────────────\n            const rawValue: unknown = overrideText ?? (text as unknown);\n            const content = typeof rawValue === \"string\" ? rawValue.trim() : \"\";\n            \n            // Exit early if no valid content to send\n            if (!content) return;\n\n            const sendToken = sendSequenceGuardRef.current.next();\n\n            // ────────────────────────────────────────────────────────────────\n            // STATE INITIALIZATION\n            // ────────────────────────────────────────────────────────────────\n            setIsStreaming(true);                    // Start streaming state\n            setIsThinking(false);                    // Reset thinking state\n            canceledRef.current = false;            // Clear cancellation flag\n            setCanRetry(false);                     // Disable retry until needed\n            lastUserMessageRef.current = content;   // Store for retry capability\n            \n            // Initialize stream lifecycle management\n            const streamController = initializeStream();\n            const abortSignal = streamController.signal;\n            const canMutateForCurrentSend = (): boolean => (\n                sendSequenceGuardRef.current.isCurrent(sendToken)\n                && !canceledRef.current\n                && !abortSignal.aborted\n            );\n\n            // ────────────────────────────────────────────────────────────────\n            // MESSAGE HISTORY MANAGEMENT\n            // ────────────────────────────────────────────────────────────────\n            const userMessage: ModelMessage = { role: \"user\", content };\n            const updatedMessages = [...messagesRef.current, userMessage];\n            setMessages(updatedMessages);\n            setThinkingOutput((prev) => [...prev, \"\"]);\n\n            // Clear input field if we're using the current text (not override)\n            if (overrideText === undefined) {\n                setText(\"\");\n            }\n\n            // Add placeholder for assistant response\n            const assistantIndex = updatedMessages.length;\n            setMessages((prev) => [\n                ...prev,\n                {\n                    role: \"assistant\",\n                    content: placeholderText,\n                },\n            ]);\n            setThinkingOutput((prev) => [...prev, \"\"]);\n\n            // ────────────────────────────────────────────────────────────────\n            // MODEL VALIDATION\n            // ────────────────────────────────────────────────────────────────\n            if (!model) {\n                // Show helpful error message when no provider is configured\n                setMessages((prev) => {\n                    const next = [...prev];\n                    next[assistantIndex] = {\n                        role: \"assistant\",\n                        content: \"**Setup Required**\\n\\nNo AI provider configured. Please set up a provider in settings.\\n\\n*Go to Settings to configure an AI provider.*\",\n                    };\n                    return next;\n                });\n                \n                onError?.(new Error(\"No AI provider configured\"));\n                setIsStreaming(false);\n                setIsThinking(false);\n                onComplete?.();\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // STREAMING CONFIGURATION\n            // ────────────────────────────────────────────────────────────────\n            const handleThinkingChunk = enableThinking\n                ? (chunk: string, accumulated: string) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    setIsThinking(true);\n                    setThinkingOutput((prev) => {\n                        const next = [...prev];\n                        next[assistantIndex] = accumulated;\n                        return next;\n                    });\n                    onThinkingChunk?.(chunk, accumulated);\n                }\n                : undefined;\n\n            const streamingOptions = {\n                model: {\n                    model,\n                    provider: activeProvider,\n                    modelId: activeModel,\n                    isOriginal: !isUsingFallback,\n                    attemptedProviders: failedProvidersRef.current,\n                } as FallbackResult,\n                enableRetry,\n                retryConfig: mergedRetryConfig,\n                enableFallback,\n                activeProvider,\n                effectiveProviderId,\n                thinkingLevel,\n                abortSignal,\n                onChunk,\n                onThinkingChunk: handleThinkingChunk,\n                canMutateState: canMutateForCurrentSend,\n                onError: (error: unknown) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    if (error instanceof Error) {\n                        markError(error);\n                        setErrorMessage(error.message);\n                        setCanRetry(true);\n                        onError?.(error);\n                    } else {\n                        const wrappedError = new Error(String(error));\n                        markError(wrappedError);\n                        setErrorMessage(wrappedError.message);\n                        setCanRetry(true);\n                        onError?.(wrappedError);\n                    }\n                },\n                onFallback,\n                onProviderChange: (provider: ProviderId, model: string, isFallback: boolean) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    setActiveProvider(provider);\n                    setActiveModel(model);\n                    setIsUsingFallback(isFallback);\n                },\n            };\n\n            // ────────────────────────────────────────────────────────────────\n            // STREAMING EXECUTION\n            // ────────────────────────────────────────────────────────────────\n            const result = await executeStreaming(\n                streamingOptions,\n                updatedMessages,\n                setMessages,\n                assistantIndex,\n                failedProvidersRef\n            );\n\n            if (!sendSequenceGuardRef.current.isCurrent(sendToken)) {\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // FALLBACK RETRY LOGIC\n            // ────────────────────────────────────────────────────────────────\n            if (result.shouldRetryWithFallback && !canceledRef.current) {\n                setIsStreaming(false);\n                setIsThinking(false);\n                // Small delay to ensure clean state transition\n                await new Promise(resolve => setTimeout(resolve, 100));\n                await sendMessage(content);\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // COMPLETION\n            // ────────────────────────────────────────────────────────────────\n            if (canMutateForCurrentSend()) {\n                setIsStreaming(false);\n                setIsThinking(false);\n                onComplete?.();\n            }\n        },\n        [\n            text, \n            placeholderText, \n            model, \n            activeProvider, \n            activeModel, \n            isUsingFallback,\n            enableRetry, \n            mergedRetryConfig,\n            executeStreaming,\n            onChunk, \n            onThinkingChunk,\n            onComplete, \n            onError, \n            onFallback,\n            effectiveProviderId,\n            enableThinking,\n            thinkingLevel,\n            onThinkingChunk\n        ],\n    );\n\n        // =============================================================================\n    // RETRY FUNCTIONALITY\n    // =============================================================================\n    // \n    // Retry functionality allows users to resend their last message when the\n    // AI response failed or was incomplete. This involves:\n    // 1. Removing the failed assistant response\n    // 2. Optionally removing the user message (if they want to edit)\n    // 3. Resending the original message with fresh state\n\n    /**\n     * Retry the last failed message\n     * \n     * This function enables users to retry their last message when the AI\n     * response failed or was cut off. It cleans up the conversation history\n     * and resends the original message with fresh streaming state.\n     */\n    const retryLastMessage = useCallback(async () => {\n        // Guard against invalid retry attempts\n        if (!lastUserMessageRef.current || !canRetry) return;\n        \n        // Remove the failed assistant message from history\n        setMessages((prev) => {\n            if (prev.length >= 2 && prev[prev.length - 1].role === \"assistant\") {\n                return prev.slice(0, -1);\n            }\n            return prev;\n        });\n        setThinkingOutput((prev) => {\n            if (prev.length >= 1) {\n                return prev.slice(0, -1);\n            }\n            return prev;\n        });\n\n        // Remove the original user message (we'll resend it fresh)\n        setMessages((prev) => {\n            if (prev.length >= 1 && prev[prev.length - 1].role === \"user\") {\n                return prev.slice(0, -1);\n            }\n            return prev;\n        });\n        setThinkingOutput((prev) => {\n            if (prev.length >= 1) {\n                return prev.slice(0, -1);\n            }\n            return prev;\n        });\n\n        // Reset retry state and clear error message\n        setCanRetry(false);\n        setErrorMessage(null);\n        await sendMessage(lastUserMessageRef.current);\n    }, [canRetry, sendMessage]);\n\n    // =============================================================================\n    // PUBLIC INTERFACE\n    // =============================================================================\n    // \n    // Return the complete chat interface. All values are stable references\n    // where appropriate to prevent unnecessary re-renders in consuming components.\n    // The interface provides both state accessors and action functions.\n\n    return {\n        // ────────────────────────────────────────────────────────────────\n        // CORE CHAT STATE\n        // ────────────────────────────────────────────────────────────────\n        text,                           // Current input text\n        setText,                        // Update input text\n        messages,                       // Message history\n        setMessages,                    // Update message history\n        thinkingOutput,                 // Reasoning output\n        setThinkingOutput,              // Update reasoning output\n        isThinking,                     // Thinking status\n        isStreaming,                    // Streaming status\n        streamState,                    // Stream lifecycle state (streaming | completing | completed | error)\n\n        // ────────────────────────────────────────────────────────────────\n        // ACTIONS\n        // ────────────────────────────────────────────────────────────────\n        sendMessage,                    // Send message\n        cancel,                         // Cancel streaming\n        reset,                          // Reset all state\n\n        // ────────────────────────────────────────────────────────────────\n        // TITLE MANAGEMENT\n        // ────────────────────────────────────────────────────────────────\n        title,                          // Current title\n        setTitle,                       // Update title\n        generateTitle,                  // Generate new title\n\n        // ────────────────────────────────────────────────────────────────\n        // PROVIDER STATE\n        // ────────────────────────────────────────────────────────────────\n        currentProvider: activeProvider, // Active AI provider\n        currentModel: activeModel,      // Active model\n        isUsingFallback,                // Fallback status\n\n        // ────────────────────────────────────────────────────────────────\n        // RETRY FUNCTIONALITY\n        // ────────────────────────────────────────────────────────────────\n        retryLastMessage,               // Retry last message\n        canRetry,                       // Whether retry is available\n        errorMessage,                   // Error message for display\n    };\n}\n\n/*\n * =============================================================================\n * HOOK COMPREHENSIVE DOCUMENTATION\n * =============================================================================\n * \n * ARCHITECTURAL SUMMARY:\n * ────────────────────────────────────────────────────────────────────────\n * useChat is a sophisticated hook that combines multiple concerns into a\n * cohesive chat interface. It follows the composition pattern, building upon\n * specialized hooks for different aspects of chat functionality.\n * \n * KEY PRINCIPLES:\n * ────────────────────────────────────────────────────────────────────────\n * 1. Separation of Concerns: Different aspects (streaming, title generation,\n *    state management) are handled by dedicated hooks\n * 2. Referential Stability: useCallback and useMemo prevent unnecessary re-renders\n * 3. Unidirectional Data Flow: State flows down, actions flow up\n * 4. Error Resilience: Multiple layers of error handling and fallback\n * 5. Performance Optimization: Caching, memoization, and efficient updates\n * \n * PROVIDER ECOSYSTEM INTEGRATION:\n * ────────────────────────────────────────────────────────────────────────\n * The hook integrates with a robust provider system that supports:\n * • Multiple AI providers (Apple, OpenAI, OpenRouter, Ollama)\n * • Automatic fallback on failures\n * • Model caching for performance\n * • Per-chat provider overrides\n * • Retry with exponential backoff\n * \n * STATE MANAGEMENT STRATEGY:\n * ────────────────────────────────────────────────────────────────────────\n * • Local React state for immediate UI updates\n * • Zustand stores for persistent data\n * • Refs for operation tracking without re-renders\n * • Unified chat state system for consistency\n * \n * ERROR HANDLING APPROACH:\n * ────────────────────────────────────────────────────────────────────────\n * • Graceful degradation when providers fail\n * • User-friendly error messages\n * • Automatic retry with configurable backoff\n * • Fallback chain through multiple providers\n * • Recovery mechanisms for common failure scenarios\n * \n * PERFORMANCE OPTIMIZATIONS:\n * ────────────────────────────────────────────────────────────────────────\n * • Model caching to avoid repeated initialization\n * • Memoized callbacks to prevent child re-renders\n * • Efficient state updates with minimal re-renders\n * • Lazy loading of provider resources\n * • Streaming to provide immediate feedback\n * \n * =============================================================================\n */\n","after":"/**\n * @file useChat.ts\n * @purpose Main chat orchestrator with comprehensive state management\n * @connects-to useChatStreaming, useTitleGeneration, useChatState\n * \n * =============================================================================\n * COMPREHENSIVE HOOK OVERVIEW\n * =============================================================================\n * \n * useChat is the central hook that manages all chat functionality in the seabreeze\n * application. It orchestrates message handling, streaming responses, provider\n * management, fallback mechanisms, title generation, and error recovery.\n * \n * KEY RESPONSIBILITIES:\n * ────────────────────────────────────────────────────────────────────────\n * • Message state management (input text, message history)\n * • Streaming response handling with real-time updates\n * • AI provider and model management with fallback support\n * • Error handling with automatic retry mechanisms\n * • Chat title generation based on conversation content\n * • Persistent chat state across app sessions\n * \n * ARCHITECTURAL PATTERNS:\n * ────────────────────────────────────────────────────────────────────────\n * • Composition over inheritance - combines specialized hooks\n * • Unidirectional data flow - state flows down, actions flow up\n * • Immutable state updates - ensures React re-renders correctly\n * • Referential stability - uses useCallback/useMemo for performance\n * \n * PROVIDER ECOSYSTEM:\n * ────────────────────────────────────────────────────────────────────────\n * Supports Apple Intelligence, OpenAI, OpenRouter, and Ollama providers with:\n * • Automatic fallback on failures\n * • Model caching for performance\n * • Per-chat provider overrides\n * • Retry with exponential backoff\n * \n * =============================================================================\n */\n\nimport { useCallback, useState, useRef, useEffect, useMemo } from \"react\";\nimport type { LanguageModel, ModelMessage } from \"ai\";\nimport { ProviderId } from \"@/types/provider.types\";\nimport { getProviderModel } from \"@/providers/provider-factory\";\nimport { getCachedModel } from \"@/providers/provider-cache\";\nimport { type FallbackResult } from \"@/providers/fallback-chain\";\nimport { executeWithRetry, DEFAULT_RETRY_CONFIG, type RetryConfig } from \"@/hooks/useErrorRecovery\";\nimport { useChatState } from \"@/hooks/useChatState\";\nimport { useTitleGeneration } from \"./useTitleGeneration\";\nimport { useChatStreaming } from \"./useChatStreaming\";\nimport { useStreamLifecycle } from \"./useStreamLifecycle\";\nimport type { UseChatOptions, StreamState } from \"@/types/chat.types\";\nimport {\n    createIdempotencyKey,\n    createIdempotencyRegistry,\n    createSequenceGuard,\n} from \"@/lib/concurrency\";\n\ntype ChunkHandler = (chunk: string, accumulated: string) => void;\n\ninterface RetryableOperation {\n    operationKey: string;\n    content: string;\n}\n\nconst DEFAULT_PLACEHOLDER_TEXT = \"...\";\n\n// =============================================================================\n// TYPE DEFINITIONS\n// =============================================================================\n// \n// These types define the public interface of the useChat hook, ensuring type\n// safety for all returned values and callbacks.\n\n/**\n * Return type for the useChat hook\n * \n * This interface defines all the values and functions that the hook exposes to\n * consuming components. Each property serves a specific purpose in the chat\n * interaction flow.\n */\nexport interface UseChatReturn {\n    /** Current input text in the chat field */\n    text: string;\n    /** Function to update the input text */\n    setText: (value: string) => void;\n    /** Array of all messages in the conversation */\n    messages: ModelMessage[];\n    /** Function to update the messages array */\n    setMessages: React.Dispatch<React.SetStateAction<ModelMessage[]>>;\n    /** Array of reasoning output aligned with messages */\n    thinkingOutput: string[];\n    /** Function to update the thinking output array */\n    setThinkingOutput: React.Dispatch<React.SetStateAction<string[]>>;\n    /** Whether the AI is currently streaming reasoning text */\n    isThinking: boolean;\n    /** Whether the AI is currently streaming a response */\n    isStreaming: boolean;\n    /** Current stream state for lifecycle tracking */\n    streamState: StreamState;\n    /** Send a message to the AI (optionally override current text) */\n    sendMessage: (overrideText?: string) => Promise<void>;\n    /** Cancel the current streaming response */\n    cancel: () => void;\n    /** Reset all chat state to initial values */\n    reset: () => void;\n    /** Current chat title (generated from conversation) */\n    title: string;\n    /** Function to update the chat title */\n    setTitle: (title: string) => void;\n    /** Generate a new title based on conversation content */\n    generateTitle: () => Promise<string>;\n    /** Currently active AI provider */\n    currentProvider: ProviderId;\n    /** Currently active model within the provider */\n    currentModel: string;\n    /** Whether we're currently using a fallback provider */\n    isUsingFallback: boolean;\n    /** Retry the last failed message */\n    retryLastMessage: () => Promise<void>;\n    /** Whether retry is available for the last message */\n    canRetry: boolean;\n    /** Error message for display when stream fails */\n    errorMessage: string | null;\n}\n\n// =============================================================================\n// MAIN HOOK IMPLEMENTATION\n// =============================================================================\n\n/**\n * Main useChat hook - orchestrates all chat functionality\n * \n * This hook serves as the central hub for chat operations, combining message\n * management, AI provider handling, streaming responses, and error recovery into\n * a cohesive interface.\n * \n * @param options - Configuration options for the chat instance\n * @returns Complete chat interface with state and actions\n */\nexport default function useChat(options: UseChatOptions = {}): UseChatReturn {\n    // =============================================================================\n    // OPTIONS DESTRUCTURING AND DEFAULTS\n    // =============================================================================\n    // \n    // Extract all options with sensible defaults. The hook is designed to work\n    // out-of-the-box with minimal configuration while allowing deep customization.\n    \n    const {\n        initialMessages = [],              // Start with empty message history\n        initialText = \"\",                  // Start with empty input field\n        placeholder = true,                // Enable placeholder for AI responses\n        providerId: legacyProviderId,      // Deprecated: use chatId instead\n        modelId: legacyModelId,           // Deprecated: use chatId instead\n        chatId,                           // Modern unified state management\n        model: providedModel,             // Direct model injection (testing)\n        onChunk,                          // Callback for streaming chunks\n        onThinkingChunk,                  // Callback for streaming thinking chunks\n        enableThinking = true,            // Enable thinking output updates\n        thinkingLevel,                    // Control reasoning effort when supported\n        onError,                          // Error handling callback\n        onComplete,                       // Completion callback\n        onFallback,                       // Provider fallback notification\n        enableFallback = true,            // Enable automatic fallback\n        enableRetry = true,               // Enable automatic retry\n        retryConfig = {},                 // Custom retry configuration\n    } = options;\n\n    // =============================================================================\n    // CHAT STATE MANAGEMENT\n    // =============================================================================\n    // \n    // Initialize chat state management. This handles both the new unified approach\n    // (using chatId) and legacy providerId/modelId for backward compatibility.\n    \n    const chatState = useChatState(chatId || null);\n    \n    // Resolve effective provider/model based on whether we're using unified state\n    // or legacy direct provider specification\n    const effectiveProviderId = chatId \n        ? chatState.provider                    // Use unified chat state\n        : (legacyProviderId || \"apple\");       // Fallback to legacy or default\n    const effectiveModelId = chatId \n        ? chatState.model                      // Use unified chat state  \n        : (legacyModelId || \"system-default\"); // Fallback to legacy or default\n\n    // =============================================================================\n    // CORE REACT STATE\n    // =============================================================================\n    // \n    // These are the fundamental React state variables that drive the chat interface.\n    // Each piece of state has a specific responsibility in the chat flow.\n    \n    const [text, setText] = useState<string>(initialText);           // Input field content\n    const [messages, setMessages] = useState<ModelMessage[]>(initialMessages); // Message history\n    const [thinkingOutput, setThinkingOutput] = useState<string[]>(\n        () => initialMessages.map(() => \"\")\n    );\n    const [isThinking, setIsThinking] = useState<boolean>(false);\n    const [isStreaming, setIsStreaming] = useState<boolean>(false);  // Streaming status\n    \n    // =============================================================================\n    // PROVIDER AND FALLBACK STATE\n    // =============================================================================\n    // \n    // These state variables manage the AI provider ecosystem, including fallback\n    // handling and provider switching during failures.\n    \n    const [activeProvider, setActiveProvider] = useState<ProviderId>(effectiveProviderId);\n    const [activeModel, setActiveModel] = useState<string>(effectiveModelId);\n    const [isUsingFallback, setIsUsingFallback] = useState<boolean>(false);\n    \n    // =============================================================================\n    // REFERENCES FOR STABLE OPERATIONS\n    // =============================================================================\n    // \n    // useRef values that persist across re-renders without triggering them.\n    // These are used for tracking operation state and maintaining data integrity.\n    \n    const failedProvidersRef = useRef<ProviderId[]>([]);     // Track failed providers for fallback\n    \n    // Retry and cancellation tracking\n    const lastUserMessageRef = useRef<string | null>(null); // Store last user message for retry\n    const [canRetry, setCanRetry] = useState<boolean>(false); // Whether retry is available\n    const [errorMessage, setErrorMessage] = useState<string | null>(null); // Error message for display\n    const canceledRef = useRef<boolean>(false);             // Track if streaming was canceled\n    const messagesRef = useRef<ModelMessage[]>(initialMessages);\n    const sendSequenceGuardRef = useRef(createSequenceGuard(`chat-send-${chatId ?? \"default\"}`));\n    const retryOperationRegistryRef = useRef(createIdempotencyRegistry<void>());\n    const lastRetryableOperationRef = useRef<RetryableOperation | null>(null);\n\n    useEffect(() => {\n        messagesRef.current = messages;\n    }, [messages]);\n\n    // =============================================================================\n    // CONFIGURATION MERGING\n    // =============================================================================\n    // \n    // Merge user-provided retry configuration with system defaults to create\n    // the final configuration used throughout the hook.\n    \n    const mergedRetryConfig: RetryConfig = { ...DEFAULT_RETRY_CONFIG, ...retryConfig };\n    const placeholderText = placeholder ? DEFAULT_PLACEHOLDER_TEXT : \"\";\n\n        // =============================================================================\n    // MODEL RESOLUTION AND CACHING\n    // =============================================================================\n    // \n    // Resolve the actual AI model to use for chat operations. This involves:\n    // 1. Using directly provided model (for testing/special cases)\n    // 2. Looking up cached model for performance\n    // 3. Creating new model instance if needed\n    // \n    // The useMemo ensures we only recompute when provider/model actually changes.\n    \n    const model: LanguageModel | null = useMemo(() => {\n        // Direct model injection takes precedence (useful for testing)\n        if (providedModel) {\n            return providedModel as LanguageModel;\n        }\n\n        // Try to get cached model for performance\n        const cachedModel = getCachedModel(\n            activeProvider,\n            activeModel,\n            () => getProviderModel(activeProvider, activeModel).model\n        );\n\n        return cachedModel || null;\n    }, [providedModel, activeProvider, activeModel]);\n\n    // =============================================================================\n    // TITLE GENERATION INTEGRATION\n    // =============================================================================\n    // \n    // Connect to the title generation subsystem. Titles are automatically\n    // generated based on conversation content and used for chat identification\n    // in the UI and database storage.\n    \n    const { title, setTitle, generateTitle } = useTitleGeneration(\n        messages.map(m => ({ role: m.role, content: typeof m.content === 'string' ? m.content : '' })),\n        model,\n        enableRetry,\n        mergedRetryConfig\n    );\n\n    // =============================================================================\n    // STREAMING INFRASTRUCTURE\n    // =============================================================================\n    // \n    // Connect to the streaming subsystem that handles real-time AI responses.\n    // This provides the core functionality for streaming text from AI providers.\n    \n    const { executeStreaming, handleStreamingError } = useChatStreaming();\n\n    // =============================================================================\n    // STREAM LIFECYCLE MANAGEMENT\n    // =============================================================================\n    // \n    // Manages stream state transitions, timeout detection, and cleanup.\n    // Ensures streams always complete fully and handles edge cases like\n    // app backgrounding and navigation away.\n    \n    const {\n        streamState,\n        isStreaming: isStreamLifecycleStreaming,\n        abortController,\n        initializeStream,\n        markChunkReceived,\n        markDoneSignalReceived,\n        markCompleting,\n        markCompleted,\n        markError,\n        cancelStream,\n    } = useStreamLifecycle({\n        timeoutMs: 30000, // 30 second fallback timeout\n        backgroundBehavior: \"cancel\",\n        enableLogging: __DEV__,\n        onError: (error) => {\n            console.error(\"[StreamLifecycle] Error:\", error.message);\n            onError?.(error);\n        },\n    });\n\n        // =============================================================================\n    // PROVIDER RESET EFFECT\n    // =============================================================================\n    // \n    // This effect ensures that when streaming completes (either successfully or\n    // with failure), we reset the provider state to the originally intended\n    // provider/model. This prevents fallback state from persisting between\n    // messages.\n    \n    useEffect(() => {\n        // Only reset when not actively streaming to avoid race conditions\n        if (!isStreaming) {\n            setActiveProvider(effectiveProviderId);\n            setActiveModel(effectiveModelId);\n            setIsUsingFallback(false);\n            failedProvidersRef.current = [];\n        }\n    }, [effectiveProviderId, effectiveModelId, isStreaming]);\n\n    // =============================================================================\n    // UTILITY FUNCTIONS\n    // =============================================================================\n    // \n    // Core utility functions that control chat state and flow. These are\n    // memoized with useCallback to maintain referential stability and prevent\n    // unnecessary re-renders in child components.\n\n    /**\n     * Reset all chat state to initial values\n     * \n     * This function completely clears the chat history, resets the input field,\n     * restores the original title, and resets all provider and fallback state.\n     * It's typically used when starting a new chat conversation.\n     */\n    const reset = useCallback(() => {\n        setText(\"\");                              // Clear input field\n        setMessages([]);                          // Clear message history\n        setThinkingOutput([]);                    // Clear reasoning output\n        setIsThinking(false);                     // Clear thinking state\n        setTitle(\"Chat\");                         // Reset to default title\n        setActiveProvider(effectiveProviderId);   // Reset to intended provider\n        setActiveModel(effectiveModelId);        // Reset to intended model\n        setIsUsingFallback(false);                // Clear fallback state\n        failedProvidersRef.current = [];         // Clear failed providers list\n        lastUserMessageRef.current = null;       // Clear retry message\n        setCanRetry(false);                      // Disable retry capability\n        setErrorMessage(null);                   // Clear error message\n        lastRetryableOperationRef.current = null;\n        retryOperationRegistryRef.current.clear();\n    }, [effectiveProviderId, effectiveModelId, setTitle]);\n\n    /**\n     * Cancel the current streaming operation\n     *\n     * Sets a flag that the streaming loop checks to determine if it should\n     * stop processing chunks. This provides a clean way to interrupt AI responses.\n     */\n    const cancel = useCallback(() => {\n        canceledRef.current = true;\n        sendSequenceGuardRef.current.next();\n        setIsStreaming(false);\n        setIsThinking(false);\n        cancelStream(); // Use stream lifecycle cancel for comprehensive cancellation\n    }, [cancelStream]);\n\n        // =============================================================================\n    // CORE MESSAGE SENDING LOGIC\n    // =============================================================================\n    // \n    // This is the heart of the chat functionality. The sendMessage function:\n    // 1. Validates and prepares the user message\n    // 2. Updates the message history\n    // 3. Initiates streaming with the AI provider\n    // 4. Handles fallback and retry logic\n    // 5. Manages the complete message flow lifecycle\n\n    /**\n     * Send a message to the AI and initiate streaming response\n     * \n     * @param overrideText - Optional text to send instead of current input\n     * \n     * This function orchestrates the complete message sending flow:\n     * 1. Input validation and preprocessing\n     * 2. Message history updates\n     * 3. AI provider streaming initiation\n     * 4. Error handling with fallback mechanisms\n     * 5. Completion callbacks\n     */\n    const sendMessage = useCallback(\n        async (overrideText?: string) => {\n            // ────────────────────────────────────────────────────────────────\n            // INPUT VALIDATION AND PREPARATION\n            // ────────────────────────────────────────────────────────────────\n            const rawValue: unknown = overrideText ?? (text as unknown);\n            const content = typeof rawValue === \"string\" ? rawValue.trim() : \"\";\n            \n            // Exit early if no valid content to send\n            if (!content) return;\n\n            const sendToken = sendSequenceGuardRef.current.next();\n            const sendOperationKey = createIdempotencyKey(\"chat-send\", [\n                chatId ?? \"default\",\n                sendToken.sequence,\n                content,\n            ]);\n\n            // ────────────────────────────────────────────────────────────────\n            // STATE INITIALIZATION\n            // ────────────────────────────────────────────────────────────────\n            setIsStreaming(true);                    // Start streaming state\n            setIsThinking(false);                    // Reset thinking state\n            canceledRef.current = false;            // Clear cancellation flag\n            setCanRetry(false);                     // Disable retry until needed\n            lastRetryableOperationRef.current = null;\n            lastUserMessageRef.current = content;   // Store for retry capability\n            \n            // Initialize stream lifecycle management\n            const streamController = initializeStream();\n            const abortSignal = streamController.signal;\n            const canMutateForCurrentSend = (): boolean => (\n                sendSequenceGuardRef.current.isCurrent(sendToken)\n                && !canceledRef.current\n                && !abortSignal.aborted\n            );\n\n            // ────────────────────────────────────────────────────────────────\n            // MESSAGE HISTORY MANAGEMENT\n            // ────────────────────────────────────────────────────────────────\n            const userMessage: ModelMessage = { role: \"user\", content };\n            const updatedMessages = [...messagesRef.current, userMessage];\n            setMessages(updatedMessages);\n            setThinkingOutput((prev) => [...prev, \"\"]);\n\n            // Clear input field if we're using the current text (not override)\n            if (overrideText === undefined) {\n                setText(\"\");\n            }\n\n            // Add placeholder for assistant response\n            const assistantIndex = updatedMessages.length;\n            setMessages((prev) => [\n                ...prev,\n                {\n                    role: \"assistant\",\n                    content: placeholderText,\n                },\n            ]);\n            setThinkingOutput((prev) => [...prev, \"\"]);\n\n            // ────────────────────────────────────────────────────────────────\n            // MODEL VALIDATION\n            // ────────────────────────────────────────────────────────────────\n            if (!model) {\n                // Show helpful error message when no provider is configured\n                setMessages((prev) => {\n                    const next = [...prev];\n                    next[assistantIndex] = {\n                        role: \"assistant\",\n                        content: \"**Setup Required**\\n\\nNo AI provider configured. Please set up a provider in settings.\\n\\n*Go to Settings to configure an AI provider.*\",\n                    };\n                    return next;\n                });\n                \n                onError?.(new Error(\"No AI provider configured\"));\n                setIsStreaming(false);\n                setIsThinking(false);\n                onComplete?.();\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // STREAMING CONFIGURATION\n            // ────────────────────────────────────────────────────────────────\n            const handleThinkingChunk = enableThinking\n                ? (chunk: string, accumulated: string) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    setIsThinking(true);\n                    setThinkingOutput((prev) => {\n                        const next = [...prev];\n                        next[assistantIndex] = accumulated;\n                        return next;\n                    });\n                    onThinkingChunk?.(chunk, accumulated);\n                }\n                : undefined;\n\n            const streamingOptions = {\n                model: {\n                    model,\n                    provider: activeProvider,\n                    modelId: activeModel,\n                    isOriginal: !isUsingFallback,\n                    attemptedProviders: failedProvidersRef.current,\n                } as FallbackResult,\n                enableRetry,\n                retryConfig: mergedRetryConfig,\n                enableFallback,\n                activeProvider,\n                effectiveProviderId,\n                thinkingLevel,\n                abortSignal,\n                onChunk,\n                onThinkingChunk: handleThinkingChunk,\n                canMutateState: canMutateForCurrentSend,\n                onError: (error: unknown) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    if (error instanceof Error) {\n                        markError(error);\n                        setErrorMessage(error.message);\n                        setCanRetry(true);\n                        lastRetryableOperationRef.current = {\n                            operationKey: sendOperationKey,\n                            content,\n                        };\n                        onError?.(error);\n                    } else {\n                        const wrappedError = new Error(String(error));\n                        markError(wrappedError);\n                        setErrorMessage(wrappedError.message);\n                        setCanRetry(true);\n                        lastRetryableOperationRef.current = {\n                            operationKey: sendOperationKey,\n                            content,\n                        };\n                        onError?.(wrappedError);\n                    }\n                },\n                onFallback,\n                onProviderChange: (provider: ProviderId, model: string, isFallback: boolean) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    setActiveProvider(provider);\n                    setActiveModel(model);\n                    setIsUsingFallback(isFallback);\n                },\n            };\n\n            // ────────────────────────────────────────────────────────────────\n            // STREAMING EXECUTION\n            // ────────────────────────────────────────────────────────────────\n            const result = await executeStreaming(\n                streamingOptions,\n                updatedMessages,\n                setMessages,\n                assistantIndex,\n                failedProvidersRef\n            );\n\n            if (!sendSequenceGuardRef.current.isCurrent(sendToken)) {\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // FALLBACK RETRY LOGIC\n            // ────────────────────────────────────────────────────────────────\n            if (result.shouldRetryWithFallback && !canceledRef.current) {\n                setIsStreaming(false);\n                setIsThinking(false);\n                // Small delay to ensure clean state transition\n                await new Promise(resolve => setTimeout(resolve, 100));\n                await sendMessage(content);\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // COMPLETION\n            // ────────────────────────────────────────────────────────────────\n            if (canMutateForCurrentSend()) {\n                setIsStreaming(false);\n                setIsThinking(false);\n                onComplete?.();\n            }\n        },\n        [\n            text, \n            placeholderText, \n            model, \n            activeProvider, \n            activeModel, \n            isUsingFallback,\n            enableRetry, \n            mergedRetryConfig,\n            executeStreaming,\n            onChunk, \n            onThinkingChunk,\n            onComplete, \n            onError, \n            onFallback,\n            effectiveProviderId,\n            enableThinking,\n            thinkingLevel,\n            onThinkingChunk\n        ],\n    );\n\n        // =============================================================================\n    // RETRY FUNCTIONALITY\n    // =============================================================================\n    // \n    // Retry functionality allows users to resend their last message when the\n    // AI response failed or was incomplete. This involves:\n    // 1. Removing the failed assistant response\n    // 2. Optionally removing the user message (if they want to edit)\n    // 3. Resending the original message with fresh state\n\n    /**\n     * Retry the last failed message\n     * \n     * This function enables users to retry their last message when the AI\n     * response failed or was cut off. It cleans up the conversation history\n     * and resends the original message with fresh streaming state.\n     */\n    const retryLastMessage = useCallback(async () => {\n        const retryableOperation = lastRetryableOperationRef.current;\n\n        // Guard against invalid retry attempts\n        if (!lastUserMessageRef.current || !canRetry || !retryableOperation) return;\n\n        const retryOperationKey = createIdempotencyKey(\"chat-retry\", [\n            retryableOperation.operationKey,\n            retryableOperation.content,\n        ]);\n\n        await retryOperationRegistryRef.current.run(retryOperationKey, async () => {\n            const currentMessages = messagesRef.current;\n            let nextMessages = [...currentMessages];\n            let removedCount = 0;\n\n            if (nextMessages.length > 0 && nextMessages[nextMessages.length - 1].role === \"assistant\") {\n                nextMessages = nextMessages.slice(0, -1);\n                removedCount += 1;\n            }\n\n            const lastMessage = nextMessages[nextMessages.length - 1];\n            if (\n                lastMessage\n                && lastMessage.role === \"user\"\n                && typeof lastMessage.content === \"string\"\n                && lastMessage.content === retryableOperation.content\n            ) {\n                nextMessages = nextMessages.slice(0, -1);\n                removedCount += 1;\n            }\n\n            messagesRef.current = nextMessages;\n            setMessages(nextMessages);\n            setThinkingOutput((prev) => prev.slice(0, Math.max(0, prev.length - removedCount)));\n\n            // Reset retry state and clear error message\n            setCanRetry(false);\n            setErrorMessage(null);\n            lastRetryableOperationRef.current = null;\n\n            await sendMessage(retryableOperation.content);\n        });\n    }, [canRetry, sendMessage]);\n\n    // =============================================================================\n    // PUBLIC INTERFACE\n    // =============================================================================\n    // \n    // Return the complete chat interface. All values are stable references\n    // where appropriate to prevent unnecessary re-renders in consuming components.\n    // The interface provides both state accessors and action functions.\n\n    return {\n        // ────────────────────────────────────────────────────────────────\n        // CORE CHAT STATE\n        // ────────────────────────────────────────────────────────────────\n        text,                           // Current input text\n        setText,                        // Update input text\n        messages,                       // Message history\n        setMessages,                    // Update message history\n        thinkingOutput,                 // Reasoning output\n        setThinkingOutput,              // Update reasoning output\n        isThinking,                     // Thinking status\n        isStreaming,                    // Streaming status\n        streamState,                    // Stream lifecycle state (streaming | completing | completed | error)\n\n        // ────────────────────────────────────────────────────────────────\n        // ACTIONS\n        // ────────────────────────────────────────────────────────────────\n        sendMessage,                    // Send message\n        cancel,                         // Cancel streaming\n        reset,                          // Reset all state\n\n        // ────────────────────────────────────────────────────────────────\n        // TITLE MANAGEMENT\n        // ────────────────────────────────────────────────────────────────\n        title,                          // Current title\n        setTitle,                       // Update title\n        generateTitle,                  // Generate new title\n\n        // ────────────────────────────────────────────────────────────────\n        // PROVIDER STATE\n        // ────────────────────────────────────────────────────────────────\n        currentProvider: activeProvider, // Active AI provider\n        currentModel: activeModel,      // Active model\n        isUsingFallback,                // Fallback status\n\n        // ────────────────────────────────────────────────────────────────\n        // RETRY FUNCTIONALITY\n        // ────────────────────────────────────────────────────────────────\n        retryLastMessage,               // Retry last message\n        canRetry,                       // Whether retry is available\n        errorMessage,                   // Error message for display\n    };\n}\n\n/*\n * =============================================================================\n * HOOK COMPREHENSIVE DOCUMENTATION\n * =============================================================================\n * \n * ARCHITECTURAL SUMMARY:\n * ────────────────────────────────────────────────────────────────────────\n * useChat is a sophisticated hook that combines multiple concerns into a\n * cohesive chat interface. It follows the composition pattern, building upon\n * specialized hooks for different aspects of chat functionality.\n * \n * KEY PRINCIPLES:\n * ────────────────────────────────────────────────────────────────────────\n * 1. Separation of Concerns: Different aspects (streaming, title generation,\n *    state management) are handled by dedicated hooks\n * 2. Referential Stability: useCallback and useMemo prevent unnecessary re-renders\n * 3. Unidirectional Data Flow: State flows down, actions flow up\n * 4. Error Resilience: Multiple layers of error handling and fallback\n * 5. Performance Optimization: Caching, memoization, and efficient updates\n * \n * PROVIDER ECOSYSTEM INTEGRATION:\n * ────────────────────────────────────────────────────────────────────────\n * The hook integrates with a robust provider system that supports:\n * • Multiple AI providers (Apple, OpenAI, OpenRouter, Ollama)\n * • Automatic fallback on failures\n * • Model caching for performance\n * • Per-chat provider overrides\n * • Retry with exponential backoff\n * \n * STATE MANAGEMENT STRATEGY:\n * ────────────────────────────────────────────────────────────────────────\n * • Local React state for immediate UI updates\n * • Zustand stores for persistent data\n * • Refs for operation tracking without re-renders\n * • Unified chat state system for consistency\n * \n * ERROR HANDLING APPROACH:\n * ────────────────────────────────────────────────────────────────────────\n * • Graceful degradation when providers fail\n * • User-friendly error messages\n * • Automatic retry with configurable backoff\n * • Fallback chain through multiple providers\n * • Recovery mechanisms for common failure scenarios\n * \n * PERFORMANCE OPTIMIZATIONS:\n * ────────────────────────────────────────────────────────────────────────\n * • Model caching to avoid repeated initialization\n * • Memoized callbacks to prevent child re-renders\n * • Efficient state updates with minimal re-renders\n * • Lazy loading of provider resources\n * • Streaming to provide immediate feedback\n * \n * =============================================================================\n */\n","additions":65,"deletions":31}],"diagnostics":{"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts":[{"range":{"start":{"line":46,"character":9},"end":{"line":46,"character":25}},"message":"'executeWithRetry' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":58,"character":5},"end":{"line":58,"character":17}},"message":"'ChunkHandler' is declared but never used.","severity":4,"code":6196,"source":"typescript"},{"range":{"start":{"line":152,"character":8},"end":{"line":152,"character":18}},"message":"'providerId' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/chat.types.ts","range":{"start":{"line":20,"character":6},"end":{"line":20,"character":66}}},"message":"The declaration was marked as deprecated here."}]},{"range":{"start":{"line":153,"character":8},"end":{"line":153,"character":15}},"message":"'modelId' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/chat.types.ts","range":{"start":{"line":22,"character":6},"end":{"line":22,"character":66}}},"message":"The declaration was marked as deprecated here."}]},{"range":{"start":{"line":294,"character":30},"end":{"line":294,"character":50}},"message":"'handleStreamingError' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":306,"character":21},"end":{"line":306,"character":47}},"message":"'isStreamLifecycleStreaming' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":307,"character":8},"end":{"line":307,"character":23}},"message":"'abortController' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":309,"character":8},"end":{"line":309,"character":25}},"message":"'markChunkReceived' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":310,"character":8},"end":{"line":310,"character":30}},"message":"'markDoneSignalReceived' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":311,"character":8},"end":{"line":311,"character":22}},"message":"'markCompleting' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":312,"character":8},"end":{"line":312,"character":21}},"message":"'markCompleted' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"}],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/concurrency.types.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/lib/concurrency.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChatStreaming.ts":[{"range":{"start":{"line":104,"character":26},"end":{"line":104,"character":39}},"message":"'LanguageModel' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":109,"character":9},"end":{"line":109,"character":29}},"message":"'getModelWithFallback' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":109,"character":71},"end":{"line":109,"character":91}},"message":"'hasFallbackAvailable' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":111,"character":51},"end":{"line":111,"character":66}},"message":"'shouldShowRetry' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":246,"character":34},"end":{"line":246,"character":50}},"message":"'MutableRefObject' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/%40types/react/index.d.ts","range":{"start":{"line":1658,"character":7},"end":{"line":1659,"character":5}}},"message":"The declaration was marked as deprecated here."}]}]},"truncated":false},"time":{"start":1770428692578,"end":1770428695623}},"metadata":{"openai":{"itemId":"fc_08afd66e9a7cf790016986990602e481979b63b3851cf642db"}}}}
{"type":"step_finish","timestamp":1770428695680,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c60449001kna2GiPxZgnIqz","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c50a42001CfifBfrqyjOmft","type":"step-finish","reason":"tool-calls","snapshot":"fea1351ce7c0edc42e41aae2f1c58e7a5fc77cbf","cost":0,"tokens":{"input":21162,"output":3830,"reasoning":2477,"cache":{"read":22016,"write":0}}}}
{"type":"step_start","timestamp":1770428696395,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c6074a001QEnUSGzH7IZONS","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c604b3001N7omldNbu4xLTz","type":"step-start","snapshot":"fea1351ce7c0edc42e41aae2f1c58e7a5fc77cbf"}}
{"type":"tool_use","timestamp":1770428699215,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c60fca001lUomrgxq4nAp9U","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c604b3001N7omldNbu4xLTz","type":"tool","callID":"call_op1BVN3HYuyf2dZzWQoKsNlG","tool":"read","state":{"status":"completed","input":{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts","offset":35,"limit":260},"output":"<file>\n00036|  * • Retry with exponential backoff\n00037|  * \n00038|  * =============================================================================\n00039|  */\n00040| \n00041| import { useCallback, useState, useRef, useEffect, useMemo } from \"react\";\n00042| import type { LanguageModel, ModelMessage } from \"ai\";\n00043| import { ProviderId } from \"@/types/provider.types\";\n00044| import { getProviderModel } from \"@/providers/provider-factory\";\n00045| import { getCachedModel } from \"@/providers/provider-cache\";\n00046| import { type FallbackResult } from \"@/providers/fallback-chain\";\n00047| import { executeWithRetry, DEFAULT_RETRY_CONFIG, type RetryConfig } from \"@/hooks/useErrorRecovery\";\n00048| import { useChatState } from \"@/hooks/useChatState\";\n00049| import { useTitleGeneration } from \"./useTitleGeneration\";\n00050| import { useChatStreaming } from \"./useChatStreaming\";\n00051| import { useStreamLifecycle } from \"./useStreamLifecycle\";\n00052| import type { UseChatOptions, StreamState } from \"@/types/chat.types\";\n00053| import {\n00054|     createIdempotencyKey,\n00055|     createIdempotencyRegistry,\n00056|     createSequenceGuard,\n00057| } from \"@/lib/concurrency\";\n00058| \n00059| type ChunkHandler = (chunk: string, accumulated: string) => void;\n00060| \n00061| interface RetryableOperation {\n00062|     operationKey: string;\n00063|     content: string;\n00064| }\n00065| \n00066| const DEFAULT_PLACEHOLDER_TEXT = \"...\";\n00067| \n00068| // =============================================================================\n00069| // TYPE DEFINITIONS\n00070| // =============================================================================\n00071| // \n00072| // These types define the public interface of the useChat hook, ensuring type\n00073| // safety for all returned values and callbacks.\n00074| \n00075| /**\n00076|  * Return type for the useChat hook\n00077|  * \n00078|  * This interface defines all the values and functions that the hook exposes to\n00079|  * consuming components. Each property serves a specific purpose in the chat\n00080|  * interaction flow.\n00081|  */\n00082| export interface UseChatReturn {\n00083|     /** Current input text in the chat field */\n00084|     text: string;\n00085|     /** Function to update the input text */\n00086|     setText: (value: string) => void;\n00087|     /** Array of all messages in the conversation */\n00088|     messages: ModelMessage[];\n00089|     /** Function to update the messages array */\n00090|     setMessages: React.Dispatch<React.SetStateAction<ModelMessage[]>>;\n00091|     /** Array of reasoning output aligned with messages */\n00092|     thinkingOutput: string[];\n00093|     /** Function to update the thinking output array */\n00094|     setThinkingOutput: React.Dispatch<React.SetStateAction<string[]>>;\n00095|     /** Whether the AI is currently streaming reasoning text */\n00096|     isThinking: boolean;\n00097|     /** Whether the AI is currently streaming a response */\n00098|     isStreaming: boolean;\n00099|     /** Current stream state for lifecycle tracking */\n00100|     streamState: StreamState;\n00101|     /** Send a message to the AI (optionally override current text) */\n00102|     sendMessage: (overrideText?: string) => Promise<void>;\n00103|     /** Cancel the current streaming response */\n00104|     cancel: () => void;\n00105|     /** Reset all chat state to initial values */\n00106|     reset: () => void;\n00107|     /** Current chat title (generated from conversation) */\n00108|     title: string;\n00109|     /** Function to update the chat title */\n00110|     setTitle: (title: string) => void;\n00111|     /** Generate a new title based on conversation content */\n00112|     generateTitle: () => Promise<string>;\n00113|     /** Currently active AI provider */\n00114|     currentProvider: ProviderId;\n00115|     /** Currently active model within the provider */\n00116|     currentModel: string;\n00117|     /** Whether we're currently using a fallback provider */\n00118|     isUsingFallback: boolean;\n00119|     /** Retry the last failed message */\n00120|     retryLastMessage: () => Promise<void>;\n00121|     /** Whether retry is available for the last message */\n00122|     canRetry: boolean;\n00123|     /** Error message for display when stream fails */\n00124|     errorMessage: string | null;\n00125| }\n00126| \n00127| // =============================================================================\n00128| // MAIN HOOK IMPLEMENTATION\n00129| // =============================================================================\n00130| \n00131| /**\n00132|  * Main useChat hook - orchestrates all chat functionality\n00133|  * \n00134|  * This hook serves as the central hub for chat operations, combining message\n00135|  * management, AI provider handling, streaming responses, and error recovery into\n00136|  * a cohesive interface.\n00137|  * \n00138|  * @param options - Configuration options for the chat instance\n00139|  * @returns Complete chat interface with state and actions\n00140|  */\n00141| export default function useChat(options: UseChatOptions = {}): UseChatReturn {\n00142|     // =============================================================================\n00143|     // OPTIONS DESTRUCTURING AND DEFAULTS\n00144|     // =============================================================================\n00145|     // \n00146|     // Extract all options with sensible defaults. The hook is designed to work\n00147|     // out-of-the-box with minimal configuration while allowing deep customization.\n00148|     \n00149|     const {\n00150|         initialMessages = [],              // Start with empty message history\n00151|         initialText = \"\",                  // Start with empty input field\n00152|         placeholder = true,                // Enable placeholder for AI responses\n00153|         providerId: legacyProviderId,      // Deprecated: use chatId instead\n00154|         modelId: legacyModelId,           // Deprecated: use chatId instead\n00155|         chatId,                           // Modern unified state management\n00156|         model: providedModel,             // Direct model injection (testing)\n00157|         onChunk,                          // Callback for streaming chunks\n00158|         onThinkingChunk,                  // Callback for streaming thinking chunks\n00159|         enableThinking = true,            // Enable thinking output updates\n00160|         thinkingLevel,                    // Control reasoning effort when supported\n00161|         onError,                          // Error handling callback\n00162|         onComplete,                       // Completion callback\n00163|         onFallback,                       // Provider fallback notification\n00164|         enableFallback = true,            // Enable automatic fallback\n00165|         enableRetry = true,               // Enable automatic retry\n00166|         retryConfig = {},                 // Custom retry configuration\n00167|     } = options;\n00168| \n00169|     // =============================================================================\n00170|     // CHAT STATE MANAGEMENT\n00171|     // =============================================================================\n00172|     // \n00173|     // Initialize chat state management. This handles both the new unified approach\n00174|     // (using chatId) and legacy providerId/modelId for backward compatibility.\n00175|     \n00176|     const chatState = useChatState(chatId || null);\n00177|     \n00178|     // Resolve effective provider/model based on whether we're using unified state\n00179|     // or legacy direct provider specification\n00180|     const effectiveProviderId = chatId \n00181|         ? chatState.provider                    // Use unified chat state\n00182|         : (legacyProviderId || \"apple\");       // Fallback to legacy or default\n00183|     const effectiveModelId = chatId \n00184|         ? chatState.model                      // Use unified chat state  \n00185|         : (legacyModelId || \"system-default\"); // Fallback to legacy or default\n00186| \n00187|     // =============================================================================\n00188|     // CORE REACT STATE\n00189|     // =============================================================================\n00190|     // \n00191|     // These are the fundamental React state variables that drive the chat interface.\n00192|     // Each piece of state has a specific responsibility in the chat flow.\n00193|     \n00194|     const [text, setText] = useState<string>(initialText);           // Input field content\n00195|     const [messages, setMessages] = useState<ModelMessage[]>(initialMessages); // Message history\n00196|     const [thinkingOutput, setThinkingOutput] = useState<string[]>(\n00197|         () => initialMessages.map(() => \"\")\n00198|     );\n00199|     const [isThinking, setIsThinking] = useState<boolean>(false);\n00200|     const [isStreaming, setIsStreaming] = useState<boolean>(false);  // Streaming status\n00201|     \n00202|     // =============================================================================\n00203|     // PROVIDER AND FALLBACK STATE\n00204|     // =============================================================================\n00205|     // \n00206|     // These state variables manage the AI provider ecosystem, including fallback\n00207|     // handling and provider switching during failures.\n00208|     \n00209|     const [activeProvider, setActiveProvider] = useState<ProviderId>(effectiveProviderId);\n00210|     const [activeModel, setActiveModel] = useState<string>(effectiveModelId);\n00211|     const [isUsingFallback, setIsUsingFallback] = useState<boolean>(false);\n00212|     \n00213|     // =============================================================================\n00214|     // REFERENCES FOR STABLE OPERATIONS\n00215|     // =============================================================================\n00216|     // \n00217|     // useRef values that persist across re-renders without triggering them.\n00218|     // These are used for tracking operation state and maintaining data integrity.\n00219|     \n00220|     const failedProvidersRef = useRef<ProviderId[]>([]);     // Track failed providers for fallback\n00221|     \n00222|     // Retry and cancellation tracking\n00223|     const lastUserMessageRef = useRef<string | null>(null); // Store last user message for retry\n00224|     const [canRetry, setCanRetry] = useState<boolean>(false); // Whether retry is available\n00225|     const [errorMessage, setErrorMessage] = useState<string | null>(null); // Error message for display\n00226|     const canceledRef = useRef<boolean>(false);             // Track if streaming was canceled\n00227|     const messagesRef = useRef<ModelMessage[]>(initialMessages);\n00228|     const sendSequenceGuardRef = useRef(createSequenceGuard(`chat-send-${chatId ?? \"default\"}`));\n00229|     const retryOperationRegistryRef = useRef(createIdempotencyRegistry<void>());\n00230|     const lastRetryableOperationRef = useRef<RetryableOperation | null>(null);\n00231| \n00232|     useEffect(() => {\n00233|         messagesRef.current = messages;\n00234|     }, [messages]);\n00235| \n00236|     // =============================================================================\n00237|     // CONFIGURATION MERGING\n00238|     // =============================================================================\n00239|     // \n00240|     // Merge user-provided retry configuration with system defaults to create\n00241|     // the final configuration used throughout the hook.\n00242|     \n00243|     const mergedRetryConfig: RetryConfig = { ...DEFAULT_RETRY_CONFIG, ...retryConfig };\n00244|     const placeholderText = placeholder ? DEFAULT_PLACEHOLDER_TEXT : \"\";\n00245| \n00246|         // =============================================================================\n00247|     // MODEL RESOLUTION AND CACHING\n00248|     // =============================================================================\n00249|     // \n00250|     // Resolve the actual AI model to use for chat operations. This involves:\n00251|     // 1. Using directly provided model (for testing/special cases)\n00252|     // 2. Looking up cached model for performance\n00253|     // 3. Creating new model instance if needed\n00254|     // \n00255|     // The useMemo ensures we only recompute when provider/model actually changes.\n00256|     \n00257|     const model: LanguageModel | null = useMemo(() => {\n00258|         // Direct model injection takes precedence (useful for testing)\n00259|         if (providedModel) {\n00260|             return providedModel as LanguageModel;\n00261|         }\n00262| \n00263|         // Try to get cached model for performance\n00264|         const cachedModel = getCachedModel(\n00265|             activeProvider,\n00266|             activeModel,\n00267|             () => getProviderModel(activeProvider, activeModel).model\n00268|         );\n00269| \n00270|         return cachedModel || null;\n00271|     }, [providedModel, activeProvider, activeModel]);\n00272| \n00273|     // =============================================================================\n00274|     // TITLE GENERATION INTEGRATION\n00275|     // =============================================================================\n00276|     // \n00277|     // Connect to the title generation subsystem. Titles are automatically\n00278|     // generated based on conversation content and used for chat identification\n00279|     // in the UI and database storage.\n00280|     \n00281|     const { title, setTitle, generateTitle } = useTitleGeneration(\n00282|         messages.map(m => ({ role: m.role, content: typeof m.content === 'string' ? m.content : '' })),\n00283|         model,\n00284|         enableRetry,\n00285|         mergedRetryConfig\n00286|     );\n00287| \n00288|     // =============================================================================\n00289|     // STREAMING INFRASTRUCTURE\n00290|     // =============================================================================\n00291|     // \n00292|     // Connect to the streaming subsystem that handles real-time AI responses.\n00293|     // This provides the core functionality for streaming text from AI providers.\n00294|     \n00295|     const { executeStreaming, handleStreamingError } = useChatStreaming();\n\n(File has more lines. Use 'offset' parameter to read beyond line 295)\n</file>","title":"hooks/chat/useChat.ts","metadata":{"preview":" * • Retry with exponential backoff\n * \n * =============================================================================\n */\n\nimport { useCallback, useState, useRef, useEffect, useMemo } from \"react\";\nimport type { LanguageModel, ModelMessage } from \"ai\";\nimport { ProviderId } from \"@/types/provider.types\";\nimport { getProviderModel } from \"@/providers/provider-factory\";\nimport { getCachedModel } from \"@/providers/provider-cache\";\nimport { type FallbackResult } from \"@/providers/fallback-chain\";\nimport { executeWithRetry, DEFAULT_RETRY_CONFIG, type RetryConfig } from \"@/hooks/useErrorRecovery\";\nimport { useChatState } from \"@/hooks/useChatState\";\nimport { useTitleGeneration } from \"./useTitleGeneration\";\nimport { useChatStreaming } from \"./useChatStreaming\";\nimport { useStreamLifecycle } from \"./useStreamLifecycle\";\nimport type { UseChatOptions, StreamState } from \"@/types/chat.types\";\nimport {\n    createIdempotencyKey,\n    createIdempotencyRegistry,","truncated":true},"time":{"start":1770428699212,"end":1770428699214}},"metadata":{"openai":{"itemId":"fc_022137f7c1395fb5016986991a88c08197ae6ac5a8c6cd31d8"}}}}
{"type":"step_finish","timestamp":1770428699287,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c6126c001njaAiGq3VxNPsm","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c604b3001N7omldNbu4xLTz","type":"step-finish","reason":"tool-calls","snapshot":"fea1351ce7c0edc42e41aae2f1c58e7a5fc77cbf","cost":0,"tokens":{"input":12774,"output":128,"reasoning":80,"cache":{"read":34304,"write":0}}}}
{"type":"step_start","timestamp":1770428699977,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c61549001VrUz72WjJWlNlz","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c612ca0011OJr2OY2er2tmc","type":"step-start","snapshot":"fea1351ce7c0edc42e41aae2f1c58e7a5fc77cbf"}}
{"type":"tool_use","timestamp":1770428701525,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c6186a001ybgzeDESxw750v","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c612ca0011OJr2OY2er2tmc","type":"tool","callID":"call_6pxA3hrXaf4JOiT1QVqV7EVM","tool":"read","state":{"status":"completed","input":{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts","offset":390,"limit":280},"output":"<file>\n00391|         // =============================================================================\n00392|     // CORE MESSAGE SENDING LOGIC\n00393|     // =============================================================================\n00394|     // \n00395|     // This is the heart of the chat functionality. The sendMessage function:\n00396|     // 1. Validates and prepares the user message\n00397|     // 2. Updates the message history\n00398|     // 3. Initiates streaming with the AI provider\n00399|     // 4. Handles fallback and retry logic\n00400|     // 5. Manages the complete message flow lifecycle\n00401| \n00402|     /**\n00403|      * Send a message to the AI and initiate streaming response\n00404|      * \n00405|      * @param overrideText - Optional text to send instead of current input\n00406|      * \n00407|      * This function orchestrates the complete message sending flow:\n00408|      * 1. Input validation and preprocessing\n00409|      * 2. Message history updates\n00410|      * 3. AI provider streaming initiation\n00411|      * 4. Error handling with fallback mechanisms\n00412|      * 5. Completion callbacks\n00413|      */\n00414|     const sendMessage = useCallback(\n00415|         async (overrideText?: string) => {\n00416|             // ────────────────────────────────────────────────────────────────\n00417|             // INPUT VALIDATION AND PREPARATION\n00418|             // ────────────────────────────────────────────────────────────────\n00419|             const rawValue: unknown = overrideText ?? (text as unknown);\n00420|             const content = typeof rawValue === \"string\" ? rawValue.trim() : \"\";\n00421|             \n00422|             // Exit early if no valid content to send\n00423|             if (!content) return;\n00424| \n00425|             const sendToken = sendSequenceGuardRef.current.next();\n00426|             const sendOperationKey = createIdempotencyKey(\"chat-send\", [\n00427|                 chatId ?? \"default\",\n00428|                 sendToken.sequence,\n00429|                 content,\n00430|             ]);\n00431| \n00432|             // ────────────────────────────────────────────────────────────────\n00433|             // STATE INITIALIZATION\n00434|             // ────────────────────────────────────────────────────────────────\n00435|             setIsStreaming(true);                    // Start streaming state\n00436|             setIsThinking(false);                    // Reset thinking state\n00437|             canceledRef.current = false;            // Clear cancellation flag\n00438|             setCanRetry(false);                     // Disable retry until needed\n00439|             lastRetryableOperationRef.current = null;\n00440|             lastUserMessageRef.current = content;   // Store for retry capability\n00441|             \n00442|             // Initialize stream lifecycle management\n00443|             const streamController = initializeStream();\n00444|             const abortSignal = streamController.signal;\n00445|             const canMutateForCurrentSend = (): boolean => (\n00446|                 sendSequenceGuardRef.current.isCurrent(sendToken)\n00447|                 && !canceledRef.current\n00448|                 && !abortSignal.aborted\n00449|             );\n00450| \n00451|             // ────────────────────────────────────────────────────────────────\n00452|             // MESSAGE HISTORY MANAGEMENT\n00453|             // ────────────────────────────────────────────────────────────────\n00454|             const userMessage: ModelMessage = { role: \"user\", content };\n00455|             const updatedMessages = [...messagesRef.current, userMessage];\n00456|             setMessages(updatedMessages);\n00457|             setThinkingOutput((prev) => [...prev, \"\"]);\n00458| \n00459|             // Clear input field if we're using the current text (not override)\n00460|             if (overrideText === undefined) {\n00461|                 setText(\"\");\n00462|             }\n00463| \n00464|             // Add placeholder for assistant response\n00465|             const assistantIndex = updatedMessages.length;\n00466|             setMessages((prev) => [\n00467|                 ...prev,\n00468|                 {\n00469|                     role: \"assistant\",\n00470|                     content: placeholderText,\n00471|                 },\n00472|             ]);\n00473|             setThinkingOutput((prev) => [...prev, \"\"]);\n00474| \n00475|             // ────────────────────────────────────────────────────────────────\n00476|             // MODEL VALIDATION\n00477|             // ────────────────────────────────────────────────────────────────\n00478|             if (!model) {\n00479|                 // Show helpful error message when no provider is configured\n00480|                 setMessages((prev) => {\n00481|                     const next = [...prev];\n00482|                     next[assistantIndex] = {\n00483|                         role: \"assistant\",\n00484|                         content: \"**Setup Required**\\n\\nNo AI provider configured. Please set up a provider in settings.\\n\\n*Go to Settings to configure an AI provider.*\",\n00485|                     };\n00486|                     return next;\n00487|                 });\n00488|                 \n00489|                 onError?.(new Error(\"No AI provider configured\"));\n00490|                 setIsStreaming(false);\n00491|                 setIsThinking(false);\n00492|                 onComplete?.();\n00493|                 return;\n00494|             }\n00495| \n00496|             // ────────────────────────────────────────────────────────────────\n00497|             // STREAMING CONFIGURATION\n00498|             // ────────────────────────────────────────────────────────────────\n00499|             const handleThinkingChunk = enableThinking\n00500|                 ? (chunk: string, accumulated: string) => {\n00501|                     if (!canMutateForCurrentSend()) {\n00502|                         return;\n00503|                     }\n00504| \n00505|                     setIsThinking(true);\n00506|                     setThinkingOutput((prev) => {\n00507|                         const next = [...prev];\n00508|                         next[assistantIndex] = accumulated;\n00509|                         return next;\n00510|                     });\n00511|                     onThinkingChunk?.(chunk, accumulated);\n00512|                 }\n00513|                 : undefined;\n00514| \n00515|             const streamingOptions = {\n00516|                 model: {\n00517|                     model,\n00518|                     provider: activeProvider,\n00519|                     modelId: activeModel,\n00520|                     isOriginal: !isUsingFallback,\n00521|                     attemptedProviders: failedProvidersRef.current,\n00522|                 } as FallbackResult,\n00523|                 enableRetry,\n00524|                 retryConfig: mergedRetryConfig,\n00525|                 enableFallback,\n00526|                 activeProvider,\n00527|                 effectiveProviderId,\n00528|                 thinkingLevel,\n00529|                 abortSignal,\n00530|                 onChunk,\n00531|                 onThinkingChunk: handleThinkingChunk,\n00532|                 canMutateState: canMutateForCurrentSend,\n00533|                 onError: (error: unknown) => {\n00534|                     if (!canMutateForCurrentSend()) {\n00535|                         return;\n00536|                     }\n00537| \n00538|                     if (error instanceof Error) {\n00539|                         markError(error);\n00540|                         setErrorMessage(error.message);\n00541|                         setCanRetry(true);\n00542|                         lastRetryableOperationRef.current = {\n00543|                             operationKey: sendOperationKey,\n00544|                             content,\n00545|                         };\n00546|                         onError?.(error);\n00547|                     } else {\n00548|                         const wrappedError = new Error(String(error));\n00549|                         markError(wrappedError);\n00550|                         setErrorMessage(wrappedError.message);\n00551|                         setCanRetry(true);\n00552|                         lastRetryableOperationRef.current = {\n00553|                             operationKey: sendOperationKey,\n00554|                             content,\n00555|                         };\n00556|                         onError?.(wrappedError);\n00557|                     }\n00558|                 },\n00559|                 onFallback,\n00560|                 onProviderChange: (provider: ProviderId, model: string, isFallback: boolean) => {\n00561|                     if (!canMutateForCurrentSend()) {\n00562|                         return;\n00563|                     }\n00564| \n00565|                     setActiveProvider(provider);\n00566|                     setActiveModel(model);\n00567|                     setIsUsingFallback(isFallback);\n00568|                 },\n00569|             };\n00570| \n00571|             // ────────────────────────────────────────────────────────────────\n00572|             // STREAMING EXECUTION\n00573|             // ────────────────────────────────────────────────────────────────\n00574|             const result = await executeStreaming(\n00575|                 streamingOptions,\n00576|                 updatedMessages,\n00577|                 setMessages,\n00578|                 assistantIndex,\n00579|                 failedProvidersRef\n00580|             );\n00581| \n00582|             if (!sendSequenceGuardRef.current.isCurrent(sendToken)) {\n00583|                 return;\n00584|             }\n00585| \n00586|             // ────────────────────────────────────────────────────────────────\n00587|             // FALLBACK RETRY LOGIC\n00588|             // ────────────────────────────────────────────────────────────────\n00589|             if (result.shouldRetryWithFallback && !canceledRef.current) {\n00590|                 setIsStreaming(false);\n00591|                 setIsThinking(false);\n00592|                 // Small delay to ensure clean state transition\n00593|                 await new Promise(resolve => setTimeout(resolve, 100));\n00594|                 await sendMessage(content);\n00595|                 return;\n00596|             }\n00597| \n00598|             // ────────────────────────────────────────────────────────────────\n00599|             // COMPLETION\n00600|             // ────────────────────────────────────────────────────────────────\n00601|             if (canMutateForCurrentSend()) {\n00602|                 setIsStreaming(false);\n00603|                 setIsThinking(false);\n00604|                 onComplete?.();\n00605|             }\n00606|         },\n00607|         [\n00608|             text, \n00609|             placeholderText, \n00610|             model, \n00611|             activeProvider, \n00612|             activeModel, \n00613|             isUsingFallback,\n00614|             enableRetry, \n00615|             mergedRetryConfig,\n00616|             executeStreaming,\n00617|             onChunk, \n00618|             onThinkingChunk,\n00619|             onComplete, \n00620|             onError, \n00621|             onFallback,\n00622|             effectiveProviderId,\n00623|             enableThinking,\n00624|             thinkingLevel,\n00625|             onThinkingChunk\n00626|         ],\n00627|     );\n00628| \n00629|         // =============================================================================\n00630|     // RETRY FUNCTIONALITY\n00631|     // =============================================================================\n00632|     // \n00633|     // Retry functionality allows users to resend their last message when the\n00634|     // AI response failed or was incomplete. This involves:\n00635|     // 1. Removing the failed assistant response\n00636|     // 2. Optionally removing the user message (if they want to edit)\n00637|     // 3. Resending the original message with fresh state\n00638| \n00639|     /**\n00640|      * Retry the last failed message\n00641|      * \n00642|      * This function enables users to retry their last message when the AI\n00643|      * response failed or was cut off. It cleans up the conversation history\n00644|      * and resends the original message with fresh streaming state.\n00645|      */\n00646|     const retryLastMessage = useCallback(async () => {\n00647|         const retryableOperation = lastRetryableOperationRef.current;\n00648| \n00649|         // Guard against invalid retry attempts\n00650|         if (!lastUserMessageRef.current || !canRetry || !retryableOperation) return;\n00651| \n00652|         const retryOperationKey = createIdempotencyKey(\"chat-retry\", [\n00653|             retryableOperation.operationKey,\n00654|             retryableOperation.content,\n00655|         ]);\n00656| \n00657|         await retryOperationRegistryRef.current.run(retryOperationKey, async () => {\n00658|             const currentMessages = messagesRef.current;\n00659|             let nextMessages = [...currentMessages];\n00660|             let removedCount = 0;\n00661| \n00662|             if (nextMessages.length > 0 && nextMessages[nextMessages.length - 1].role === \"assistant\") {\n00663|                 nextMessages = nextMessages.slice(0, -1);\n00664|                 removedCount += 1;\n00665|             }\n00666| \n00667|             const lastMessage = nextMessages[nextMessages.length - 1];\n00668|             if (\n00669|                 lastMessage\n00670|                 && lastMessage.role === \"user\"\n\n(File has more lines. Use 'offset' parameter to read beyond line 670)\n</file>","title":"hooks/chat/useChat.ts","metadata":{"preview":"        // =============================================================================\n    // CORE MESSAGE SENDING LOGIC\n    // =============================================================================\n    // \n    // This is the heart of the chat functionality. The sendMessage function:\n    // 1. Validates and prepares the user message\n    // 2. Updates the message history\n    // 3. Initiates streaming with the AI provider\n    // 4. Handles fallback and retry logic\n    // 5. Manages the complete message flow lifecycle\n\n    /**\n     * Send a message to the AI and initiate streaming response\n     * \n     * @param overrideText - Optional text to send instead of current input\n     * \n     * This function orchestrates the complete message sending flow:\n     * 1. Input validation and preprocessing\n     * 2. Message history updates\n     * 3. AI provider streaming initiation","truncated":true},"time":{"start":1770428701522,"end":1770428701524}},"metadata":{"openai":{"itemId":"fc_06b91a0ad2551734016986991cbf48819586f35975e33dd9e4"}}}}
{"type":"step_finish","timestamp":1770428701602,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c61b6f001ZAXe2EkeDm9HhL","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c612ca0011OJr2OY2er2tmc","type":"step-finish","reason":"tool-calls","snapshot":"fea1351ce7c0edc42e41aae2f1c58e7a5fc77cbf","cost":0,"tokens":{"input":5962,"output":67,"reasoning":19,"cache":{"read":44544,"write":0}}}}
{"type":"step_start","timestamp":1770428702253,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c61e2a001wwyr0N8B4Eb3pJ","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c61bd8001B7hCWIO9c5boY7","type":"step-start","snapshot":"fea1351ce7c0edc42e41aae2f1c58e7a5fc77cbf"}}
{"type":"tool_use","timestamp":1770428705261,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c62791001JL1d8EZr1Kl0Hz","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c61bd8001B7hCWIO9c5boY7","type":"tool","callID":"call_N9IUO6di92Iyz5Rufu3QvnYj","tool":"read","state":{"status":"completed","input":{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts","offset":670,"limit":80},"output":"<file>\n00671|                 && typeof lastMessage.content === \"string\"\n00672|                 && lastMessage.content === retryableOperation.content\n00673|             ) {\n00674|                 nextMessages = nextMessages.slice(0, -1);\n00675|                 removedCount += 1;\n00676|             }\n00677| \n00678|             messagesRef.current = nextMessages;\n00679|             setMessages(nextMessages);\n00680|             setThinkingOutput((prev) => prev.slice(0, Math.max(0, prev.length - removedCount)));\n00681| \n00682|             // Reset retry state and clear error message\n00683|             setCanRetry(false);\n00684|             setErrorMessage(null);\n00685|             lastRetryableOperationRef.current = null;\n00686| \n00687|             await sendMessage(retryableOperation.content);\n00688|         });\n00689|     }, [canRetry, sendMessage]);\n00690| \n00691|     // =============================================================================\n00692|     // PUBLIC INTERFACE\n00693|     // =============================================================================\n00694|     // \n00695|     // Return the complete chat interface. All values are stable references\n00696|     // where appropriate to prevent unnecessary re-renders in consuming components.\n00697|     // The interface provides both state accessors and action functions.\n00698| \n00699|     return {\n00700|         // ────────────────────────────────────────────────────────────────\n00701|         // CORE CHAT STATE\n00702|         // ────────────────────────────────────────────────────────────────\n00703|         text,                           // Current input text\n00704|         setText,                        // Update input text\n00705|         messages,                       // Message history\n00706|         setMessages,                    // Update message history\n00707|         thinkingOutput,                 // Reasoning output\n00708|         setThinkingOutput,              // Update reasoning output\n00709|         isThinking,                     // Thinking status\n00710|         isStreaming,                    // Streaming status\n00711|         streamState,                    // Stream lifecycle state (streaming | completing | completed | error)\n00712| \n00713|         // ────────────────────────────────────────────────────────────────\n00714|         // ACTIONS\n00715|         // ────────────────────────────────────────────────────────────────\n00716|         sendMessage,                    // Send message\n00717|         cancel,                         // Cancel streaming\n00718|         reset,                          // Reset all state\n00719| \n00720|         // ────────────────────────────────────────────────────────────────\n00721|         // TITLE MANAGEMENT\n00722|         // ────────────────────────────────────────────────────────────────\n00723|         title,                          // Current title\n00724|         setTitle,                       // Update title\n00725|         generateTitle,                  // Generate new title\n00726| \n00727|         // ────────────────────────────────────────────────────────────────\n00728|         // PROVIDER STATE\n00729|         // ────────────────────────────────────────────────────────────────\n00730|         currentProvider: activeProvider, // Active AI provider\n00731|         currentModel: activeModel,      // Active model\n00732|         isUsingFallback,                // Fallback status\n00733| \n00734|         // ────────────────────────────────────────────────────────────────\n00735|         // RETRY FUNCTIONALITY\n00736|         // ────────────────────────────────────────────────────────────────\n00737|         retryLastMessage,               // Retry last message\n00738|         canRetry,                       // Whether retry is available\n00739|         errorMessage,                   // Error message for display\n00740|     };\n00741| }\n00742| \n00743| /*\n00744|  * =============================================================================\n00745|  * HOOK COMPREHENSIVE DOCUMENTATION\n00746|  * =============================================================================\n00747|  * \n00748|  * ARCHITECTURAL SUMMARY:\n00749|  * ────────────────────────────────────────────────────────────────────────\n00750|  * useChat is a sophisticated hook that combines multiple concerns into a\n\n(File has more lines. Use 'offset' parameter to read beyond line 750)\n</file>","title":"hooks/chat/useChat.ts","metadata":{"preview":"                && typeof lastMessage.content === \"string\"\n                && lastMessage.content === retryableOperation.content\n            ) {\n                nextMessages = nextMessages.slice(0, -1);\n                removedCount += 1;\n            }\n\n            messagesRef.current = nextMessages;\n            setMessages(nextMessages);\n            setThinkingOutput((prev) => prev.slice(0, Math.max(0, prev.length - removedCount)));\n\n            // Reset retry state and clear error message\n            setCanRetry(false);\n            setErrorMessage(null);\n            lastRetryableOperationRef.current = null;\n\n            await sendMessage(retryableOperation.content);\n        });\n    }, [canRetry, sendMessage]);\n","truncated":true},"time":{"start":1770428705258,"end":1770428705260}},"metadata":{"openai":{"itemId":"fc_0cfc2660c03c4c3a01698699209f50819591877db63b4a254d"}}}}
{"type":"step_finish","timestamp":1770428705361,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c62a23001eXpQqOzvnD3W6r","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c61bd8001B7hCWIO9c5boY7","type":"step-finish","reason":"tool-calls","snapshot":"fea1351ce7c0edc42e41aae2f1c58e7a5fc77cbf","cost":0,"tokens":{"input":6885,"output":147,"reasoning":99,"cache":{"read":46592,"write":0}}}}
{"type":"step_start","timestamp":1770428707714,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c633810014PlGhwzHp7b6kp","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c62a84001kUVYHUKav9ZUWY","type":"step-start","snapshot":"fea1351ce7c0edc42e41aae2f1c58e7a5fc77cbf"}}
{"type":"tool_use","timestamp":1770428740962,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c667800010PSwyu7d3YfZI9","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c62a84001kUVYHUKav9ZUWY","type":"tool","callID":"call_c7xKVX0XFwEHbAX7JcSFfguN","tool":"apply_patch","state":{"status":"completed","input":{"patchText":"*** Begin Patch\n*** Update File: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n@@\n   describe('edge cases', () => {\n@@\n     it('prevents post-cancel error mutation from stale stream callbacks', async () => {\n@@\n       expect(result.current.canRetry).toBe(false);\n       expect(onError).toHaveBeenCalledTimes(0);\n     });\n+\n+    it('deduplicates quick retry taps for the same failed operation', async () => {\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('network flap'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      const retryDeferred = createDeferred<{\n+        success: boolean;\n+        shouldRetryWithFallback: boolean;\n+        accumulated: string;\n+      }>();\n+\n+      mockExecuteStreaming.mockImplementationOnce(async () => retryDeferred.promise);\n+\n+      const { result } = renderHook(() => useChat({}));\n+\n+      await act(async () => {\n+        await result.current.sendMessage('retry me');\n+      });\n+\n+      expect(result.current.canRetry).toBe(true);\n+      expect(result.current.messages).toHaveLength(2);\n+\n+      let firstRetry = Promise.resolve();\n+      let secondRetry = Promise.resolve();\n+\n+      act(() => {\n+        firstRetry = result.current.retryLastMessage();\n+        secondRetry = result.current.retryLastMessage();\n+      });\n+\n+      expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n+\n+      await act(async () => {\n+        retryDeferred.resolve({\n+          success: true,\n+          shouldRetryWithFallback: false,\n+          accumulated: 'retry ok',\n+        });\n+\n+        await Promise.all([firstRetry, secondRetry]);\n+      });\n+\n+      expect(result.current.messages).toHaveLength(2);\n+      expect(result.current.messages[0]).toEqual({\n+        role: 'user',\n+        content: 'retry me',\n+      });\n+    });\n+\n+    it('keeps retry state stable when retry is tapped while a retry is inflight', async () => {\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('temporary outage'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      const inflightRetry = createDeferred<{\n+        success: boolean;\n+        shouldRetryWithFallback: boolean;\n+        accumulated: string;\n+      }>();\n+\n+      mockExecuteStreaming.mockImplementationOnce(async () => inflightRetry.promise);\n+\n+      const { result } = renderHook(() => useChat({}));\n+\n+      await act(async () => {\n+        await result.current.sendMessage('inflight retry');\n+      });\n+\n+      let firstRetry = Promise.resolve();\n+      let secondRetry = Promise.resolve();\n+\n+      act(() => {\n+        firstRetry = result.current.retryLastMessage();\n+      });\n+\n+      act(() => {\n+        secondRetry = result.current.retryLastMessage();\n+      });\n+\n+      expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n+\n+      await act(async () => {\n+        inflightRetry.resolve({\n+          success: true,\n+          shouldRetryWithFallback: false,\n+          accumulated: 'recovered',\n+        });\n+\n+        await Promise.all([firstRetry, secondRetry]);\n+      });\n+\n+      expect(result.current.messages).toHaveLength(2);\n+      expect(result.current.canRetry).toBe(false);\n+    });\n+\n+    it('recovers from repeated network flap retries without duplicating chat entries', async () => {\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('network flap - initial'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('network flap - retry'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      mockExecuteStreaming.mockImplementationOnce(async () => ({\n+        success: true,\n+        shouldRetryWithFallback: false,\n+        accumulated: 'eventual success',\n+      }));\n+\n+      const { result } = renderHook(() => useChat({}));\n+\n+      await act(async () => {\n+        await result.current.sendMessage('flap-safe');\n+      });\n+\n+      expect(result.current.canRetry).toBe(true);\n+      expect(result.current.messages).toHaveLength(2);\n+\n+      await act(async () => {\n+        await result.current.retryLastMessage();\n+      });\n+\n+      expect(result.current.canRetry).toBe(true);\n+      expect(result.current.messages).toHaveLength(2);\n+\n+      await act(async () => {\n+        await result.current.retryLastMessage();\n+      });\n+\n+      expect(result.current.canRetry).toBe(false);\n+      expect(result.current.messages).toHaveLength(2);\n+      expect(result.current.messages[0]).toEqual({\n+        role: 'user',\n+        content: 'flap-safe',\n+      });\n+    });\n   });\n });\n*** End Patch"},"output":"Success. Updated the following files:\nM hooks/chat/__tests__/useChat.test.ts","title":"Success. Updated the following files:\nM hooks/chat/__tests__/useChat.test.ts","metadata":{"diff":"Index: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n===================================================================\n--- /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n+++ /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n@@ -452,6 +452,164 @@\n       expect(result.current.errorMessage).toBeNull();\n       expect(result.current.canRetry).toBe(false);\n       expect(onError).toHaveBeenCalledTimes(0);\n     });\n+\n+    it('deduplicates quick retry taps for the same failed operation', async () => {\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('network flap'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      const retryDeferred = createDeferred<{\n+        success: boolean;\n+        shouldRetryWithFallback: boolean;\n+        accumulated: string;\n+      }>();\n+\n+      mockExecuteStreaming.mockImplementationOnce(async () => retryDeferred.promise);\n+\n+      const { result } = renderHook(() => useChat({}));\n+\n+      await act(async () => {\n+        await result.current.sendMessage('retry me');\n+      });\n+\n+      expect(result.current.canRetry).toBe(true);\n+      expect(result.current.messages).toHaveLength(2);\n+\n+      let firstRetry = Promise.resolve();\n+      let secondRetry = Promise.resolve();\n+\n+      act(() => {\n+        firstRetry = result.current.retryLastMessage();\n+        secondRetry = result.current.retryLastMessage();\n+      });\n+\n+      expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n+\n+      await act(async () => {\n+        retryDeferred.resolve({\n+          success: true,\n+          shouldRetryWithFallback: false,\n+          accumulated: 'retry ok',\n+        });\n+\n+        await Promise.all([firstRetry, secondRetry]);\n+      });\n+\n+      expect(result.current.messages).toHaveLength(2);\n+      expect(result.current.messages[0]).toEqual({\n+        role: 'user',\n+        content: 'retry me',\n+      });\n+    });\n+\n+    it('keeps retry state stable when retry is tapped while a retry is inflight', async () => {\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('temporary outage'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      const inflightRetry = createDeferred<{\n+        success: boolean;\n+        shouldRetryWithFallback: boolean;\n+        accumulated: string;\n+      }>();\n+\n+      mockExecuteStreaming.mockImplementationOnce(async () => inflightRetry.promise);\n+\n+      const { result } = renderHook(() => useChat({}));\n+\n+      await act(async () => {\n+        await result.current.sendMessage('inflight retry');\n+      });\n+\n+      let firstRetry = Promise.resolve();\n+      let secondRetry = Promise.resolve();\n+\n+      act(() => {\n+        firstRetry = result.current.retryLastMessage();\n+      });\n+\n+      act(() => {\n+        secondRetry = result.current.retryLastMessage();\n+      });\n+\n+      expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n+\n+      await act(async () => {\n+        inflightRetry.resolve({\n+          success: true,\n+          shouldRetryWithFallback: false,\n+          accumulated: 'recovered',\n+        });\n+\n+        await Promise.all([firstRetry, secondRetry]);\n+      });\n+\n+      expect(result.current.messages).toHaveLength(2);\n+      expect(result.current.canRetry).toBe(false);\n+    });\n+\n+    it('recovers from repeated network flap retries without duplicating chat entries', async () => {\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('network flap - initial'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('network flap - retry'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      mockExecuteStreaming.mockImplementationOnce(async () => ({\n+        success: true,\n+        shouldRetryWithFallback: false,\n+        accumulated: 'eventual success',\n+      }));\n+\n+      const { result } = renderHook(() => useChat({}));\n+\n+      await act(async () => {\n+        await result.current.sendMessage('flap-safe');\n+      });\n+\n+      expect(result.current.canRetry).toBe(true);\n+      expect(result.current.messages).toHaveLength(2);\n+\n+      await act(async () => {\n+        await result.current.retryLastMessage();\n+      });\n+\n+      expect(result.current.canRetry).toBe(true);\n+      expect(result.current.messages).toHaveLength(2);\n+\n+      await act(async () => {\n+        await result.current.retryLastMessage();\n+      });\n+\n+      expect(result.current.canRetry).toBe(false);\n+      expect(result.current.messages).toHaveLength(2);\n+      expect(result.current.messages[0]).toEqual({\n+        role: 'user',\n+        content: 'flap-safe',\n+      });\n+    });\n   });\n });\n\n","files":[{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts","relativePath":"hooks/chat/__tests__/useChat.test.ts","type":"update","diff":"Index: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n===================================================================\n--- /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n+++ /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n@@ -452,6 +452,164 @@\n       expect(result.current.errorMessage).toBeNull();\n       expect(result.current.canRetry).toBe(false);\n       expect(onError).toHaveBeenCalledTimes(0);\n     });\n+\n+    it('deduplicates quick retry taps for the same failed operation', async () => {\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('network flap'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      const retryDeferred = createDeferred<{\n+        success: boolean;\n+        shouldRetryWithFallback: boolean;\n+        accumulated: string;\n+      }>();\n+\n+      mockExecuteStreaming.mockImplementationOnce(async () => retryDeferred.promise);\n+\n+      const { result } = renderHook(() => useChat({}));\n+\n+      await act(async () => {\n+        await result.current.sendMessage('retry me');\n+      });\n+\n+      expect(result.current.canRetry).toBe(true);\n+      expect(result.current.messages).toHaveLength(2);\n+\n+      let firstRetry = Promise.resolve();\n+      let secondRetry = Promise.resolve();\n+\n+      act(() => {\n+        firstRetry = result.current.retryLastMessage();\n+        secondRetry = result.current.retryLastMessage();\n+      });\n+\n+      expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n+\n+      await act(async () => {\n+        retryDeferred.resolve({\n+          success: true,\n+          shouldRetryWithFallback: false,\n+          accumulated: 'retry ok',\n+        });\n+\n+        await Promise.all([firstRetry, secondRetry]);\n+      });\n+\n+      expect(result.current.messages).toHaveLength(2);\n+      expect(result.current.messages[0]).toEqual({\n+        role: 'user',\n+        content: 'retry me',\n+      });\n+    });\n+\n+    it('keeps retry state stable when retry is tapped while a retry is inflight', async () => {\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('temporary outage'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      const inflightRetry = createDeferred<{\n+        success: boolean;\n+        shouldRetryWithFallback: boolean;\n+        accumulated: string;\n+      }>();\n+\n+      mockExecuteStreaming.mockImplementationOnce(async () => inflightRetry.promise);\n+\n+      const { result } = renderHook(() => useChat({}));\n+\n+      await act(async () => {\n+        await result.current.sendMessage('inflight retry');\n+      });\n+\n+      let firstRetry = Promise.resolve();\n+      let secondRetry = Promise.resolve();\n+\n+      act(() => {\n+        firstRetry = result.current.retryLastMessage();\n+      });\n+\n+      act(() => {\n+        secondRetry = result.current.retryLastMessage();\n+      });\n+\n+      expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n+\n+      await act(async () => {\n+        inflightRetry.resolve({\n+          success: true,\n+          shouldRetryWithFallback: false,\n+          accumulated: 'recovered',\n+        });\n+\n+        await Promise.all([firstRetry, secondRetry]);\n+      });\n+\n+      expect(result.current.messages).toHaveLength(2);\n+      expect(result.current.canRetry).toBe(false);\n+    });\n+\n+    it('recovers from repeated network flap retries without duplicating chat entries', async () => {\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('network flap - initial'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('network flap - retry'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      mockExecuteStreaming.mockImplementationOnce(async () => ({\n+        success: true,\n+        shouldRetryWithFallback: false,\n+        accumulated: 'eventual success',\n+      }));\n+\n+      const { result } = renderHook(() => useChat({}));\n+\n+      await act(async () => {\n+        await result.current.sendMessage('flap-safe');\n+      });\n+\n+      expect(result.current.canRetry).toBe(true);\n+      expect(result.current.messages).toHaveLength(2);\n+\n+      await act(async () => {\n+        await result.current.retryLastMessage();\n+      });\n+\n+      expect(result.current.canRetry).toBe(true);\n+      expect(result.current.messages).toHaveLength(2);\n+\n+      await act(async () => {\n+        await result.current.retryLastMessage();\n+      });\n+\n+      expect(result.current.canRetry).toBe(false);\n+      expect(result.current.messages).toHaveLength(2);\n+      expect(result.current.messages[0]).toEqual({\n+        role: 'user',\n+        content: 'flap-safe',\n+      });\n+    });\n   });\n });\n","before":"import { describe, it, expect, beforeEach, jest } from '@jest/globals';\nimport { renderHook, act } from '@testing-library/react-native';\nimport useChat from '../useChat';\n\nconst mockExecuteStreaming = jest.fn();\n\ninterface Deferred<T> {\n  promise: Promise<T>;\n  resolve: (value: T) => void;\n}\n\nconst createDeferred = <T,>(): Deferred<T> => {\n  let resolve!: (value: T) => void;\n  const promise = new Promise<T>((innerResolve) => {\n    resolve = innerResolve;\n  });\n\n  return { promise, resolve };\n};\n\n// Mock all dependencies with simpler mocks\njest.mock('@/hooks/useChatState', () => ({\n  useChatState: jest.fn(() => ({\n    provider: 'apple',\n    model: 'gpt-4',\n    isOverridden: false,\n    globalProvider: 'apple',\n    globalModel: 'gpt-4',\n    setOverride: jest.fn(),\n    clearOverride: jest.fn(),\n    syncFromDatabase: jest.fn(),\n    hasOverride: false,\n  })),\n}));\n\njest.mock('../useTitleGeneration', () => {\n  const mockTitleState = {\n    title: 'Test Chat',\n    setTitle: jest.fn(),\n    generateTitle: jest.fn(async () => 'Generated Title'),\n    resetTitle: jest.fn(),\n  };\n\n  return {\n    useTitleGeneration: jest.fn(() => mockTitleState),\n  };\n});\n\njest.mock('../useChatStreaming', () => ({\n  useChatStreaming: jest.fn(() => ({\n    executeStreaming: (...args: any[]) => mockExecuteStreaming(...args),\n    handleStreamingError: jest.fn(),\n  })),\n}));\n\njest.mock('@/providers/provider-cache', () => ({\n  getCachedModel: jest.fn(() => ({\n    provider: 'openai',\n    modelId: 'gpt-4',\n  })),\n}));\n\ndescribe('useChat', () => {\n  beforeEach(() => {\n    jest.clearAllMocks();\n    mockExecuteStreaming.mockImplementation(async (options: any) => {\n      const onThinkingChunk = options?.onThinkingChunk as ((chunk: string, accumulated: string) => void) | undefined;\n      onThinkingChunk?.('Thinking', 'Thinking');\n      return {\n        success: true,\n        shouldRetryWithFallback: false,\n        accumulated: 'Test response',\n      };\n    });\n  });\n\n  describe('basic functionality', () => {\n    it('should initialize with default values', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      expect(result.current.text).toBe('');\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.thinkingOutput).toEqual([]);\n      expect(result.current.isThinking).toBe(false);\n      expect(result.current.isStreaming).toBe(false);\n      expect(result.current.title).toBe('Test Chat');\n      expect(result.current.currentProvider).toBe('apple');\n      expect(result.current.currentModel).toBe('system-default'); // Default when no chatId\n      expect(result.current.isUsingFallback).toBe(false);\n      expect(result.current.canRetry).toBe(false);\n    });\n\n    it('should initialize with provided initial text', () => {\n      const { result } = renderHook(() => useChat({ initialText: 'Hello' }));\n\n      expect(result.current.text).toBe('Hello');\n    });\n\n    it('should update text when setText is called', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('New text');\n      });\n\n      expect(result.current.text).toBe('New text');\n    });\n\n    it('should not send empty message', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage('');\n      });\n\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.isStreaming).toBe(false);\n    });\n\n    it('should not send whitespace-only message', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('   \\n\\t  ');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.isStreaming).toBe(false);\n    });\n  });\n\n  describe('message sending', () => {\n    it('should send message and add to history', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.messages[0]).toEqual({\n        role: 'user',\n        content: 'Hello, world!',\n      });\n      expect(result.current.messages[1]).toEqual({\n        role: 'assistant',\n        content: '...',\n      });\n      expect(result.current.thinkingOutput).toEqual(['', 'Thinking']);\n      expect(result.current.text).toBe('');\n      expect(result.current.isThinking).toBe(false);\n      expect(result.current.isStreaming).toBe(false); // Streaming completes after act\n    });\n\n    it('should set isThinking while reasoning streams', async () => {\n      let resolveStreaming: (() => void) | null = null;\n      mockExecuteStreaming.mockImplementation(async (options: any) => {\n        const onThinkingChunk = options?.onThinkingChunk as ((chunk: string, accumulated: string) => void) | undefined;\n        onThinkingChunk?.('Thinking', 'Thinking');\n        await new Promise<void>((resolve) => {\n          resolveStreaming = resolve;\n        });\n        return {\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'Test response',\n        };\n      });\n\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      let sendPromise = Promise.resolve();\n      act(() => {\n        sendPromise = result.current.sendMessage();\n      });\n\n      expect(result.current.isThinking).toBe(true);\n\n      await act(async () => {\n        resolveStreaming?.();\n        await sendPromise;\n      });\n\n      expect(result.current.isThinking).toBe(false);\n    });\n\n    it('should ignore thinking output when disabled', async () => {\n      const onThinkingChunk = jest.fn();\n      const { result } = renderHook(() => useChat({\n        enableThinking: false,\n        onThinkingChunk,\n      }));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(result.current.thinkingOutput).toEqual(['', '']);\n      expect(result.current.isThinking).toBe(false);\n      expect(onThinkingChunk).not.toHaveBeenCalled();\n    });\n\n    it('should skip placeholder text when disabled', async () => {\n      const { result } = renderHook(() => useChat({ placeholder: false }));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.messages[1]).toEqual({\n        role: 'assistant',\n        content: '',\n      });\n    });\n\n    it('should handle message with override text', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('Original text');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage('Override text');\n      });\n\n      expect(result.current.messages[0]).toEqual({\n        role: 'user',\n        content: 'Override text',\n      });\n      expect(result.current.text).toBe('Original text'); // Should not clear when using override\n    });\n\n    it('should pass thinking level to streaming options', async () => {\n      const { result } = renderHook(() => useChat({ thinkingLevel: 'high' }));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(mockExecuteStreaming).toHaveBeenCalled();\n      const [options] = mockExecuteStreaming.mock.calls[0] as [{ thinkingLevel?: string }];\n      expect(options.thinkingLevel).toBe('high');\n    });\n  });\n\n  describe('state management', () => {\n    it('should reset all state to initial values', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      // Modify some state\n      act(() => {\n        result.current.setText('Some text');\n      });\n\n      // Reset\n      act(() => {\n        result.current.reset();\n      });\n\n      expect(result.current.text).toBe('');\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.thinkingOutput).toEqual([]);\n      expect(result.current.isThinking).toBe(false);\n      expect(result.current.isUsingFallback).toBe(false);\n      expect(result.current.canRetry).toBe(false);\n    });\n\n    it('should not throw when cancel is called', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      expect(() => result.current.cancel()).not.toThrow();\n    });\n  });\n\n  describe('provider configuration', () => {\n    it('should use legacy provider when no chatId provided', () => {\n      const { result } = renderHook(() => useChat({\n        providerId: 'openai' as any,\n        modelId: 'gpt-3.5',\n      }));\n\n      expect(result.current.currentProvider).toBe('openai');\n      expect(result.current.currentModel).toBe('gpt-3.5');\n    });\n\n    it('should use chat state when chatId is provided', () => {\n      const { result } = renderHook(() => useChat({\n        chatId: '123',\n        providerId: 'openai' as any, // Should be ignored\n        modelId: 'gpt-3.5',        // Should be ignored\n      }));\n\n      expect(result.current.currentProvider).toBe('apple');\n      expect(result.current.currentModel).toBe('gpt-4');\n    });\n  });\n\n  describe('title functionality', () => {\n    it('should update title when setTitle is called', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setTitle('New Title');\n      });\n\n      const { useTitleGeneration } = require('../useTitleGeneration');\n      expect(useTitleGeneration().setTitle).toHaveBeenCalledWith('New Title');\n    });\n\n    it('should generate title when generateTitle is called', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        const title = await result.current.generateTitle();\n        expect(title).toBe('Generated Title');\n      });\n\n      const { useTitleGeneration } = require('../useTitleGeneration');\n      expect(useTitleGeneration().generateTitle).toHaveBeenCalled();\n    });\n  });\n\n  describe('edge cases', () => {\n    it('should handle non-string input gracefully', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage(123 as any);\n      });\n\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.isStreaming).toBe(false);\n    });\n\n    it('keeps completion ordering stable under rapid sends', async () => {\n      const onComplete = jest.fn();\n      const first = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n      const second = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n\n      mockExecuteStreaming\n        .mockImplementationOnce(() => first.promise)\n        .mockImplementationOnce(() => second.promise);\n\n      const { result } = renderHook(() => useChat({ onComplete }));\n\n      let firstSend = Promise.resolve();\n      let secondSend = Promise.resolve();\n\n      act(() => {\n        firstSend = result.current.sendMessage('first');\n      });\n\n      act(() => {\n        secondSend = result.current.sendMessage('second');\n      });\n\n      await act(async () => {\n        first.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'first-response',\n        });\n        await firstSend;\n      });\n\n      expect(result.current.isStreaming).toBe(true);\n      expect(onComplete).toHaveBeenCalledTimes(0);\n\n      await act(async () => {\n        second.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'second-response',\n        });\n        await secondSend;\n      });\n\n      expect(result.current.isStreaming).toBe(false);\n      expect(onComplete).toHaveBeenCalledTimes(1);\n    });\n\n    it('prevents post-cancel error mutation from stale stream callbacks', async () => {\n      const onError = jest.fn();\n      const pending = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n      let capturedOptions: { onError?: (error: unknown) => void } | null = null;\n\n      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n        capturedOptions = options;\n        return pending.promise;\n      });\n\n      const { result } = renderHook(() => useChat({ onError }));\n\n      let sendPromise = Promise.resolve();\n\n      act(() => {\n        sendPromise = result.current.sendMessage('cancel-me');\n      });\n\n      act(() => {\n        result.current.cancel();\n      });\n\n      await act(async () => {\n        capturedOptions?.onError?.(new Error('late error'));\n        pending.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: '',\n        });\n        await sendPromise;\n      });\n\n      expect(result.current.errorMessage).toBeNull();\n      expect(result.current.canRetry).toBe(false);\n      expect(onError).toHaveBeenCalledTimes(0);\n    });\n  });\n});\n","after":"import { describe, it, expect, beforeEach, jest } from '@jest/globals';\nimport { renderHook, act } from '@testing-library/react-native';\nimport useChat from '../useChat';\n\nconst mockExecuteStreaming = jest.fn();\n\ninterface Deferred<T> {\n  promise: Promise<T>;\n  resolve: (value: T) => void;\n}\n\nconst createDeferred = <T,>(): Deferred<T> => {\n  let resolve!: (value: T) => void;\n  const promise = new Promise<T>((innerResolve) => {\n    resolve = innerResolve;\n  });\n\n  return { promise, resolve };\n};\n\n// Mock all dependencies with simpler mocks\njest.mock('@/hooks/useChatState', () => ({\n  useChatState: jest.fn(() => ({\n    provider: 'apple',\n    model: 'gpt-4',\n    isOverridden: false,\n    globalProvider: 'apple',\n    globalModel: 'gpt-4',\n    setOverride: jest.fn(),\n    clearOverride: jest.fn(),\n    syncFromDatabase: jest.fn(),\n    hasOverride: false,\n  })),\n}));\n\njest.mock('../useTitleGeneration', () => {\n  const mockTitleState = {\n    title: 'Test Chat',\n    setTitle: jest.fn(),\n    generateTitle: jest.fn(async () => 'Generated Title'),\n    resetTitle: jest.fn(),\n  };\n\n  return {\n    useTitleGeneration: jest.fn(() => mockTitleState),\n  };\n});\n\njest.mock('../useChatStreaming', () => ({\n  useChatStreaming: jest.fn(() => ({\n    executeStreaming: (...args: any[]) => mockExecuteStreaming(...args),\n    handleStreamingError: jest.fn(),\n  })),\n}));\n\njest.mock('@/providers/provider-cache', () => ({\n  getCachedModel: jest.fn(() => ({\n    provider: 'openai',\n    modelId: 'gpt-4',\n  })),\n}));\n\ndescribe('useChat', () => {\n  beforeEach(() => {\n    jest.clearAllMocks();\n    mockExecuteStreaming.mockImplementation(async (options: any) => {\n      const onThinkingChunk = options?.onThinkingChunk as ((chunk: string, accumulated: string) => void) | undefined;\n      onThinkingChunk?.('Thinking', 'Thinking');\n      return {\n        success: true,\n        shouldRetryWithFallback: false,\n        accumulated: 'Test response',\n      };\n    });\n  });\n\n  describe('basic functionality', () => {\n    it('should initialize with default values', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      expect(result.current.text).toBe('');\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.thinkingOutput).toEqual([]);\n      expect(result.current.isThinking).toBe(false);\n      expect(result.current.isStreaming).toBe(false);\n      expect(result.current.title).toBe('Test Chat');\n      expect(result.current.currentProvider).toBe('apple');\n      expect(result.current.currentModel).toBe('system-default'); // Default when no chatId\n      expect(result.current.isUsingFallback).toBe(false);\n      expect(result.current.canRetry).toBe(false);\n    });\n\n    it('should initialize with provided initial text', () => {\n      const { result } = renderHook(() => useChat({ initialText: 'Hello' }));\n\n      expect(result.current.text).toBe('Hello');\n    });\n\n    it('should update text when setText is called', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('New text');\n      });\n\n      expect(result.current.text).toBe('New text');\n    });\n\n    it('should not send empty message', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage('');\n      });\n\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.isStreaming).toBe(false);\n    });\n\n    it('should not send whitespace-only message', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('   \\n\\t  ');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.isStreaming).toBe(false);\n    });\n  });\n\n  describe('message sending', () => {\n    it('should send message and add to history', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.messages[0]).toEqual({\n        role: 'user',\n        content: 'Hello, world!',\n      });\n      expect(result.current.messages[1]).toEqual({\n        role: 'assistant',\n        content: '...',\n      });\n      expect(result.current.thinkingOutput).toEqual(['', 'Thinking']);\n      expect(result.current.text).toBe('');\n      expect(result.current.isThinking).toBe(false);\n      expect(result.current.isStreaming).toBe(false); // Streaming completes after act\n    });\n\n    it('should set isThinking while reasoning streams', async () => {\n      let resolveStreaming: (() => void) | null = null;\n      mockExecuteStreaming.mockImplementation(async (options: any) => {\n        const onThinkingChunk = options?.onThinkingChunk as ((chunk: string, accumulated: string) => void) | undefined;\n        onThinkingChunk?.('Thinking', 'Thinking');\n        await new Promise<void>((resolve) => {\n          resolveStreaming = resolve;\n        });\n        return {\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'Test response',\n        };\n      });\n\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      let sendPromise = Promise.resolve();\n      act(() => {\n        sendPromise = result.current.sendMessage();\n      });\n\n      expect(result.current.isThinking).toBe(true);\n\n      await act(async () => {\n        resolveStreaming?.();\n        await sendPromise;\n      });\n\n      expect(result.current.isThinking).toBe(false);\n    });\n\n    it('should ignore thinking output when disabled', async () => {\n      const onThinkingChunk = jest.fn();\n      const { result } = renderHook(() => useChat({\n        enableThinking: false,\n        onThinkingChunk,\n      }));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(result.current.thinkingOutput).toEqual(['', '']);\n      expect(result.current.isThinking).toBe(false);\n      expect(onThinkingChunk).not.toHaveBeenCalled();\n    });\n\n    it('should skip placeholder text when disabled', async () => {\n      const { result } = renderHook(() => useChat({ placeholder: false }));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.messages[1]).toEqual({\n        role: 'assistant',\n        content: '',\n      });\n    });\n\n    it('should handle message with override text', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('Original text');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage('Override text');\n      });\n\n      expect(result.current.messages[0]).toEqual({\n        role: 'user',\n        content: 'Override text',\n      });\n      expect(result.current.text).toBe('Original text'); // Should not clear when using override\n    });\n\n    it('should pass thinking level to streaming options', async () => {\n      const { result } = renderHook(() => useChat({ thinkingLevel: 'high' }));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(mockExecuteStreaming).toHaveBeenCalled();\n      const [options] = mockExecuteStreaming.mock.calls[0] as [{ thinkingLevel?: string }];\n      expect(options.thinkingLevel).toBe('high');\n    });\n  });\n\n  describe('state management', () => {\n    it('should reset all state to initial values', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      // Modify some state\n      act(() => {\n        result.current.setText('Some text');\n      });\n\n      // Reset\n      act(() => {\n        result.current.reset();\n      });\n\n      expect(result.current.text).toBe('');\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.thinkingOutput).toEqual([]);\n      expect(result.current.isThinking).toBe(false);\n      expect(result.current.isUsingFallback).toBe(false);\n      expect(result.current.canRetry).toBe(false);\n    });\n\n    it('should not throw when cancel is called', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      expect(() => result.current.cancel()).not.toThrow();\n    });\n  });\n\n  describe('provider configuration', () => {\n    it('should use legacy provider when no chatId provided', () => {\n      const { result } = renderHook(() => useChat({\n        providerId: 'openai' as any,\n        modelId: 'gpt-3.5',\n      }));\n\n      expect(result.current.currentProvider).toBe('openai');\n      expect(result.current.currentModel).toBe('gpt-3.5');\n    });\n\n    it('should use chat state when chatId is provided', () => {\n      const { result } = renderHook(() => useChat({\n        chatId: '123',\n        providerId: 'openai' as any, // Should be ignored\n        modelId: 'gpt-3.5',        // Should be ignored\n      }));\n\n      expect(result.current.currentProvider).toBe('apple');\n      expect(result.current.currentModel).toBe('gpt-4');\n    });\n  });\n\n  describe('title functionality', () => {\n    it('should update title when setTitle is called', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setTitle('New Title');\n      });\n\n      const { useTitleGeneration } = require('../useTitleGeneration');\n      expect(useTitleGeneration().setTitle).toHaveBeenCalledWith('New Title');\n    });\n\n    it('should generate title when generateTitle is called', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        const title = await result.current.generateTitle();\n        expect(title).toBe('Generated Title');\n      });\n\n      const { useTitleGeneration } = require('../useTitleGeneration');\n      expect(useTitleGeneration().generateTitle).toHaveBeenCalled();\n    });\n  });\n\n  describe('edge cases', () => {\n    it('should handle non-string input gracefully', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage(123 as any);\n      });\n\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.isStreaming).toBe(false);\n    });\n\n    it('keeps completion ordering stable under rapid sends', async () => {\n      const onComplete = jest.fn();\n      const first = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n      const second = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n\n      mockExecuteStreaming\n        .mockImplementationOnce(() => first.promise)\n        .mockImplementationOnce(() => second.promise);\n\n      const { result } = renderHook(() => useChat({ onComplete }));\n\n      let firstSend = Promise.resolve();\n      let secondSend = Promise.resolve();\n\n      act(() => {\n        firstSend = result.current.sendMessage('first');\n      });\n\n      act(() => {\n        secondSend = result.current.sendMessage('second');\n      });\n\n      await act(async () => {\n        first.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'first-response',\n        });\n        await firstSend;\n      });\n\n      expect(result.current.isStreaming).toBe(true);\n      expect(onComplete).toHaveBeenCalledTimes(0);\n\n      await act(async () => {\n        second.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'second-response',\n        });\n        await secondSend;\n      });\n\n      expect(result.current.isStreaming).toBe(false);\n      expect(onComplete).toHaveBeenCalledTimes(1);\n    });\n\n    it('prevents post-cancel error mutation from stale stream callbacks', async () => {\n      const onError = jest.fn();\n      const pending = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n      let capturedOptions: { onError?: (error: unknown) => void } | null = null;\n\n      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n        capturedOptions = options;\n        return pending.promise;\n      });\n\n      const { result } = renderHook(() => useChat({ onError }));\n\n      let sendPromise = Promise.resolve();\n\n      act(() => {\n        sendPromise = result.current.sendMessage('cancel-me');\n      });\n\n      act(() => {\n        result.current.cancel();\n      });\n\n      await act(async () => {\n        capturedOptions?.onError?.(new Error('late error'));\n        pending.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: '',\n        });\n        await sendPromise;\n      });\n\n      expect(result.current.errorMessage).toBeNull();\n      expect(result.current.canRetry).toBe(false);\n      expect(onError).toHaveBeenCalledTimes(0);\n    });\n\n    it('deduplicates quick retry taps for the same failed operation', async () => {\n      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n        options?.onError?.(new Error('network flap'));\n        return {\n          success: false,\n          shouldRetryWithFallback: false,\n          accumulated: '',\n        };\n      });\n\n      const retryDeferred = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n\n      mockExecuteStreaming.mockImplementationOnce(async () => retryDeferred.promise);\n\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage('retry me');\n      });\n\n      expect(result.current.canRetry).toBe(true);\n      expect(result.current.messages).toHaveLength(2);\n\n      let firstRetry = Promise.resolve();\n      let secondRetry = Promise.resolve();\n\n      act(() => {\n        firstRetry = result.current.retryLastMessage();\n        secondRetry = result.current.retryLastMessage();\n      });\n\n      expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n\n      await act(async () => {\n        retryDeferred.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'retry ok',\n        });\n\n        await Promise.all([firstRetry, secondRetry]);\n      });\n\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.messages[0]).toEqual({\n        role: 'user',\n        content: 'retry me',\n      });\n    });\n\n    it('keeps retry state stable when retry is tapped while a retry is inflight', async () => {\n      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n        options?.onError?.(new Error('temporary outage'));\n        return {\n          success: false,\n          shouldRetryWithFallback: false,\n          accumulated: '',\n        };\n      });\n\n      const inflightRetry = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n\n      mockExecuteStreaming.mockImplementationOnce(async () => inflightRetry.promise);\n\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage('inflight retry');\n      });\n\n      let firstRetry = Promise.resolve();\n      let secondRetry = Promise.resolve();\n\n      act(() => {\n        firstRetry = result.current.retryLastMessage();\n      });\n\n      act(() => {\n        secondRetry = result.current.retryLastMessage();\n      });\n\n      expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n\n      await act(async () => {\n        inflightRetry.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'recovered',\n        });\n\n        await Promise.all([firstRetry, secondRetry]);\n      });\n\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.canRetry).toBe(false);\n    });\n\n    it('recovers from repeated network flap retries without duplicating chat entries', async () => {\n      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n        options?.onError?.(new Error('network flap - initial'));\n        return {\n          success: false,\n          shouldRetryWithFallback: false,\n          accumulated: '',\n        };\n      });\n\n      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n        options?.onError?.(new Error('network flap - retry'));\n        return {\n          success: false,\n          shouldRetryWithFallback: false,\n          accumulated: '',\n        };\n      });\n\n      mockExecuteStreaming.mockImplementationOnce(async () => ({\n        success: true,\n        shouldRetryWithFallback: false,\n        accumulated: 'eventual success',\n      }));\n\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage('flap-safe');\n      });\n\n      expect(result.current.canRetry).toBe(true);\n      expect(result.current.messages).toHaveLength(2);\n\n      await act(async () => {\n        await result.current.retryLastMessage();\n      });\n\n      expect(result.current.canRetry).toBe(true);\n      expect(result.current.messages).toHaveLength(2);\n\n      await act(async () => {\n        await result.current.retryLastMessage();\n      });\n\n      expect(result.current.canRetry).toBe(false);\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.messages[0]).toEqual({\n        role: 'user',\n        content: 'flap-safe',\n      });\n    });\n  });\n});\n","additions":158,"deletions":0}],"diagnostics":{"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts":[{"range":{"start":{"line":46,"character":9},"end":{"line":46,"character":25}},"message":"'executeWithRetry' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":58,"character":5},"end":{"line":58,"character":17}},"message":"'ChunkHandler' is declared but never used.","severity":4,"code":6196,"source":"typescript"},{"range":{"start":{"line":152,"character":8},"end":{"line":152,"character":18}},"message":"'providerId' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/chat.types.ts","range":{"start":{"line":20,"character":6},"end":{"line":20,"character":66}}},"message":"The declaration was marked as deprecated here."}]},{"range":{"start":{"line":153,"character":8},"end":{"line":153,"character":15}},"message":"'modelId' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/chat.types.ts","range":{"start":{"line":22,"character":6},"end":{"line":22,"character":66}}},"message":"The declaration was marked as deprecated here."}]},{"range":{"start":{"line":294,"character":30},"end":{"line":294,"character":50}},"message":"'handleStreamingError' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":306,"character":21},"end":{"line":306,"character":47}},"message":"'isStreamLifecycleStreaming' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":307,"character":8},"end":{"line":307,"character":23}},"message":"'abortController' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":309,"character":8},"end":{"line":309,"character":25}},"message":"'markChunkReceived' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":310,"character":8},"end":{"line":310,"character":30}},"message":"'markDoneSignalReceived' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":311,"character":8},"end":{"line":311,"character":22}},"message":"'markCompleting' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":312,"character":8},"end":{"line":312,"character":21}},"message":"'markCompleted' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"}],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/concurrency.types.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/lib/concurrency.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChatStreaming.ts":[{"range":{"start":{"line":104,"character":26},"end":{"line":104,"character":39}},"message":"'LanguageModel' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":109,"character":9},"end":{"line":109,"character":29}},"message":"'getModelWithFallback' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":109,"character":71},"end":{"line":109,"character":91}},"message":"'hasFallbackAvailable' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":111,"character":51},"end":{"line":111,"character":66}},"message":"'shouldShowRetry' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":246,"character":34},"end":{"line":246,"character":50}},"message":"'MutableRefObject' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/%40types/react/index.d.ts","range":{"start":{"line":1658,"character":7},"end":{"line":1659,"character":5}}},"message":"The declaration was marked as deprecated here."}]}]},"truncated":false},"time":{"start":1770428737921,"end":1770428740959}},"metadata":{"openai":{"itemId":"fc_0ca15db3c40b0d910169869930ab748193a0e0547f40135a85"}}}}
{"type":"step_finish","timestamp":1770428741017,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c6b561001CITUmEbvcxmpXw","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c62a84001kUVYHUKav9ZUWY","type":"step-finish","reason":"tool-calls","snapshot":"6a5e15c0ec138d71d412d25da9427f3594ecce5c","cost":0,"tokens":{"input":4905,"output":2080,"reasoning":626,"cache":{"read":49664,"write":0}}}}
{"type":"step_start","timestamp":1770428742071,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c6b9b6001bHE7KRKCWhYQNX","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c6b5ce00106CtCGR628jn1k","type":"step-start","snapshot":"6a5e15c0ec138d71d412d25da9427f3594ecce5c"}}
{"type":"tool_use","timestamp":1770428752909,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c6e3b1001X38R4s9eBjsCbu","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c6b5ce00106CtCGR628jn1k","type":"tool","callID":"call_stWXbDnZFtAO71LpCxvROQBi","tool":"prune","state":{"status":"completed","input":{"ids":["2","3","4","5","7","8"]},"output":"Context pruning complete. Pruned 6 tool outputs.\n\nSemantically pruned (6):\n→ glob: \"**/*useChat*.ts*\" in .\n→ grep: \"retry|resend|inflight|inFlight|sendMessage|failed\" in .\n→ read: hooks/chat/useChat.ts\n→ read: hooks/chat/__tests__/useChat.test.ts\n→ read: types/concurrency.types.ts\n→ read: hooks/chat/useChatStreaming.ts","title":"","metadata":{"truncated":false},"time":{"start":1770428752834,"end":1770428752909}},"metadata":{"openai":{"itemId":"fc_00afdc8c099c176d0169869950b1308197812fbbd542f24f9e"}}}}
{"type":"tool_use","timestamp":1770428756820,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c6e354001qahL5XoDRaoa3G","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c6b5ce00106CtCGR628jn1k","type":"tool","callID":"call_8vfwwTvdZ8RZMCwJvToCZdsW","tool":"bash","state":{"status":"completed","input":{"command":"npx jest hooks/chat/__tests__/useChat.test.ts","workdir":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2","description":"Run useChat hook test file"},"output":"  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { previousState: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'new-stream-initialization' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { previousState: 'streaming' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'network flap',\n      stack: 'Error: network flap\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:459:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:465:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:478:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:477:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'temporary outage',\n      stack: 'Error: temporary outage\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:513:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:519:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:532:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:531:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'network flap - initial',\n      stack: 'Error: network flap - initial\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:564:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:570:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:590:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:589:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\nFAIL hooks/chat/__tests__/useChat.test.ts\n  useChat\n    basic functionality\n      ✓ should initialize with default values (20 ms)\n      ✓ should initialize with provided initial text (1 ms)\n      ✓ should update text when setText is called (2 ms)\n      ✓ should not send empty message (2 ms)\n      ✓ should not send whitespace-only message (1 ms)\n    message sending\n      ✓ should send message and add to history (27 ms)\n      ✓ should set isThinking while reasoning streams (6 ms)\n      ✓ should ignore thinking output when disabled (5 ms)\n      ✓ should skip placeholder text when disabled (6 ms)\n      ✓ should handle message with override text (5 ms)\n      ✓ should pass thinking level to streaming options (5 ms)\n    state management\n      ✓ should reset all state to initial values (1 ms)\n      ✓ should not throw when cancel is called (3 ms)\n    provider configuration\n      ✓ should use legacy provider when no chatId provided (1 ms)\n      ✓ should use chat state when chatId is provided\n    title functionality\n      ✓ should update title when setTitle is called (1 ms)\n      ✓ should generate title when generateTitle is called (1 ms)\n    edge cases\n      ✓ should handle non-string input gracefully (1 ms)\n      ✓ keeps completion ordering stable under rapid sends (10 ms)\n      ✓ prevents post-cancel error mutation from stale stream callbacks (7 ms)\n      ✕ deduplicates quick retry taps for the same failed operation (27 ms)\n      ✕ keeps retry state stable when retry is tapped while a retry is inflight (9 ms)\n      ✓ recovers from repeated network flap retries without duplicating chat entries (21 ms)\n\n  ● useChat › edge cases › deduplicates quick retry taps for the same failed operation\n\n    expect(jest.fn()).toHaveBeenCalledTimes(expected)\n\n    Expected number of calls: 2\n    Received number of calls: 1\n\n      490 |       });\n      491 |\n    > 492 |       expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n          |                                    ^\n      493 |\n      494 |       await act(async () => {\n      495 |         retryDeferred.resolve({\n\n      at Object.toHaveBeenCalledTimes (hooks/chat/__tests__/useChat.test.ts:492:36)\n      at asyncGeneratorStep (node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\n      at _next (node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\n\n  ● useChat › edge cases › keeps retry state stable when retry is tapped while a retry is inflight\n\n    expect(jest.fn()).toHaveBeenCalledTimes(expected)\n\n    Expected number of calls: 2\n    Received number of calls: 1\n\n      544 |       });\n      545 |\n    > 546 |       expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n          |                                    ^\n      547 |\n      548 |       await act(async () => {\n      549 |         inflightRetry.resolve({\n\n      at Object.toHaveBeenCalledTimes (hooks/chat/__tests__/useChat.test.ts:546:36)\n      at asyncGeneratorStep (node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\n      at _next (node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\n\nTest Suites: 1 failed, 1 total\nTests:       2 failed, 21 passed, 23 total\nSnapshots:   0 total\nTime:        1.347 s\nRan all test suites matching /hooks\\/chat\\/__tests__\\/useChat.test.ts/i.\n","title":"Run useChat hook test file","metadata":{"output":"  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { previousState: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'new-stream-initialization' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { previousState: 'streaming' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'network flap',\n      stack: 'Error: network flap\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:459:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:465:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:478:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:477:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'temporary outage',\n      stack: 'Error: temporary outage\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:513:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:519:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:532:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:531:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'network flap - initial',\n      stack: 'Error: network flap - initial\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:564:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:570:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:590:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:589:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\nFAIL hooks/chat/__tests__/useChat.test.ts\n  useChat\n    basic functionality\n      ✓ should initialize with default values (20 ms)\n      ✓ should initialize with provided initial text (1 ms)\n      ✓ should update text when setText is called (2 ms)\n      ✓ should not send empty message (2 ms)\n      ✓ should not send whitespace-only message (1 ms)\n    message sending\n      ✓ should send message and add to history (27 ms)\n      ✓ should set isThinking while reasoning streams (6 ms)\n      ✓ should ignore thinking output when disabled (5 ms)\n      ✓ should skip placeholder text when disabled (6 ms)\n      ✓ should handle message with override text (5 ms)\n      ✓ should pass thinking level to streaming options (5 ms)\n    state management\n      ✓ should reset all state to initial values (1 ms)\n      ✓ should not throw when cancel is called (3 ms)\n    provider configuration\n      ✓ should use legacy provider when no chatId provided (1 ms)\n      ✓ should use chat state when chatId is provided\n    title functionality\n      ✓ should update title when setTitle is called (1 ms)\n      ✓ should generate title when generateTitle is called (1 ms)\n    edge cases\n      ✓ should handle non-string input gracefully (1 ms)\n      ✓ keeps completion ordering stable under rapid sends (10 ms)\n      ✓ prevents post-cancel error mutation from stale stream callbacks (7 ms)\n      ✕ deduplicates quick retry taps for the same failed operation (27 ms)\n      ✕ keeps retry state stable when retry is tapped while a retry is inflight (9 ms)\n      ✓ recovers from repeated network flap retries without duplicating chat entries (21 ms)\n\n  ● useChat › edge cases › deduplicates quick retry taps for the same failed operation\n\n    expect(jest.fn()).toHaveBeenCalledTimes(expected)\n\n    Expected number of calls: 2\n    Received number of calls: 1\n\n      490 |       });\n      491 |\n    > 492 |       expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n          |                                    ^\n      493 |\n      494 |       await act(async () => {\n      495 |         retryDeferred.resolve({\n\n      at Object.toH\n\n...","exit":1,"description":"Run useChat hook test file","truncated":false},"time":{"start":1770428752786,"end":1770428756819}},"metadata":{"openai":{"itemId":"fc_00afdc8c099c176d0169869950b12081979f5f1474b52feced"}}}}
{"type":"step_finish","timestamp":1770428756863,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c6f35400160PBsgmXqhqK06","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c6b5ce00106CtCGR628jn1k","type":"step-finish","reason":"tool-calls","snapshot":"6a5e15c0ec138d71d412d25da9427f3594ecce5c","cost":0,"tokens":{"input":56711,"output":410,"reasoning":309,"cache":{"read":0,"write":0}}}}
{"type":"step_start","timestamp":1770428757430,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c6f5b50018DNsiZH4W6Nwqi","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c6f3b3001aNXGaxTsfbPNtJ","type":"step-start","snapshot":"6a5e15c0ec138d71d412d25da9427f3594ecce5c"}}
{"type":"tool_use","timestamp":1770428772318,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c71c4f001XKpzcYmP1mlOi4","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c6f3b3001aNXGaxTsfbPNtJ","type":"tool","callID":"call_gCw3ZQ3esbbD8VlpwjvM02m2","tool":"apply_patch","state":{"status":"completed","input":{"patchText":"*** Begin Patch\n*** Update File: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n@@\n       act(() => {\n         firstRetry = result.current.retryLastMessage();\n         secondRetry = result.current.retryLastMessage();\n       });\n+\n+      await act(async () => {\n+        await Promise.resolve();\n+      });\n \n       expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n@@\n       act(() => {\n         secondRetry = result.current.retryLastMessage();\n       });\n+\n+      await act(async () => {\n+        await Promise.resolve();\n+      });\n \n       expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n*** End Patch"},"output":"Success. Updated the following files:\nM hooks/chat/__tests__/useChat.test.ts","title":"Success. Updated the following files:\nM hooks/chat/__tests__/useChat.test.ts","metadata":{"diff":"Index: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n===================================================================\n--- /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n+++ /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n@@ -488,8 +488,12 @@\n   firstRetry = result.current.retryLastMessage();\n   secondRetry = result.current.retryLastMessage();\n });\n \n+await act(async () => {\n+  await Promise.resolve();\n+});\n+\n expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n \n await act(async () => {\n   retryDeferred.resolve({\n@@ -542,8 +546,12 @@\n act(() => {\n   secondRetry = result.current.retryLastMessage();\n });\n \n+await act(async () => {\n+  await Promise.resolve();\n+});\n+\n expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n \n await act(async () => {\n   inflightRetry.resolve({\n\n","files":[{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts","relativePath":"hooks/chat/__tests__/useChat.test.ts","type":"update","diff":"Index: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n===================================================================\n--- /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n+++ /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n@@ -488,8 +488,12 @@\n   firstRetry = result.current.retryLastMessage();\n   secondRetry = result.current.retryLastMessage();\n });\n \n+await act(async () => {\n+  await Promise.resolve();\n+});\n+\n expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n \n await act(async () => {\n   retryDeferred.resolve({\n@@ -542,8 +546,12 @@\n act(() => {\n   secondRetry = result.current.retryLastMessage();\n });\n \n+await act(async () => {\n+  await Promise.resolve();\n+});\n+\n expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n \n await act(async () => {\n   inflightRetry.resolve({\n","before":"import { describe, it, expect, beforeEach, jest } from '@jest/globals';\nimport { renderHook, act } from '@testing-library/react-native';\nimport useChat from '../useChat';\n\nconst mockExecuteStreaming = jest.fn();\n\ninterface Deferred<T> {\n  promise: Promise<T>;\n  resolve: (value: T) => void;\n}\n\nconst createDeferred = <T,>(): Deferred<T> => {\n  let resolve!: (value: T) => void;\n  const promise = new Promise<T>((innerResolve) => {\n    resolve = innerResolve;\n  });\n\n  return { promise, resolve };\n};\n\n// Mock all dependencies with simpler mocks\njest.mock('@/hooks/useChatState', () => ({\n  useChatState: jest.fn(() => ({\n    provider: 'apple',\n    model: 'gpt-4',\n    isOverridden: false,\n    globalProvider: 'apple',\n    globalModel: 'gpt-4',\n    setOverride: jest.fn(),\n    clearOverride: jest.fn(),\n    syncFromDatabase: jest.fn(),\n    hasOverride: false,\n  })),\n}));\n\njest.mock('../useTitleGeneration', () => {\n  const mockTitleState = {\n    title: 'Test Chat',\n    setTitle: jest.fn(),\n    generateTitle: jest.fn(async () => 'Generated Title'),\n    resetTitle: jest.fn(),\n  };\n\n  return {\n    useTitleGeneration: jest.fn(() => mockTitleState),\n  };\n});\n\njest.mock('../useChatStreaming', () => ({\n  useChatStreaming: jest.fn(() => ({\n    executeStreaming: (...args: any[]) => mockExecuteStreaming(...args),\n    handleStreamingError: jest.fn(),\n  })),\n}));\n\njest.mock('@/providers/provider-cache', () => ({\n  getCachedModel: jest.fn(() => ({\n    provider: 'openai',\n    modelId: 'gpt-4',\n  })),\n}));\n\ndescribe('useChat', () => {\n  beforeEach(() => {\n    jest.clearAllMocks();\n    mockExecuteStreaming.mockImplementation(async (options: any) => {\n      const onThinkingChunk = options?.onThinkingChunk as ((chunk: string, accumulated: string) => void) | undefined;\n      onThinkingChunk?.('Thinking', 'Thinking');\n      return {\n        success: true,\n        shouldRetryWithFallback: false,\n        accumulated: 'Test response',\n      };\n    });\n  });\n\n  describe('basic functionality', () => {\n    it('should initialize with default values', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      expect(result.current.text).toBe('');\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.thinkingOutput).toEqual([]);\n      expect(result.current.isThinking).toBe(false);\n      expect(result.current.isStreaming).toBe(false);\n      expect(result.current.title).toBe('Test Chat');\n      expect(result.current.currentProvider).toBe('apple');\n      expect(result.current.currentModel).toBe('system-default'); // Default when no chatId\n      expect(result.current.isUsingFallback).toBe(false);\n      expect(result.current.canRetry).toBe(false);\n    });\n\n    it('should initialize with provided initial text', () => {\n      const { result } = renderHook(() => useChat({ initialText: 'Hello' }));\n\n      expect(result.current.text).toBe('Hello');\n    });\n\n    it('should update text when setText is called', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('New text');\n      });\n\n      expect(result.current.text).toBe('New text');\n    });\n\n    it('should not send empty message', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage('');\n      });\n\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.isStreaming).toBe(false);\n    });\n\n    it('should not send whitespace-only message', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('   \\n\\t  ');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.isStreaming).toBe(false);\n    });\n  });\n\n  describe('message sending', () => {\n    it('should send message and add to history', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.messages[0]).toEqual({\n        role: 'user',\n        content: 'Hello, world!',\n      });\n      expect(result.current.messages[1]).toEqual({\n        role: 'assistant',\n        content: '...',\n      });\n      expect(result.current.thinkingOutput).toEqual(['', 'Thinking']);\n      expect(result.current.text).toBe('');\n      expect(result.current.isThinking).toBe(false);\n      expect(result.current.isStreaming).toBe(false); // Streaming completes after act\n    });\n\n    it('should set isThinking while reasoning streams', async () => {\n      let resolveStreaming: (() => void) | null = null;\n      mockExecuteStreaming.mockImplementation(async (options: any) => {\n        const onThinkingChunk = options?.onThinkingChunk as ((chunk: string, accumulated: string) => void) | undefined;\n        onThinkingChunk?.('Thinking', 'Thinking');\n        await new Promise<void>((resolve) => {\n          resolveStreaming = resolve;\n        });\n        return {\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'Test response',\n        };\n      });\n\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      let sendPromise = Promise.resolve();\n      act(() => {\n        sendPromise = result.current.sendMessage();\n      });\n\n      expect(result.current.isThinking).toBe(true);\n\n      await act(async () => {\n        resolveStreaming?.();\n        await sendPromise;\n      });\n\n      expect(result.current.isThinking).toBe(false);\n    });\n\n    it('should ignore thinking output when disabled', async () => {\n      const onThinkingChunk = jest.fn();\n      const { result } = renderHook(() => useChat({\n        enableThinking: false,\n        onThinkingChunk,\n      }));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(result.current.thinkingOutput).toEqual(['', '']);\n      expect(result.current.isThinking).toBe(false);\n      expect(onThinkingChunk).not.toHaveBeenCalled();\n    });\n\n    it('should skip placeholder text when disabled', async () => {\n      const { result } = renderHook(() => useChat({ placeholder: false }));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.messages[1]).toEqual({\n        role: 'assistant',\n        content: '',\n      });\n    });\n\n    it('should handle message with override text', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('Original text');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage('Override text');\n      });\n\n      expect(result.current.messages[0]).toEqual({\n        role: 'user',\n        content: 'Override text',\n      });\n      expect(result.current.text).toBe('Original text'); // Should not clear when using override\n    });\n\n    it('should pass thinking level to streaming options', async () => {\n      const { result } = renderHook(() => useChat({ thinkingLevel: 'high' }));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(mockExecuteStreaming).toHaveBeenCalled();\n      const [options] = mockExecuteStreaming.mock.calls[0] as [{ thinkingLevel?: string }];\n      expect(options.thinkingLevel).toBe('high');\n    });\n  });\n\n  describe('state management', () => {\n    it('should reset all state to initial values', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      // Modify some state\n      act(() => {\n        result.current.setText('Some text');\n      });\n\n      // Reset\n      act(() => {\n        result.current.reset();\n      });\n\n      expect(result.current.text).toBe('');\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.thinkingOutput).toEqual([]);\n      expect(result.current.isThinking).toBe(false);\n      expect(result.current.isUsingFallback).toBe(false);\n      expect(result.current.canRetry).toBe(false);\n    });\n\n    it('should not throw when cancel is called', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      expect(() => result.current.cancel()).not.toThrow();\n    });\n  });\n\n  describe('provider configuration', () => {\n    it('should use legacy provider when no chatId provided', () => {\n      const { result } = renderHook(() => useChat({\n        providerId: 'openai' as any,\n        modelId: 'gpt-3.5',\n      }));\n\n      expect(result.current.currentProvider).toBe('openai');\n      expect(result.current.currentModel).toBe('gpt-3.5');\n    });\n\n    it('should use chat state when chatId is provided', () => {\n      const { result } = renderHook(() => useChat({\n        chatId: '123',\n        providerId: 'openai' as any, // Should be ignored\n        modelId: 'gpt-3.5',        // Should be ignored\n      }));\n\n      expect(result.current.currentProvider).toBe('apple');\n      expect(result.current.currentModel).toBe('gpt-4');\n    });\n  });\n\n  describe('title functionality', () => {\n    it('should update title when setTitle is called', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setTitle('New Title');\n      });\n\n      const { useTitleGeneration } = require('../useTitleGeneration');\n      expect(useTitleGeneration().setTitle).toHaveBeenCalledWith('New Title');\n    });\n\n    it('should generate title when generateTitle is called', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        const title = await result.current.generateTitle();\n        expect(title).toBe('Generated Title');\n      });\n\n      const { useTitleGeneration } = require('../useTitleGeneration');\n      expect(useTitleGeneration().generateTitle).toHaveBeenCalled();\n    });\n  });\n\n  describe('edge cases', () => {\n    it('should handle non-string input gracefully', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage(123 as any);\n      });\n\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.isStreaming).toBe(false);\n    });\n\n    it('keeps completion ordering stable under rapid sends', async () => {\n      const onComplete = jest.fn();\n      const first = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n      const second = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n\n      mockExecuteStreaming\n        .mockImplementationOnce(() => first.promise)\n        .mockImplementationOnce(() => second.promise);\n\n      const { result } = renderHook(() => useChat({ onComplete }));\n\n      let firstSend = Promise.resolve();\n      let secondSend = Promise.resolve();\n\n      act(() => {\n        firstSend = result.current.sendMessage('first');\n      });\n\n      act(() => {\n        secondSend = result.current.sendMessage('second');\n      });\n\n      await act(async () => {\n        first.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'first-response',\n        });\n        await firstSend;\n      });\n\n      expect(result.current.isStreaming).toBe(true);\n      expect(onComplete).toHaveBeenCalledTimes(0);\n\n      await act(async () => {\n        second.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'second-response',\n        });\n        await secondSend;\n      });\n\n      expect(result.current.isStreaming).toBe(false);\n      expect(onComplete).toHaveBeenCalledTimes(1);\n    });\n\n    it('prevents post-cancel error mutation from stale stream callbacks', async () => {\n      const onError = jest.fn();\n      const pending = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n      let capturedOptions: { onError?: (error: unknown) => void } | null = null;\n\n      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n        capturedOptions = options;\n        return pending.promise;\n      });\n\n      const { result } = renderHook(() => useChat({ onError }));\n\n      let sendPromise = Promise.resolve();\n\n      act(() => {\n        sendPromise = result.current.sendMessage('cancel-me');\n      });\n\n      act(() => {\n        result.current.cancel();\n      });\n\n      await act(async () => {\n        capturedOptions?.onError?.(new Error('late error'));\n        pending.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: '',\n        });\n        await sendPromise;\n      });\n\n      expect(result.current.errorMessage).toBeNull();\n      expect(result.current.canRetry).toBe(false);\n      expect(onError).toHaveBeenCalledTimes(0);\n    });\n\n    it('deduplicates quick retry taps for the same failed operation', async () => {\n      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n        options?.onError?.(new Error('network flap'));\n        return {\n          success: false,\n          shouldRetryWithFallback: false,\n          accumulated: '',\n        };\n      });\n\n      const retryDeferred = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n\n      mockExecuteStreaming.mockImplementationOnce(async () => retryDeferred.promise);\n\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage('retry me');\n      });\n\n      expect(result.current.canRetry).toBe(true);\n      expect(result.current.messages).toHaveLength(2);\n\n      let firstRetry = Promise.resolve();\n      let secondRetry = Promise.resolve();\n\n      act(() => {\n        firstRetry = result.current.retryLastMessage();\n        secondRetry = result.current.retryLastMessage();\n      });\n\n      expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n\n      await act(async () => {\n        retryDeferred.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'retry ok',\n        });\n\n        await Promise.all([firstRetry, secondRetry]);\n      });\n\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.messages[0]).toEqual({\n        role: 'user',\n        content: 'retry me',\n      });\n    });\n\n    it('keeps retry state stable when retry is tapped while a retry is inflight', async () => {\n      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n        options?.onError?.(new Error('temporary outage'));\n        return {\n          success: false,\n          shouldRetryWithFallback: false,\n          accumulated: '',\n        };\n      });\n\n      const inflightRetry = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n\n      mockExecuteStreaming.mockImplementationOnce(async () => inflightRetry.promise);\n\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage('inflight retry');\n      });\n\n      let firstRetry = Promise.resolve();\n      let secondRetry = Promise.resolve();\n\n      act(() => {\n        firstRetry = result.current.retryLastMessage();\n      });\n\n      act(() => {\n        secondRetry = result.current.retryLastMessage();\n      });\n\n      expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n\n      await act(async () => {\n        inflightRetry.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'recovered',\n        });\n\n        await Promise.all([firstRetry, secondRetry]);\n      });\n\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.canRetry).toBe(false);\n    });\n\n    it('recovers from repeated network flap retries without duplicating chat entries', async () => {\n      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n        options?.onError?.(new Error('network flap - initial'));\n        return {\n          success: false,\n          shouldRetryWithFallback: false,\n          accumulated: '',\n        };\n      });\n\n      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n        options?.onError?.(new Error('network flap - retry'));\n        return {\n          success: false,\n          shouldRetryWithFallback: false,\n          accumulated: '',\n        };\n      });\n\n      mockExecuteStreaming.mockImplementationOnce(async () => ({\n        success: true,\n        shouldRetryWithFallback: false,\n        accumulated: 'eventual success',\n      }));\n\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage('flap-safe');\n      });\n\n      expect(result.current.canRetry).toBe(true);\n      expect(result.current.messages).toHaveLength(2);\n\n      await act(async () => {\n        await result.current.retryLastMessage();\n      });\n\n      expect(result.current.canRetry).toBe(true);\n      expect(result.current.messages).toHaveLength(2);\n\n      await act(async () => {\n        await result.current.retryLastMessage();\n      });\n\n      expect(result.current.canRetry).toBe(false);\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.messages[0]).toEqual({\n        role: 'user',\n        content: 'flap-safe',\n      });\n    });\n  });\n});\n","after":"import { describe, it, expect, beforeEach, jest } from '@jest/globals';\nimport { renderHook, act } from '@testing-library/react-native';\nimport useChat from '../useChat';\n\nconst mockExecuteStreaming = jest.fn();\n\ninterface Deferred<T> {\n  promise: Promise<T>;\n  resolve: (value: T) => void;\n}\n\nconst createDeferred = <T,>(): Deferred<T> => {\n  let resolve!: (value: T) => void;\n  const promise = new Promise<T>((innerResolve) => {\n    resolve = innerResolve;\n  });\n\n  return { promise, resolve };\n};\n\n// Mock all dependencies with simpler mocks\njest.mock('@/hooks/useChatState', () => ({\n  useChatState: jest.fn(() => ({\n    provider: 'apple',\n    model: 'gpt-4',\n    isOverridden: false,\n    globalProvider: 'apple',\n    globalModel: 'gpt-4',\n    setOverride: jest.fn(),\n    clearOverride: jest.fn(),\n    syncFromDatabase: jest.fn(),\n    hasOverride: false,\n  })),\n}));\n\njest.mock('../useTitleGeneration', () => {\n  const mockTitleState = {\n    title: 'Test Chat',\n    setTitle: jest.fn(),\n    generateTitle: jest.fn(async () => 'Generated Title'),\n    resetTitle: jest.fn(),\n  };\n\n  return {\n    useTitleGeneration: jest.fn(() => mockTitleState),\n  };\n});\n\njest.mock('../useChatStreaming', () => ({\n  useChatStreaming: jest.fn(() => ({\n    executeStreaming: (...args: any[]) => mockExecuteStreaming(...args),\n    handleStreamingError: jest.fn(),\n  })),\n}));\n\njest.mock('@/providers/provider-cache', () => ({\n  getCachedModel: jest.fn(() => ({\n    provider: 'openai',\n    modelId: 'gpt-4',\n  })),\n}));\n\ndescribe('useChat', () => {\n  beforeEach(() => {\n    jest.clearAllMocks();\n    mockExecuteStreaming.mockImplementation(async (options: any) => {\n      const onThinkingChunk = options?.onThinkingChunk as ((chunk: string, accumulated: string) => void) | undefined;\n      onThinkingChunk?.('Thinking', 'Thinking');\n      return {\n        success: true,\n        shouldRetryWithFallback: false,\n        accumulated: 'Test response',\n      };\n    });\n  });\n\n  describe('basic functionality', () => {\n    it('should initialize with default values', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      expect(result.current.text).toBe('');\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.thinkingOutput).toEqual([]);\n      expect(result.current.isThinking).toBe(false);\n      expect(result.current.isStreaming).toBe(false);\n      expect(result.current.title).toBe('Test Chat');\n      expect(result.current.currentProvider).toBe('apple');\n      expect(result.current.currentModel).toBe('system-default'); // Default when no chatId\n      expect(result.current.isUsingFallback).toBe(false);\n      expect(result.current.canRetry).toBe(false);\n    });\n\n    it('should initialize with provided initial text', () => {\n      const { result } = renderHook(() => useChat({ initialText: 'Hello' }));\n\n      expect(result.current.text).toBe('Hello');\n    });\n\n    it('should update text when setText is called', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('New text');\n      });\n\n      expect(result.current.text).toBe('New text');\n    });\n\n    it('should not send empty message', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage('');\n      });\n\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.isStreaming).toBe(false);\n    });\n\n    it('should not send whitespace-only message', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('   \\n\\t  ');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.isStreaming).toBe(false);\n    });\n  });\n\n  describe('message sending', () => {\n    it('should send message and add to history', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.messages[0]).toEqual({\n        role: 'user',\n        content: 'Hello, world!',\n      });\n      expect(result.current.messages[1]).toEqual({\n        role: 'assistant',\n        content: '...',\n      });\n      expect(result.current.thinkingOutput).toEqual(['', 'Thinking']);\n      expect(result.current.text).toBe('');\n      expect(result.current.isThinking).toBe(false);\n      expect(result.current.isStreaming).toBe(false); // Streaming completes after act\n    });\n\n    it('should set isThinking while reasoning streams', async () => {\n      let resolveStreaming: (() => void) | null = null;\n      mockExecuteStreaming.mockImplementation(async (options: any) => {\n        const onThinkingChunk = options?.onThinkingChunk as ((chunk: string, accumulated: string) => void) | undefined;\n        onThinkingChunk?.('Thinking', 'Thinking');\n        await new Promise<void>((resolve) => {\n          resolveStreaming = resolve;\n        });\n        return {\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'Test response',\n        };\n      });\n\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      let sendPromise = Promise.resolve();\n      act(() => {\n        sendPromise = result.current.sendMessage();\n      });\n\n      expect(result.current.isThinking).toBe(true);\n\n      await act(async () => {\n        resolveStreaming?.();\n        await sendPromise;\n      });\n\n      expect(result.current.isThinking).toBe(false);\n    });\n\n    it('should ignore thinking output when disabled', async () => {\n      const onThinkingChunk = jest.fn();\n      const { result } = renderHook(() => useChat({\n        enableThinking: false,\n        onThinkingChunk,\n      }));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(result.current.thinkingOutput).toEqual(['', '']);\n      expect(result.current.isThinking).toBe(false);\n      expect(onThinkingChunk).not.toHaveBeenCalled();\n    });\n\n    it('should skip placeholder text when disabled', async () => {\n      const { result } = renderHook(() => useChat({ placeholder: false }));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.messages[1]).toEqual({\n        role: 'assistant',\n        content: '',\n      });\n    });\n\n    it('should handle message with override text', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setText('Original text');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage('Override text');\n      });\n\n      expect(result.current.messages[0]).toEqual({\n        role: 'user',\n        content: 'Override text',\n      });\n      expect(result.current.text).toBe('Original text'); // Should not clear when using override\n    });\n\n    it('should pass thinking level to streaming options', async () => {\n      const { result } = renderHook(() => useChat({ thinkingLevel: 'high' }));\n\n      act(() => {\n        result.current.setText('Hello, world!');\n      });\n\n      await act(async () => {\n        await result.current.sendMessage();\n      });\n\n      expect(mockExecuteStreaming).toHaveBeenCalled();\n      const [options] = mockExecuteStreaming.mock.calls[0] as [{ thinkingLevel?: string }];\n      expect(options.thinkingLevel).toBe('high');\n    });\n  });\n\n  describe('state management', () => {\n    it('should reset all state to initial values', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      // Modify some state\n      act(() => {\n        result.current.setText('Some text');\n      });\n\n      // Reset\n      act(() => {\n        result.current.reset();\n      });\n\n      expect(result.current.text).toBe('');\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.thinkingOutput).toEqual([]);\n      expect(result.current.isThinking).toBe(false);\n      expect(result.current.isUsingFallback).toBe(false);\n      expect(result.current.canRetry).toBe(false);\n    });\n\n    it('should not throw when cancel is called', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      expect(() => result.current.cancel()).not.toThrow();\n    });\n  });\n\n  describe('provider configuration', () => {\n    it('should use legacy provider when no chatId provided', () => {\n      const { result } = renderHook(() => useChat({\n        providerId: 'openai' as any,\n        modelId: 'gpt-3.5',\n      }));\n\n      expect(result.current.currentProvider).toBe('openai');\n      expect(result.current.currentModel).toBe('gpt-3.5');\n    });\n\n    it('should use chat state when chatId is provided', () => {\n      const { result } = renderHook(() => useChat({\n        chatId: '123',\n        providerId: 'openai' as any, // Should be ignored\n        modelId: 'gpt-3.5',        // Should be ignored\n      }));\n\n      expect(result.current.currentProvider).toBe('apple');\n      expect(result.current.currentModel).toBe('gpt-4');\n    });\n  });\n\n  describe('title functionality', () => {\n    it('should update title when setTitle is called', () => {\n      const { result } = renderHook(() => useChat({}));\n\n      act(() => {\n        result.current.setTitle('New Title');\n      });\n\n      const { useTitleGeneration } = require('../useTitleGeneration');\n      expect(useTitleGeneration().setTitle).toHaveBeenCalledWith('New Title');\n    });\n\n    it('should generate title when generateTitle is called', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        const title = await result.current.generateTitle();\n        expect(title).toBe('Generated Title');\n      });\n\n      const { useTitleGeneration } = require('../useTitleGeneration');\n      expect(useTitleGeneration().generateTitle).toHaveBeenCalled();\n    });\n  });\n\n  describe('edge cases', () => {\n    it('should handle non-string input gracefully', async () => {\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage(123 as any);\n      });\n\n      expect(result.current.messages).toEqual([]);\n      expect(result.current.isStreaming).toBe(false);\n    });\n\n    it('keeps completion ordering stable under rapid sends', async () => {\n      const onComplete = jest.fn();\n      const first = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n      const second = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n\n      mockExecuteStreaming\n        .mockImplementationOnce(() => first.promise)\n        .mockImplementationOnce(() => second.promise);\n\n      const { result } = renderHook(() => useChat({ onComplete }));\n\n      let firstSend = Promise.resolve();\n      let secondSend = Promise.resolve();\n\n      act(() => {\n        firstSend = result.current.sendMessage('first');\n      });\n\n      act(() => {\n        secondSend = result.current.sendMessage('second');\n      });\n\n      await act(async () => {\n        first.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'first-response',\n        });\n        await firstSend;\n      });\n\n      expect(result.current.isStreaming).toBe(true);\n      expect(onComplete).toHaveBeenCalledTimes(0);\n\n      await act(async () => {\n        second.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'second-response',\n        });\n        await secondSend;\n      });\n\n      expect(result.current.isStreaming).toBe(false);\n      expect(onComplete).toHaveBeenCalledTimes(1);\n    });\n\n    it('prevents post-cancel error mutation from stale stream callbacks', async () => {\n      const onError = jest.fn();\n      const pending = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n      let capturedOptions: { onError?: (error: unknown) => void } | null = null;\n\n      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n        capturedOptions = options;\n        return pending.promise;\n      });\n\n      const { result } = renderHook(() => useChat({ onError }));\n\n      let sendPromise = Promise.resolve();\n\n      act(() => {\n        sendPromise = result.current.sendMessage('cancel-me');\n      });\n\n      act(() => {\n        result.current.cancel();\n      });\n\n      await act(async () => {\n        capturedOptions?.onError?.(new Error('late error'));\n        pending.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: '',\n        });\n        await sendPromise;\n      });\n\n      expect(result.current.errorMessage).toBeNull();\n      expect(result.current.canRetry).toBe(false);\n      expect(onError).toHaveBeenCalledTimes(0);\n    });\n\n    it('deduplicates quick retry taps for the same failed operation', async () => {\n      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n        options?.onError?.(new Error('network flap'));\n        return {\n          success: false,\n          shouldRetryWithFallback: false,\n          accumulated: '',\n        };\n      });\n\n      const retryDeferred = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n\n      mockExecuteStreaming.mockImplementationOnce(async () => retryDeferred.promise);\n\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage('retry me');\n      });\n\n      expect(result.current.canRetry).toBe(true);\n      expect(result.current.messages).toHaveLength(2);\n\n      let firstRetry = Promise.resolve();\n      let secondRetry = Promise.resolve();\n\n      act(() => {\n        firstRetry = result.current.retryLastMessage();\n        secondRetry = result.current.retryLastMessage();\n      });\n\n      await act(async () => {\n        await Promise.resolve();\n      });\n\n      expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n\n      await act(async () => {\n        retryDeferred.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'retry ok',\n        });\n\n        await Promise.all([firstRetry, secondRetry]);\n      });\n\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.messages[0]).toEqual({\n        role: 'user',\n        content: 'retry me',\n      });\n    });\n\n    it('keeps retry state stable when retry is tapped while a retry is inflight', async () => {\n      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n        options?.onError?.(new Error('temporary outage'));\n        return {\n          success: false,\n          shouldRetryWithFallback: false,\n          accumulated: '',\n        };\n      });\n\n      const inflightRetry = createDeferred<{\n        success: boolean;\n        shouldRetryWithFallback: boolean;\n        accumulated: string;\n      }>();\n\n      mockExecuteStreaming.mockImplementationOnce(async () => inflightRetry.promise);\n\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage('inflight retry');\n      });\n\n      let firstRetry = Promise.resolve();\n      let secondRetry = Promise.resolve();\n\n      act(() => {\n        firstRetry = result.current.retryLastMessage();\n      });\n\n      act(() => {\n        secondRetry = result.current.retryLastMessage();\n      });\n\n      await act(async () => {\n        await Promise.resolve();\n      });\n\n      expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n\n      await act(async () => {\n        inflightRetry.resolve({\n          success: true,\n          shouldRetryWithFallback: false,\n          accumulated: 'recovered',\n        });\n\n        await Promise.all([firstRetry, secondRetry]);\n      });\n\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.canRetry).toBe(false);\n    });\n\n    it('recovers from repeated network flap retries without duplicating chat entries', async () => {\n      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n        options?.onError?.(new Error('network flap - initial'));\n        return {\n          success: false,\n          shouldRetryWithFallback: false,\n          accumulated: '',\n        };\n      });\n\n      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n        options?.onError?.(new Error('network flap - retry'));\n        return {\n          success: false,\n          shouldRetryWithFallback: false,\n          accumulated: '',\n        };\n      });\n\n      mockExecuteStreaming.mockImplementationOnce(async () => ({\n        success: true,\n        shouldRetryWithFallback: false,\n        accumulated: 'eventual success',\n      }));\n\n      const { result } = renderHook(() => useChat({}));\n\n      await act(async () => {\n        await result.current.sendMessage('flap-safe');\n      });\n\n      expect(result.current.canRetry).toBe(true);\n      expect(result.current.messages).toHaveLength(2);\n\n      await act(async () => {\n        await result.current.retryLastMessage();\n      });\n\n      expect(result.current.canRetry).toBe(true);\n      expect(result.current.messages).toHaveLength(2);\n\n      await act(async () => {\n        await result.current.retryLastMessage();\n      });\n\n      expect(result.current.canRetry).toBe(false);\n      expect(result.current.messages).toHaveLength(2);\n      expect(result.current.messages[0]).toEqual({\n        role: 'user',\n        content: 'flap-safe',\n      });\n    });\n  });\n});\n","additions":8,"deletions":0}],"diagnostics":{"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts":[{"range":{"start":{"line":46,"character":9},"end":{"line":46,"character":25}},"message":"'executeWithRetry' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":58,"character":5},"end":{"line":58,"character":17}},"message":"'ChunkHandler' is declared but never used.","severity":4,"code":6196,"source":"typescript"},{"range":{"start":{"line":152,"character":8},"end":{"line":152,"character":18}},"message":"'providerId' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/chat.types.ts","range":{"start":{"line":20,"character":6},"end":{"line":20,"character":66}}},"message":"The declaration was marked as deprecated here."}]},{"range":{"start":{"line":153,"character":8},"end":{"line":153,"character":15}},"message":"'modelId' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/chat.types.ts","range":{"start":{"line":22,"character":6},"end":{"line":22,"character":66}}},"message":"The declaration was marked as deprecated here."}]},{"range":{"start":{"line":294,"character":30},"end":{"line":294,"character":50}},"message":"'handleStreamingError' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":306,"character":21},"end":{"line":306,"character":47}},"message":"'isStreamLifecycleStreaming' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":307,"character":8},"end":{"line":307,"character":23}},"message":"'abortController' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":309,"character":8},"end":{"line":309,"character":25}},"message":"'markChunkReceived' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":310,"character":8},"end":{"line":310,"character":30}},"message":"'markDoneSignalReceived' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":311,"character":8},"end":{"line":311,"character":22}},"message":"'markCompleting' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":312,"character":8},"end":{"line":312,"character":21}},"message":"'markCompleted' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"}],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/concurrency.types.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/lib/concurrency.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChatStreaming.ts":[{"range":{"start":{"line":104,"character":26},"end":{"line":104,"character":39}},"message":"'LanguageModel' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":109,"character":9},"end":{"line":109,"character":29}},"message":"'getModelWithFallback' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":109,"character":71},"end":{"line":109,"character":91}},"message":"'hasFallbackAvailable' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":111,"character":51},"end":{"line":111,"character":66}},"message":"'shouldShowRetry' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":246,"character":34},"end":{"line":246,"character":50}},"message":"'MutableRefObject' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/%40types/react/index.d.ts","range":{"start":{"line":1658,"character":7},"end":{"line":1659,"character":5}}},"message":"The declaration was marked as deprecated here."}]}]},"truncated":false},"time":{"start":1770428769281,"end":1770428772316}},"metadata":{"openai":{"itemId":"fc_031fd5f846625879016986995f400481968b7480ea86fd339d"}}}}
{"type":"step_finish","timestamp":1770428772367,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c72fde001dRdA6ZxxAnhzj9","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c6f3b3001aNXGaxTsfbPNtJ","type":"step-finish","reason":"tool-calls","snapshot":"e34ae44e4c48d99d294c3ded20943d89986712a9","cost":0,"tokens":{"input":24046,"output":614,"reasoning":413,"cache":{"read":19968,"write":0}}}}
{"type":"step_start","timestamp":1770428772991,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c7327e0018ET5Rn22QGB9i7","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c73043001wgC4GuqJPcdKOB","type":"step-start","snapshot":"e34ae44e4c48d99d294c3ded20943d89986712a9"}}
{"type":"tool_use","timestamp":1770428780554,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c73e4f001Lg3iOnZyZHVXvO","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c73043001wgC4GuqJPcdKOB","type":"tool","callID":"call_OCv4q74TrcP7hhldYnPvefsS","tool":"bash","state":{"status":"completed","input":{"command":"npx jest hooks/chat/__tests__/useChat.test.ts","workdir":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2","description":"Re-run useChat hook test file"},"output":"  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { previousState: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'new-stream-initialization' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { previousState: 'streaming' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'network flap',\n      stack: 'Error: network flap\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:459:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:465:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:478:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:477:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'temporary outage',\n      stack: 'Error: temporary outage\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:517:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:523:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:536:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:535:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'network flap - initial',\n      stack: 'Error: network flap - initial\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:572:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:578:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:598:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:597:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\nPASS hooks/chat/__tests__/useChat.test.ts\n  useChat\n    basic functionality\n      ✓ should initialize with default values (18 ms)\n      ✓ should initialize with provided initial text (1 ms)\n      ✓ should update text when setText is called (2 ms)\n      ✓ should not send empty message (1 ms)\n      ✓ should not send whitespace-only message (1 ms)\n    message sending\n      ✓ should send message and add to history (26 ms)\n      ✓ should set isThinking while reasoning streams (7 ms)\n      ✓ should ignore thinking output when disabled (7 ms)\n      ✓ should skip placeholder text when disabled (7 ms)\n      ✓ should handle message with override text (6 ms)\n      ✓ should pass thinking level to streaming options (6 ms)\n    state management\n      ✓ should reset all state to initial values (2 ms)\n      ✓ should not throw when cancel is called (3 ms)\n    provider configuration\n      ✓ should use legacy provider when no chatId provided\n      ✓ should use chat state when chatId is provided\n    title functionality\n      ✓ should update title when setTitle is called (1 ms)\n      ✓ should generate title when generateTitle is called (1 ms)\n    edge cases\n      ✓ should handle non-string input gracefully (1 ms)\n      ✓ keeps completion ordering stable under rapid sends (11 ms)\n      ✓ prevents post-cancel error mutation from stale stream callbacks (7 ms)\n      ✓ deduplicates quick retry taps for the same failed operation (35 ms)\n      ✓ keeps retry state stable when retry is tapped while a retry is inflight (9 ms)\n      ✓ recovers from repeated network flap retries without duplicating chat entries (12 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       23 passed, 23 total\nSnapshots:   0 total\nTime:        1.203 s, estimated 2 s\nRan all test suites matching /hooks\\/chat\\/__tests__\\/useChat.test.ts/i.\n","title":"Re-run useChat hook test file","metadata":{"output":"  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { previousState: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'new-stream-initialization' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { previousState: 'streaming' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'network flap',\n      stack: 'Error: network flap\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:459:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:465:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:478:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:477:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'temporary outage',\n      stack: 'Error: temporary outage\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:517:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:523:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:536:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:535:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'network flap - initial',\n      stack: 'Error: network flap - initial\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:572:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:578:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:598:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:597:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\nPASS hooks/chat/__tests__/useChat.test.ts\n  useChat\n    basic functionality\n      ✓ should initialize with default values (18 ms)\n      ✓ should initialize with provided initial text (1 ms)\n      ✓ should update text when setText is called (2 ms)\n      ✓ should not send empty message (1 ms)\n      ✓ should not send whitespace-only message (1 ms)\n    message sending\n      ✓ should send message and add to history (26 ms)\n      ✓ should set isThinking while reasoning streams (7 ms)\n      ✓ should ignore thinking output when disabled (7 ms)\n      ✓ should skip placeholder text when disabled (7 ms)\n      ✓ should handle message with override text (6 ms)\n      ✓ should pass thinking level to streaming options (6 ms)\n    state management\n      ✓ should reset all state to initial values (2 ms)\n      ✓ should not throw when cancel is called (3 ms)\n    provider configuration\n      ✓ should use legacy provider when no chatId provided\n      ✓ should use chat state when chatId is provided\n    title functionality\n      ✓ should update title when setTitle is called (1 ms)\n      ✓ should generate title when generateTitle is called (1 ms)\n    edge cases\n      ✓ should handle non-string input gracefully (1 ms)\n      ✓ keeps completion ordering stable under rapid sends (11 ms)\n      ✓ prevents post-cancel error mutation from stale stream callbacks (7 ms)\n      ✓ deduplicates quick retry taps for the same failed operation (35 ms)\n      ✓ keeps retry state stable when retry is tapped while a retry is inflight (9 ms)\n      ✓ recovers from repeated network flap retries without duplicating chat entries (12 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       23 passed, 23 total\nSnapshots:   0 total\nTime:        1.203 s, estimated 2 s\nRan all test suites matching /hooks\\/chat\\/__tests__\\/useChat.test.ts/i.\n","exit":0,"description":"Re-run useChat hook test file","truncated":false},"time":{"start":1770428776652,"end":1770428780551}},"metadata":{"openai":{"itemId":"fc_0aeb0cd7202955a90169869967f43081978af0e62ca28156ee"}}}}
{"type":"step_finish","timestamp":1770428780599,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c75009001YDLoTw4l1BPHlz","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c73043001wgC4GuqJPcdKOB","type":"step-finish","reason":"tool-calls","snapshot":"e34ae44e4c48d99d294c3ded20943d89986712a9","cost":0,"tokens":{"input":25025,"output":132,"reasoning":71,"cache":{"read":19968,"write":0}}}}
{"type":"step_start","timestamp":1770428781492,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c753b2001vPsXfSSgFTAHLs","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c7506e001HObEnL3BF0djxx","type":"step-start","snapshot":"e34ae44e4c48d99d294c3ded20943d89986712a9"}}
{"type":"tool_use","timestamp":1770428798312,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c794be001ftkA0wBe1kd6V7","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c7506e001HObEnL3BF0djxx","type":"tool","callID":"call_DaV3rwqtt98AOQp25UGPuY7y","tool":"distill","state":{"status":"completed","input":{"targets":[{"id":"10","distillation":"`hooks/chat/useChat.ts` (lines 35-295) key changes:\n- Imports from `@/lib/concurrency` now include `createIdempotencyKey` and `createIdempotencyRegistry` in addition to `createSequenceGuard`.\n- Added local interface:\n  - `RetryableOperation { operationKey: string; content: string; }`.\n- Added refs in hook state:\n  - `retryOperationRegistryRef = useRef(createIdempotencyRegistry<void>())`.\n  - `lastRetryableOperationRef = useRef<RetryableOperation | null>(null)`.\n- Existing refs retained (`messagesRef`, `sendSequenceGuardRef`, etc.).\n- In `reset` callback, added idempotency cleanup:\n  - `lastRetryableOperationRef.current = null;`\n  - `retryOperationRegistryRef.current.clear();`\n- No change to public return type in this section; structure still centered on `UseChatReturn` and hook setup."},{"id":"11","distillation":"`hooks/chat/useChat.ts` (lines 390-670) key changes in `sendMessage`:\n- After `sendToken` creation, generated deterministic operation key:\n  - `sendOperationKey = createIdempotencyKey(\"chat-send\", [chatId ?? \"default\", sendToken.sequence, content])`.\n- At send start:\n  - `setCanRetry(false)` remains.\n  - Added `lastRetryableOperationRef.current = null` before streaming begins.\n- Error callback in streaming options now stores retry metadata when mutation is allowed:\n  - For both `Error` and non-`Error` branches, after setting `errorMessage` and `canRetry`, sets:\n    - `lastRetryableOperationRef.current = { operationKey: sendOperationKey, content }`.\n- Existing sequence guard checks, stream execution, fallback recursion, and completion flow remain otherwise intact.\n- Dependency array near end still includes many existing deps; duplicates (`onThinkingChunk`) remain as preexisting style issue."},{"id":"12","distillation":"`hooks/chat/useChat.ts` (lines 670-750) key changes in `retryLastMessage`:\n- Reworked retry to idempotent operation using registry dedupe.\n- Guard now requires all:\n  - `lastUserMessageRef.current`\n  - `canRetry`\n  - `lastRetryableOperationRef.current`\n- Builds retry key:\n  - `createIdempotencyKey(\"chat-retry\", [retryableOperation.operationKey, retryableOperation.content])`.\n- Executes retry inside `retryOperationRegistryRef.current.run(key, async () => ...)` so repeated taps share one in-flight promise.\n- Inside task:\n  - Reads `messagesRef.current` and removes trailing failed assistant message if present.\n  - Then removes trailing user message only if it matches retry content string.\n  - Tracks `removedCount` and trims `thinkingOutput` by same count.\n  - Writes pruned array to both `messagesRef.current` and `setMessages(nextMessages)`.\n  - Clears retry UI state (`setCanRetry(false)`, `setErrorMessage(null)`), nulls `lastRetryableOperationRef`.\n  - Calls `await sendMessage(retryableOperation.content)`.\n- Callback dependencies remain `[canRetry, sendMessage]`."}]},"output":"Context pruning complete. Pruned 3 tool outputs.\n\nSemantically pruned (3):\n→ read: hooks/chat/useChat.ts (lines 35-295)\n→ read: hooks/chat/useChat.ts (lines 390-670)\n→ read: hooks/chat/useChat.ts (lines 670-750)","title":"","metadata":{"truncated":false},"time":{"start":1770428798143,"end":1770428798311}},"metadata":{"openai":{"itemId":"fc_0c922e4881884222016986997e03ec8190809a2621d9885146"}}}}
{"type":"tool_use","timestamp":1770428798313,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c794c0001gG9pr4c9wIlPKR","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c7506e001HObEnL3BF0djxx","type":"tool","callID":"call_6qOEa13UbN4mx7izE2IRg2uA","tool":"prune","state":{"status":"completed","input":{"ids":["14","17"]},"output":"Context pruning complete. Pruned 2 tool outputs.\n\nSemantically pruned (2):\n→ bash: Run useChat hook test file\n→ bash: Re-run useChat hook test file","title":"","metadata":{"truncated":false},"time":{"start":1770428798144,"end":1770428798312}},"metadata":{"openai":{"itemId":"fc_0c922e4881884222016986997e03f48190873a16a2dc3eb3ed"}}}}
{"type":"tool_use","timestamp":1770428800065,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c794b6001G08T2URKPzSymD","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c7506e001HObEnL3BF0djxx","type":"tool","callID":"call_6NdQQYCbmsx497njBM7Kvn4p","tool":"bash","state":{"status":"completed","input":{"command":"npm run lint","workdir":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2","description":"Run ESLint for project"},"output":"\n> seabreeze@1.0.0 lint\n> expo lint\n\n","title":"Run ESLint for project","metadata":{"output":"\n> seabreeze@1.0.0 lint\n> expo lint\n\n","exit":0,"description":"Run ESLint for project","truncated":false},"time":{"start":1770428798137,"end":1770428800064}},"metadata":{"openai":{"itemId":"fc_0c922e4881884222016986997e03d88190843472c4fe2d7901"}}}}
{"type":"step_finish","timestamp":1770428800113,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c79c410014MUPKJrWKA6kwT","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c7506e001HObEnL3BF0djxx","type":"step-finish","reason":"tool-calls","snapshot":"e34ae44e4c48d99d294c3ded20943d89986712a9","cost":0,"tokens":{"input":8885,"output":1075,"reasoning":250,"cache":{"read":44288,"write":0}}}}
{"type":"step_start","timestamp":1770428800799,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c79f1f001tSGr57zhrS6CfD","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c79ca9001Kxr1WZbxOlwyZ1","type":"step-start","snapshot":"e34ae44e4c48d99d294c3ded20943d89986712a9"}}
{"type":"tool_use","timestamp":1770428811149,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c7adab001QQdIqk2HvUNCFg","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c79ca9001Kxr1WZbxOlwyZ1","type":"tool","callID":"call_AWGhfIPqB4lmoFtl55fRinCx","tool":"bash","state":{"status":"completed","input":{"command":"npx tsc --noEmit","workdir":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2","description":"Run TypeScript typecheck"},"output":"app/index.tsx(99,14): error TS2339: Property 'chat' does not exist on type '{}'.\nhooks/__tests__/useChatState.test.ts(23,3): error TS2698: Spread types may only be created from object types.\nhooks/__tests__/useChatState.test.ts(152,7): error TS2554: Expected 1 arguments, but got 0.\nhooks/__tests__/useErrorRecovery.test.ts(73,57): error TS2345: Argument of type '\"success\"' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(81,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(92,32): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(93,32): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(94,28): error TS2345: Argument of type '\"success\"' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(104,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(114,57): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(122,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(132,57): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(140,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(173,57): error TS2345: Argument of type '\"success\"' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(185,54): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(188,33): error TS2454: Variable 'promise' is used before being assigned.\nhooks/__tests__/useErrorRecovery.test.ts(239,57): error TS2345: Argument of type '\"success\"' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(250,44): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(251,44): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(252,44): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(292,57): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(295,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(303,57): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(318,40): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nproviders/__tests__/ollama-provider.test.ts(355,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(382,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(400,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(433,51): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(435,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(475,51): error TS2345: Argument of type '{ models: never[]; }' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(477,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(489,51): error TS2345: Argument of type '{ models: never[]; }' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(491,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(505,51): error TS2345: Argument of type '{}' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(507,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(518,51): error TS2345: Argument of type 'null' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(520,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(547,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(600,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(635,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\n","title":"Run TypeScript typecheck","metadata":{"output":"app/index.tsx(99,14): error TS2339: Property 'chat' does not exist on type '{}'.\nhooks/__tests__/useChatState.test.ts(23,3): error TS2698: Spread types may only be created from object types.\nhooks/__tests__/useChatState.test.ts(152,7): error TS2554: Expected 1 arguments, but got 0.\nhooks/__tests__/useErrorRecovery.test.ts(73,57): error TS2345: Argument of type '\"success\"' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(81,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(92,32): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(93,32): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(94,28): error TS2345: Argument of type '\"success\"' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(104,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(114,57): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(122,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(132,57): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(140,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(173,57): error TS2345: Argument of type '\"success\"' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(185,54): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(188,33): error TS2454: Variable 'promise' is used before being assigned.\nhooks/__tests__/useErrorRecovery.test.ts(239,57): error TS2345: Argument of type '\"success\"' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(250,44): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(251,44): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(252,44): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(292,57): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(295,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(303,57): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(318,40): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nproviders/__tests__/ollama-provider.test.ts(355,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(382,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(400,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(433,51): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(435,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(475,51): error TS2345: Argument of type '{ models: never[]; }' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(477,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(489,51): error TS2345: Argument of type '{ models: never[]; }' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(491,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(505,51): error TS2345: Argument of type '{}' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(507,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(518,51): error TS2345: Argument of type 'null' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(520,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(547,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(600,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(635,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\n","exit":2,"description":"Run TypeScript typecheck","truncated":false},"time":{"start":1770428804525,"end":1770428811148}},"metadata":{"openai":{"itemId":"fc_077853cb4c73ed69016986998474dc81978c8cbf653ecffed9"}}}}
{"type":"tool_use","timestamp":1770428924681,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c7adba0018A6moBRvG1PIye","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c79ca9001Kxr1WZbxOlwyZ1","type":"tool","callID":"call_DGmTC9nGklzbxvnYLYMug1YD","tool":"bash","state":{"status":"completed","input":{"command":"npm test -- --watch=false","workdir":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2","description":"Run full Jest test suite"},"output":"\n> seabreeze@1.0.0 test\n> jest --watchAll --watch=false\n\nFAIL hooks/__tests__/useDatabase.test.ts\n  ● useDatabase › database name configuration › should export correct database name\n\n    expect(received).toBe(expected) // Object.is equality\n\n    Expected: \"seabreeze\"\n    Received: \"seabreeze-v2\"\n\n      48 |   describe('database name configuration', () => {\n      49 |     it('should export correct database name', () => {\n    > 50 |       expect(dbname).toBe('seabreeze');\n         |                      ^\n      51 |     });\n      52 |\n      53 |     it('should use consistent database name across calls', () => {\n\n      at Object.toBe (hooks/__tests__/useDatabase.test.ts:50:22)\n\n  ● useDatabase › database name configuration › should use consistent database name across calls\n\n    expect(received).toBe(expected) // Object.is equality\n\n    Expected: \"seabreeze\"\n    Received: \"seabreeze-v2\"\n\n      55 |       const name2 = dbname;\n      56 |       expect(name1).toBe(name2);\n    > 57 |       expect(name1).toBe('seabreeze');\n         |                     ^\n      58 |     });\n      59 |   });\n      60 |\n\n      at Object.toBe (hooks/__tests__/useDatabase.test.ts:57:21)\n\n  ● useDatabase › initialization side effects › should have imported all dependencies successfully\n\n    expect(received).toBe(expected) // Object.is equality\n\n    Expected: \"seabreeze\"\n    Received: \"seabreeze-v2\"\n\n      113 |     it('should have imported all dependencies successfully', () => {\n      114 |       // If we get to this point, all imports were successful\n    > 115 |       expect(dbname).toBe('seabreeze');\n          |                      ^\n      116 |       expect(typeof useDatabase).toBe('function');\n      117 |     });\n      118 |   });\n\n      at Object.toBe (hooks/__tests__/useDatabase.test.ts:115:22)\n\nFAIL components/ui/__tests__/ThemeProvider.test.tsx\n  ● ThemeProvider › light theme › should render light theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      35 |             renderThemeProvider('light');\n      36 |             \n    > 37 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#f2f2f7');\n         |                           ^\n      38 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#ffffff');\n      39 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#000000');\n      40 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#007AFF');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:37:27)\n\n  ● ThemeProvider › light theme › should set themeType to light\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      45 |         it('should set themeType to light', () => {\n      46 |             renderThemeProvider('light');\n    > 47 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('light');\n         |                           ^\n      48 |         });\n      49 |\n      50 |         it('should set themeMode to light', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:47:27)\n\n  ● ThemeProvider › light theme › should set themeMode to light\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      50 |         it('should set themeMode to light', () => {\n      51 |             renderThemeProvider('light');\n    > 52 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('light');\n         |                           ^\n      53 |         });\n      54 |     });\n      55 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:52:27)\n\n  ● ThemeProvider › dark theme › should render dark theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      58 |             renderThemeProvider('dark');\n      59 |             \n    > 60 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#000000');\n         |                           ^\n      61 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#1a1a1a');\n      62 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#ffffff');\n      63 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#0567d1');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:60:27)\n\n  ● ThemeProvider › dark theme › should set themeType to dark\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      68 |         it('should set themeType to dark', () => {\n      69 |             renderThemeProvider('dark');\n    > 70 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('dark');\n         |                           ^\n      71 |         });\n      72 |\n      73 |         it('should set themeMode to dark', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:70:27)\n\n  ● ThemeProvider › dark theme › should set themeMode to dark\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      73 |         it('should set themeMode to dark', () => {\n      74 |             renderThemeProvider('dark');\n    > 75 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('dark');\n         |                           ^\n      76 |         });\n      77 |     });\n      78 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:75:27)\n\n  ● ThemeProvider › nord theme › should render nord theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      81 |             renderThemeProvider('nord');\n      82 |             \n    > 83 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#2E3440');\n         |                           ^\n      84 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#3B4252');\n      85 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#ECEFF4');\n      86 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#88C0D0');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:83:27)\n\n  ● ThemeProvider › nord theme › should set themeType to nord\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      91 |         it('should set themeType to nord', () => {\n      92 |             renderThemeProvider('nord');\n    > 93 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('nord');\n         |                           ^\n      94 |         });\n      95 |\n      96 |         it('should set themeMode to nord', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:93:27)\n\n  ● ThemeProvider › nord theme › should set themeMode to nord\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n       96 |         it('should set themeMode to nord', () => {\n       97 |             renderThemeProvider('nord');\n    >  98 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('nord');\n          |                           ^\n       99 |         });\n      100 |     });\n      101 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:98:27)\n\n  ● ThemeProvider › catppuccin theme › should render catppuccin theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      104 |             renderThemeProvider('catppuccin');\n      105 |             \n    > 106 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#1E1E2E');\n          |                           ^\n      107 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#313244');\n      108 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#CDD6F4');\n      109 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#89B4FA');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:106:27)\n\n  ● ThemeProvider › catppuccin theme › should set themeType to catppuccin\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      114 |         it('should set themeType to catppuccin', () => {\n      115 |             renderThemeProvider('catppuccin');\n    > 116 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('catppuccin');\n          |                           ^\n      117 |         });\n      118 |\n      119 |         it('should set themeMode to catppuccin', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:116:27)\n\n  ● ThemeProvider › catppuccin theme › should set themeMode to catppuccin\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      119 |         it('should set themeMode to catppuccin', () => {\n      120 |             renderThemeProvider('catppuccin');\n    > 121 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('catppuccin');\n          |                           ^\n      122 |         });\n      123 |     });\n      124 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:121:27)\n\n  ● ThemeProvider › tokyo-night theme › should render tokyo-night theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      127 |             renderThemeProvider('tokyo-night');\n      128 |             \n    > 129 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#1a1b26');\n          |                           ^\n      130 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#24283b');\n      131 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#c0caf5');\n      132 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#7aa2f7');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:129:27)\n\n  ● ThemeProvider › tokyo-night theme › should set themeType to tokyo-night\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      137 |         it('should set themeType to tokyo-night', () => {\n      138 |             renderThemeProvider('tokyo-night');\n    > 139 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('tokyo-night');\n          |                           ^\n      140 |         });\n      141 |\n      142 |         it('should set themeMode to tokyo-night', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:139:27)\n\n  ● ThemeProvider › tokyo-night theme › should set themeMode to tokyo-night\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      142 |         it('should set themeMode to tokyo-night', () => {\n      143 |             renderThemeProvider('tokyo-night');\n    > 144 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('tokyo-night');\n          |                           ^\n      145 |         });\n      146 |     });\n      147 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:144:27)\n\nFAIL app/settings/__tests__/ollama.test.tsx\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should render URL input field with correct label\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      88 |     it('should render URL input field with correct label', () => {\n      89 |       const { getByTestId } = render(<OllamaSettings />);\n    > 90 |       expect(getByTestId('setting-input-Ollama Base URL')).toBeTruthy();\n         |              ^\n      91 |     });\n      92 |\n      93 |     it('should display default URL in input field', () => {\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:90:14)\n\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should display default URL in input field\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      93 |     it('should display default URL in input field', () => {\n      94 |       const { getByTestId } = render(<OllamaSettings />);\n    > 95 |       const input = getByTestId('setting-input-Ollama Base URL') as HTMLInputElement;\n         |                     ^\n      96 |       expect(input.value).toBe('http://localhost:11434');\n      97 |     });\n      98 |\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:95:21)\n\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should have correct placeholder text\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n       99 |     it('should have correct placeholder text', () => {\n      100 |       const { getByTestId } = render(<OllamaSettings />);\n    > 101 |       const input = getByTestId('setting-input-Ollama Base URL') as HTMLInputElement;\n          |                     ^\n      102 |       expect(input.placeholder).toBe('http://localhost:11434');\n      103 |     });\n      104 |\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:101:21)\n\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should allow user to modify the URL\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      105 |     it('should allow user to modify the URL', () => {\n      106 |       const { getByTestId } = render(<OllamaSettings />);\n    > 107 |       const input = getByTestId('setting-input-Ollama Base URL') as any;\n          |                     ^\n      108 |       \n      109 |       fireEvent(input, 'changeText', 'http://192.168.1.100:11434');\n      110 |       expect(input.value).toBe('http://192.168.1.100:11434');\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:107:21)\n\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should disable autocapitalization for URL input\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      113 |     it('should disable autocapitalization for URL input', () => {\n      114 |       const { getByTestId } = render(<OllamaSettings />);\n    > 115 |       const input = getByTestId('setting-input-Ollama Base URL') as HTMLInputElement;\n          |                     ^\n      116 |       // In React Native, autoCapitalize=\"none\" is a prop that prevents uppercase conversion\n      117 |       expect(input).toBeTruthy();\n      118 |     });\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:115:21)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should render Save & Test button\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      122 |     it('should render Save & Test button', () => {\n      123 |       const { getByTestId } = render(<OllamaSettings />);\n    > 124 |       expect(getByTestId('save-button-Save & Test')).toBeTruthy();\n          |              ^\n      125 |     });\n      126 |\n      127 |     it('should render Load Models button', () => {\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:124:14)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should render Load Models button\n\n    Unable to find an element with testID: save-button-Load Models\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      127 |     it('should render Load Models button', () => {\n      128 |       const { getByTestId } = render(<OllamaSettings />);\n    > 129 |       expect(getByTestId('save-button-Load Models')).toBeTruthy();\n          |              ^\n      130 |     });\n      131 |\n      132 |     it('should have both buttons in a row layout', () => {\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:129:14)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should have both buttons in a row layout\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      132 |     it('should have both buttons in a row layout', () => {\n      133 |       const { getByTestId } = render(<OllamaSettings />);\n    > 134 |       const saveButton = getByTestId('save-button-Save & Test');\n          |                          ^\n      135 |       const loadButton = getByTestId('save-button-Load Models');\n      136 |       expect(saveButton).toBeTruthy();\n      137 |       expect(loadButton).toBeTruthy();\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:134:26)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should call handleSave when Save & Test button is pressed\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      140 |     it('should call handleSave when Save & Test button is pressed', async () => {\n      141 |       const { getByTestId } = render(<OllamaSettings />);\n    > 142 |       const saveButton = getByTestId('save-button-Save & Test');\n          |                          ^\n      143 |       \n      144 |       fireEvent(saveButton, 'press');\n      145 |       \n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:142:26)\n      at asyncGeneratorStep (node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\n      at _next (node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\n      at node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\n      at Object.<anonymous> (node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should call handleFetchModels when Load Models button is pressed\n\n    Unable to find an element with testID: save-button-Load Models\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      151 |     it('should call handleFetchModels when Load Models button is pressed', async () => {\n      152 |       const { getByTestId } = render(<OllamaSettings />);\n    > 153 |       const loadButton = getByTestId('save-button-Load Models');\n          |                          ^\n      154 |       \n      155 |       fireEvent(loadButton, 'press');\n      156 |       \n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:153:26)\n      at asyncGeneratorStep (node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\n      at _next (node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\n      at node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\n      at Object.<anonymous> (node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\n\n  ● OllamaSettings Component › SECTION 3: Connection Test Result Message › should display success message color when connection succeeds\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      173 |       \n      174 |       const { getByTestId } = render(<OllamaSettings />);\n    > 175 |       const saveButton = getByTestId('save-button-Save & Test');\n          |                          ^\n      176 |       \n      177 |       fireEvent(saveButton, 'press');\n      178 |       \n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:175:26)\n      at asyncGeneratorStep (node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\n      at _next (node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\n      at node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\n      at Object.<anonymous> (node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\n\n  ● OllamaSettings Component › SECTION 3: Connection Test Result Message › should display error message color when connection fails\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      188 |       \n      189 |       const { getByTestId } = render(<OllamaSettings />);\n    > 190 |       const saveButton = getByTestId('save-button-Save & Test');\n          |                          ^\n      191 |       \n      192 |       fireEvent(saveButton, 'press');\n      193 |       \n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:190:26)\n      at asyncGeneratorStep (node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\n      at _next (node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\n      at node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\n      at Object.<anonymous> (node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\n\n  ● OllamaSettings Component › SECTION 4: Model Selection Manager › should render ModelListManager component\n\n    Unable to find an element with testID: model-list-manager\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      201 |     it('should render ModelListManager component', () => {\n      202 |       const { getByTestId } = render(<OllamaSettings />);\n    > 203 |       expect(getByTestId('model-list-manager')).toBeTruthy();\n          |              ^\n      204 |     });\n      205 |\n      206 |     it('should pass ollama provider ID to ModelListManager', () => {\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:203:14)\n\n  ● OllamaSettings Component › SECTION 4: Model Selection Manager › should pass ollama provider ID to ModelListManager\n\n    Unable to find an element with testID: model-list-manager\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      206 |     it('should pass ollama provider ID to ModelListManager', () => {\n      207 |       const { getByTestId } = render(<OllamaSettings />);\n    > 208 |       const manager = getByTestId('model-list-manager');\n          |                       ^\n      209 |       expect(manager.textContent).toBe('ollama');\n      210 |     });\n      211 |\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:208:23)\n\n  ● OllamaSettings Component › SECTION 4: Model Selection Manager › should render model manager with available models\n\n    Unable to find an element with testID: model-list-manager\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      212 |     it('should render model manager with available models', () => {\n      213 |       const { getByTestId } = render(<OllamaSettings />);\n    > 214 |       expect(getByTestId('model-list-manager')).toBeTruthy();\n          |              ^\n      215 |     });\n      216 |   });\n      217 |\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:214:14)\n\n  ● OllamaSettings Component › Component Rendering › should render without crashing\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      219 |     it('should render without crashing', () => {\n      220 |       const { getByTestId } = render(<OllamaSettings />);\n    > 221 |       expect(getByTestId('setting-input-Ollama Base URL')).toBeTruthy();\n          |              ^\n      222 |     });\n      223 |\n      224 |     it('should render all four main sections', () => {\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:221:14)\n\n  ● OllamaSettings Component › Component Rendering › should render all four main sections\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      225 |       const { getByTestId } = render(<OllamaSettings />);\n      226 |       // Section 1: URL Input\n    > 227 |       expect(getByTestId('setting-input-Ollama Base URL')).toBeTruthy();\n          |              ^\n      228 |       // Section 2: Action Buttons\n      229 |       expect(getByTestId('save-button-Save & Test')).toBeTruthy();\n      230 |       expect(getByTestId('save-button-Load Models')).toBeTruthy();\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:227:14)\n\n  ● OllamaSettings Component › Component Rendering › should have proper view hierarchy\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      235 |     it('should have proper view hierarchy', () => {\n      236 |       const { getByTestId } = render(<OllamaSettings />);\n    > 237 |       expect(getByTestId('setting-input-Ollama Base URL')).toBeTruthy();\n          |              ^\n      238 |       expect(getByTestId('save-button-Save & Test')).toBeTruthy();\n      239 |       expect(getByTestId('model-list-manager')).toBeTruthy();\n      240 |     });\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:237:14)\n\n  ● OllamaSettings Component › State Management › should initialize with correct default URL from auth store\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      244 |     it('should initialize with correct default URL from auth store', () => {\n      245 |       const { getByTestId } = render(<OllamaSettings />);\n    > 246 |       const input = getByTestId('setting-input-Ollama Base URL') as HTMLInputElement;\n          |                     ^\n      247 |       expect(input.value).toBe('http://localhost:11434');\n      248 |     });\n      249 |\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:246:21)\n\n  ● OllamaSettings Component › State Management › should handle URL changes in local state\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      250 |     it('should handle URL changes in local state', () => {\n      251 |       const { getByTestId } = render(<OllamaSettings />);\n    > 252 |       const input = getByTestId('setting-input-Ollama Base URL') as any;\n          |                     ^\n      253 |       \n      254 |       fireEvent(input, 'changeText', 'http://example.com:11434');\n      255 |       expect(input.value).toBe('http://example.com:11434');\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:252:21)\n\n  ● OllamaSettings Component › Accessibility and Layout › should render sections in proper order\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      269 |     it('should render sections in proper order', () => {\n      270 |       const { getByTestId } = render(<OllamaSettings />);\n    > 271 |       const urlInput = getByTestId('setting-input-Ollama Base URL');\n          |                        ^\n      272 |       const saveButton = getByTestId('save-button-Save & Test');\n      273 |       const modelManager = getByTestId('model-list-manager');\n      274 |       \n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:271:24)\n\n  ● OllamaSettings Component › Accessibility and Layout › should have gap between sections\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      280 |     it('should have gap between sections', () => {\n      281 |       const { getByTestId } = render(<OllamaSettings />);\n    > 282 |       expect(getByTestId('setting-input-Ollama Base URL')).toBeTruthy();\n          |              ^\n      283 |       expect(getByTestId('save-button-Save & Test')).toBeTruthy();\n      284 |     });\n      285 |   });\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:282:14)\n\nFAIL components/chat/__tests__/ChatListItem.test.tsx\n  ● ChatListItem Component › renders chat title and preview correctly\n\n    TypeError: Cannot read properties of undefined (reading 'Tap')\n\n      57 |      */\n      58 |     it(\"renders chat title and preview correctly\", () => {\n    > 59 |         render(\n         |               ^\n      60 |             <ChatListItem\n      61 |                 id={1}\n      62 |                 title=\"Test Chat\"\n\n      at Tap (node_modules/react-native-gesture-handler/src/components/ReanimatedSwipeable/ReanimatedSwipeable.tsx:469:25)\n      at mountMemo (node_modules/react-test-renderer/cjs/react-test-renderer.development.js:3859:23)\n      at Object.useMemo (node_modules/react-test-renderer/cjs/react-test-renderer.development.js:13093:18)\n      at Object.<anonymous>.process.env.NODE_ENV.exports.useMemo (node_modules/react/cjs/react.development.js:1209:34)\n      at Swipeable (node_modules/react-native-gesture-handler/src/components/ReanimatedSwipeable/ReanimatedSwipeable.tsx:468:29)\n      at Object.react-stack-bottom-frame (node_modules/react-test-renderer/cjs/react-test-renderer.development.js:13976:20)\n      at renderWithHooks (node_modules/react-test-renderer/cjs/react-test-renderer.development.js:2866:22)\n\n...397188 bytes truncated...\n\nThe tool call succeeded but the output was truncated. Full output saved to: /Users/davidfanaro/.local/share/opencode/tool-output/tool_c35c98303001kWsclMd4wB6cyj\nUse the Task tool to have explore agent process this file with Grep and Read (with offset/limit). Do NOT read the full file yourself - delegate to save context.","title":"Run full Jest test suite","metadata":{"output":"\n> seabreeze@1.0.0 test\n> jest --watchAll --watch=false\n\nFAIL hooks/__tests__/useDatabase.test.ts\n  ● useDatabase › database name configuration › should export correct database name\n\n    expect(received).toBe(expected) // Object.is equality\n\n    Expected: \"seabreeze\"\n    Received: \"seabreeze-v2\"\n\n      48 |   describe('database name configuration', () => {\n      49 |     it('should export correct database name', () => {\n    > 50 |       expect(dbname).toBe('seabreeze');\n         |                      ^\n      51 |     });\n      52 |\n      53 |     it('should use consistent database name across calls', () => {\n\n      at Object.toBe (hooks/__tests__/useDatabase.test.ts:50:22)\n\n  ● useDatabase › database name configuration › should use consistent database name across calls\n\n    expect(received).toBe(expected) // Object.is equality\n\n    Expected: \"seabreeze\"\n    Received: \"seabreeze-v2\"\n\n      55 |       const name2 = dbname;\n      56 |       expect(name1).toBe(name2);\n    > 57 |       expect(name1).toBe('seabreeze');\n         |                     ^\n      58 |     });\n      59 |   });\n      60 |\n\n      at Object.toBe (hooks/__tests__/useDatabase.test.ts:57:21)\n\n  ● useDatabase › initialization side effects › should have imported all dependencies successfully\n\n    expect(received).toBe(expected) // Object.is equality\n\n    Expected: \"seabreeze\"\n    Received: \"seabreeze-v2\"\n\n      113 |     it('should have imported all dependencies successfully', () => {\n      114 |       // If we get to this point, all imports were successful\n    > 115 |       expect(dbname).toBe('seabreeze');\n          |                      ^\n      116 |       expect(typeof useDatabase).toBe('function');\n      117 |     });\n      118 |   });\n\n      at Object.toBe (hooks/__tests__/useDatabase.test.ts:115:22)\n\nFAIL components/ui/__tests__/ThemeProvider.test.tsx\n  ● ThemeProvider › light theme › should render light theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      35 |             renderThemeProvider('light');\n      36 |             \n    > 37 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#f2f2f7');\n         |                           ^\n      38 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#ffffff');\n      39 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#000000');\n      40 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#007AFF');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:37:27)\n\n  ● ThemeProvider › light theme › should set themeType to light\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      45 |         it('should set themeType to light', () => {\n      46 |             renderThemeProvider('light');\n    > 47 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('light');\n         |                           ^\n      48 |         });\n      49 |\n      50 |         it('should set themeMode to light', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:47:27)\n\n  ● ThemeProvider › light theme › should set themeMode to light\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      50 |         it('should set themeMode to light', () => {\n      51 |             renderThemeProvider('light');\n    > 52 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('light');\n         |                           ^\n      53 |         });\n      54 |     });\n      55 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:52:27)\n\n  ● ThemeProvider › dark theme › should render dark theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      58 |             renderThemeProvider('dark');\n      59 |             \n    > 60 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#000000');\n         |                           ^\n      61 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#1a1a1a');\n      62 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#ffffff');\n      63 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#0567d1');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:60:27)\n\n  ● ThemeProvider › dark theme › should set themeType to dark\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      68 |         it('should set themeType to dark', () => {\n      69 |             renderThemeProvider('dark');\n    > 70 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('dark');\n         |                           ^\n      71 |         });\n      72 |\n      73 |         it('should set themeMode to dark', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:70:27)\n\n  ● ThemeProvider › dark theme › should set themeMode to dark\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      73 |         it('should set themeMode to dark', () => {\n      74 |             renderThemeProvider('dark');\n    > 75 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('dark');\n         |                           ^\n      76 |         });\n      77 |     });\n      78 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:75:27)\n\n  ● ThemeProvider › nord theme › should render nord theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      81 |             renderThemeProvider('nord');\n      82 |             \n    > 83 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#2E3440');\n         |                           ^\n      84 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#3B4252');\n      85 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#ECEFF4');\n      86 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#88C0D0');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:83:27)\n\n  ● ThemeProvider › nord theme › should set themeType to nord\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      91 |         it('should set themeType to nord', () => {\n      92 |             renderThemeProvider('nord');\n    > 93 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('nord');\n         |                           ^\n      94 |         });\n      95 |\n      96 |         it('should set themeMode to nord', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:93:27)\n\n  ● ThemeProvider › nord theme › should set themeMode to nord\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n       96 |         it('should set themeMode to nord', () => {\n       97 |             renderThemeProvider('nord');\n    >  98 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('nord');\n          |                           ^\n       99 |         });\n      100 |     });\n      101 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:98:27)\n\n  ● ThemeProvider › catppuccin theme › should render catppuccin theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      104 |             renderThemeProvider('catppuccin');\n      105 |             \n    > 106 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#1E1E2E');\n          |                           ^\n      107 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#313244');\n      108 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#CDD6F4');\n      109 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#89B4FA');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:106:27)\n\n  ● ThemeProvider › catppuccin theme › should set themeType to catppuccin\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      114 |         it('should set themeType to catppuccin', () => {\n      115 |             renderThemeProvider('catppuccin');\n    > 116 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('catppuccin');\n          |                           ^\n      117 |         });\n      118 |\n      119 |         it('should set themeMode to catppuccin', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:116:27)\n\n  ● ThemeProvider › catppuccin theme › should set themeMode to catppuccin\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      119 |         it('should set themeMode to catppuccin', () => {\n      120 |             renderThemeProvider('catppuccin');\n    > 121 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('catppuccin');\n          |                           ^\n      122 |         });\n      123 |     });\n      124 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:121:27)\n\n  ● ThemeProvider › tokyo-night theme › should render tokyo-night theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      127 |             renderThemeProvider('tokyo-night');\n      128 |             \n    > 129 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#1a1b26');\n          |                           ^\n      130 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#24283b');\n      131 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#c0caf5');\n      132 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#7aa2f7');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:129:27)\n\n  ● ThemeProvider › tokyo-night theme › should set themeType to tokyo-night\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      137 |         it('should set themeType to tokyo-night', () => {\n      138 |             renderThemeProvider('tokyo-night');\n    > 139 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('tokyo-night');\n          |                           ^\n      140 |         });\n      141 |\n      142 |         it('should set themeMode to tokyo-night', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:139:27)\n\n  ● ThemeProvider › tokyo-night theme › should set themeMode to tokyo-night\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      142 |         it('should set themeMode to tokyo-night', () => {\n      143 |             renderThemeProvider('tokyo-night');\n    > 144 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('tokyo-night');\n          |                           ^\n      145 |         });\n      146 |     });\n      147 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:144:27)\n\nFAIL app/settings/__tests__/ollama.test.tsx\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should render URL input field with correct label\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      88 |     it('should render URL input field with correct label', () => {\n      89 |       const { getByTestId } = render(<OllamaSettings />);\n    > 90 |       expect(getByTestId('setting-input-Ollama Base URL')).toBeTruthy();\n         |              ^\n      91 |     });\n      92 |\n      93 |     it('should display default URL in input field', () => {\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:90:14)\n\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should display default URL in input field\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      93 |     it('should display default URL in input field', () => {\n      94 |       const { getByTestId } = render(<OllamaSettings />);\n    > 95 |       const input = getByTestId('setting-input-Ollama Base URL') as HTMLInputElement;\n         |                     ^\n      96 |       expect(input.value).toBe('http://localhost:11434');\n      97 |     });\n      98 |\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:95:21)\n\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should have correct placeholder text\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n       99 |     it('should have correct placeholder text', () => {\n      100 |       const { getByTestId } = render(<OllamaSettings />);\n    > 101 |       const input = getByTestId('setting-input-Ollama Base URL') as HTMLInputElement;\n          |                     ^\n      102 |       expect(input.placeholder).toBe('http://localhost:11434');\n      103 |     });\n      104 |\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:101:21)\n\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should allow user to modify the URL\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      105 |     it('should allow user to modify the URL', () => {\n      106 |       const { getByTestId } = render(<OllamaSettings />);\n    > 107 |       const input = getByTestId('setting-input-Ollama Base URL') as any;\n          |                     ^\n      108 |       \n      109 |       fireEvent(input, 'changeText', 'http://192.168.1.100:11434');\n      110 |       expect(input.value).toBe('http://192.168.1.100:11434');\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:107:21)\n\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should disable autocapitalization for URL input\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      113 |     it('should disable autocapitalization for URL input', () => {\n      114 |       const { getByTestId } = render(<OllamaSettings />);\n    > 115 |       const input = getByTestId('setting-input-Ollama Base URL') as HTMLInputElement;\n          |                     ^\n      116 |       // In React Native, autoCapitalize=\"none\" is a prop that prevents uppercase conversion\n      117 |       expect(input).toBeTruthy();\n      118 |     });\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:115:21)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should render Save & Test button\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      122 |     it('should render Save & Test button', () => {\n      123 |       const { getByTestId } = render(<OllamaSettings />);\n    > 124 |       expect(getByTestId('save-button-Save & Test')).toBeTruthy();\n          |              ^\n      125 |     });\n      126 |\n      127 |     it('should render Load Models button', () => {\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:124:14)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should render Load Models button\n\n    Unable to find an element with testID: save-button-Load Models\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      127 |     it('should render Load Models button', () => {\n      128 |       const { getByTestId } = render(<OllamaSettings />);\n    > 129 |       expect(getByTestId('save-button-Load Models')).toBeTruthy();\n          |              ^\n      130 |     });\n      131 |\n      132 |     it('should have both buttons in a row layout', () => {\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:129:14)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should have both buttons in a row layout\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      132 |     it('should have both buttons in a row layout', () => {\n      133 |       const { getByTestId } = render(<OllamaSettings />);\n    > 134 |       const saveButton = getByTestId('save-button-Save & Test');\n          |                          ^\n      135 |       const loadButton = getByTestId('save-button-Load Models');\n      136 |       expect(saveButton).toBeTruthy();\n      137 |       expect(loadButton).toBeTruthy();\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:134:26)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should call handleSave when Save & Test button is pressed\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      140 |     it('should call handleSave when Save & Test button is pressed', async () => {\n      141 |       const { getByTestId } = render(<OllamaSettings />);\n    > 142 |       const saveButton = getByTestId('save-button-Save & Test');\n          |                          ^\n      143 |       \n      144 |       fireEvent(saveButton, 'press');\n      145 |       \n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:142:26)\n      at asyncGeneratorStep (node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\n      at _next (node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\n      at node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\n      at Object.<anonymous> (node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should call handleFetchModels when Load Models button is pressed\n\n    Unable to find an element with testID: save-button-Load Models\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      151 |     it('should call handleFetchModels when Load Models button is pressed', async () => {\n      152 |       const { getByTestId } = render(<OllamaSettings />);\n    > 153 |       const loadButton = getByTestId('save-button-Load Models');\n          |                          ^\n      154 |       \n      155 |       fireEvent(loadButton, 'press');\n      156 |       \n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:153:26)\n      at asyncGeneratorStep (node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\n      at _next (node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\n      at node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\n      at Object.<anonymous> (node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\n\n  ● OllamaSettings Component › SECTION 3: Connection Test Result Message › should display success message color when connection succeeds\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n   \n\n...","exit":1,"description":"Run full Jest test suite","truncated":true,"outputPath":"/Users/davidfanaro/.local/share/opencode/tool-output/tool_c35c98303001kWsclMd4wB6cyj"},"time":{"start":1770428804558,"end":1770428924678}},"metadata":{"openai":{"itemId":"fc_077853cb4c73ed69016986998474ec8197aee513cb8142aeed"}}}}
{"type":"step_finish","timestamp":1770428924729,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c98308001nD4E8jmy1yS6Vw","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c79ca9001Kxr1WZbxOlwyZ1","type":"step-finish","reason":"tool-calls","snapshot":"e34ae44e4c48d99d294c3ded20943d89986712a9","cost":0,"tokens":{"input":5781,"output":241,"reasoning":124,"cache":{"read":25088,"write":0}}}}
{"type":"step_start","timestamp":1770428925528,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c986570010rJUsEDqEo8xZB","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c983730018yFwI33lhD3Ksb","type":"step-start","snapshot":"e34ae44e4c48d99d294c3ded20943d89986712a9"}}
{"type":"tool_use","timestamp":1770428935242,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c9aab5001XmNBdpLHGvEaac","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c983730018yFwI33lhD3Ksb","type":"tool","callID":"call_CdlgKE5icuWllgp3jbv7mBXP","tool":"bash","state":{"status":"completed","input":{"command":"git diff -- hooks/chat/useChat.ts hooks/chat/__tests__/useChat.test.ts .ralph-tui/progress.md","workdir":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2","description":"Show diff for modified story files"},"output":"diff --git a/hooks/chat/__tests__/useChat.test.ts b/hooks/chat/__tests__/useChat.test.ts\nindex a966b4b..7a8971f 100644\n--- a/hooks/chat/__tests__/useChat.test.ts\n+++ b/hooks/chat/__tests__/useChat.test.ts\n@@ -453,5 +453,171 @@ describe('useChat', () => {\n       expect(result.current.canRetry).toBe(false);\n       expect(onError).toHaveBeenCalledTimes(0);\n     });\n+\n+    it('deduplicates quick retry taps for the same failed operation', async () => {\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('network flap'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      const retryDeferred = createDeferred<{\n+        success: boolean;\n+        shouldRetryWithFallback: boolean;\n+        accumulated: string;\n+      }>();\n+\n+      mockExecuteStreaming.mockImplementationOnce(async () => retryDeferred.promise);\n+\n+      const { result } = renderHook(() => useChat({}));\n+\n+      await act(async () => {\n+        await result.current.sendMessage('retry me');\n+      });\n+\n+      expect(result.current.canRetry).toBe(true);\n+      expect(result.current.messages).toHaveLength(2);\n+\n+      let firstRetry = Promise.resolve();\n+      let secondRetry = Promise.resolve();\n+\n+      act(() => {\n+        firstRetry = result.current.retryLastMessage();\n+        secondRetry = result.current.retryLastMessage();\n+      });\n+\n+      await act(async () => {\n+        await Promise.resolve();\n+      });\n+\n+      expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n+\n+      await act(async () => {\n+        retryDeferred.resolve({\n+          success: true,\n+          shouldRetryWithFallback: false,\n+          accumulated: 'retry ok',\n+        });\n+\n+        await Promise.all([firstRetry, secondRetry]);\n+      });\n+\n+      expect(result.current.messages).toHaveLength(2);\n+      expect(result.current.messages[0]).toEqual({\n+        role: 'user',\n+        content: 'retry me',\n+      });\n+    });\n+\n+    it('keeps retry state stable when retry is tapped while a retry is inflight', async () => {\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('temporary outage'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      const inflightRetry = createDeferred<{\n+        success: boolean;\n+        shouldRetryWithFallback: boolean;\n+        accumulated: string;\n+      }>();\n+\n+      mockExecuteStreaming.mockImplementationOnce(async () => inflightRetry.promise);\n+\n+      const { result } = renderHook(() => useChat({}));\n+\n+      await act(async () => {\n+        await result.current.sendMessage('inflight retry');\n+      });\n+\n+      let firstRetry = Promise.resolve();\n+      let secondRetry = Promise.resolve();\n+\n+      act(() => {\n+        firstRetry = result.current.retryLastMessage();\n+      });\n+\n+      act(() => {\n+        secondRetry = result.current.retryLastMessage();\n+      });\n+\n+      await act(async () => {\n+        await Promise.resolve();\n+      });\n+\n+      expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n+\n+      await act(async () => {\n+        inflightRetry.resolve({\n+          success: true,\n+          shouldRetryWithFallback: false,\n+          accumulated: 'recovered',\n+        });\n+\n+        await Promise.all([firstRetry, secondRetry]);\n+      });\n+\n+      expect(result.current.messages).toHaveLength(2);\n+      expect(result.current.canRetry).toBe(false);\n+    });\n+\n+    it('recovers from repeated network flap retries without duplicating chat entries', async () => {\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('network flap - initial'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('network flap - retry'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      mockExecuteStreaming.mockImplementationOnce(async () => ({\n+        success: true,\n+        shouldRetryWithFallback: false,\n+        accumulated: 'eventual success',\n+      }));\n+\n+      const { result } = renderHook(() => useChat({}));\n+\n+      await act(async () => {\n+        await result.current.sendMessage('flap-safe');\n+      });\n+\n+      expect(result.current.canRetry).toBe(true);\n+      expect(result.current.messages).toHaveLength(2);\n+\n+      await act(async () => {\n+        await result.current.retryLastMessage();\n+      });\n+\n+      expect(result.current.canRetry).toBe(true);\n+      expect(result.current.messages).toHaveLength(2);\n+\n+      await act(async () => {\n+        await result.current.retryLastMessage();\n+      });\n+\n+      expect(result.current.canRetry).toBe(false);\n+      expect(result.current.messages).toHaveLength(2);\n+      expect(result.current.messages[0]).toEqual({\n+        role: 'user',\n+        content: 'flap-safe',\n+      });\n+    });\n   });\n });\ndiff --git a/hooks/chat/useChat.ts b/hooks/chat/useChat.ts\nindex a7274a2..7f564a2 100644\n--- a/hooks/chat/useChat.ts\n+++ b/hooks/chat/useChat.ts\n@@ -50,10 +50,19 @@ import { useTitleGeneration } from \"./useTitleGeneration\";\n import { useChatStreaming } from \"./useChatStreaming\";\n import { useStreamLifecycle } from \"./useStreamLifecycle\";\n import type { UseChatOptions, StreamState } from \"@/types/chat.types\";\n-import { createSequenceGuard } from \"@/lib/concurrency\";\n+import {\n+    createIdempotencyKey,\n+    createIdempotencyRegistry,\n+    createSequenceGuard,\n+} from \"@/lib/concurrency\";\n \n type ChunkHandler = (chunk: string, accumulated: string) => void;\n \n+interface RetryableOperation {\n+    operationKey: string;\n+    content: string;\n+}\n+\n const DEFAULT_PLACEHOLDER_TEXT = \"...\";\n \n // =============================================================================\n@@ -217,6 +226,8 @@ export default function useChat(options: UseChatOptions = {}): UseChatReturn {\n     const canceledRef = useRef<boolean>(false);             // Track if streaming was canceled\n     const messagesRef = useRef<ModelMessage[]>(initialMessages);\n     const sendSequenceGuardRef = useRef(createSequenceGuard(`chat-send-${chatId ?? \"default\"}`));\n+    const retryOperationRegistryRef = useRef(createIdempotencyRegistry<void>());\n+    const lastRetryableOperationRef = useRef<RetryableOperation | null>(null);\n \n     useEffect(() => {\n         messagesRef.current = messages;\n@@ -359,6 +370,8 @@ export default function useChat(options: UseChatOptions = {}): UseChatReturn {\n         lastUserMessageRef.current = null;       // Clear retry message\n         setCanRetry(false);                      // Disable retry capability\n         setErrorMessage(null);                   // Clear error message\n+        lastRetryableOperationRef.current = null;\n+        retryOperationRegistryRef.current.clear();\n     }, [effectiveProviderId, effectiveModelId, setTitle]);\n \n     /**\n@@ -410,6 +423,11 @@ export default function useChat(options: UseChatOptions = {}): UseChatReturn {\n             if (!content) return;\n \n             const sendToken = sendSequenceGuardRef.current.next();\n+            const sendOperationKey = createIdempotencyKey(\"chat-send\", [\n+                chatId ?? \"default\",\n+                sendToken.sequence,\n+                content,\n+            ]);\n \n             // ────────────────────────────────────────────────────────────────\n             // STATE INITIALIZATION\n@@ -418,6 +436,7 @@ export default function useChat(options: UseChatOptions = {}): UseChatReturn {\n             setIsThinking(false);                    // Reset thinking state\n             canceledRef.current = false;            // Clear cancellation flag\n             setCanRetry(false);                     // Disable retry until needed\n+            lastRetryableOperationRef.current = null;\n             lastUserMessageRef.current = content;   // Store for retry capability\n             \n             // Initialize stream lifecycle management\n@@ -520,12 +539,20 @@ export default function useChat(options: UseChatOptions = {}): UseChatReturn {\n                         markError(error);\n                         setErrorMessage(error.message);\n                         setCanRetry(true);\n+                        lastRetryableOperationRef.current = {\n+                            operationKey: sendOperationKey,\n+                            content,\n+                        };\n                         onError?.(error);\n                     } else {\n                         const wrappedError = new Error(String(error));\n                         markError(wrappedError);\n                         setErrorMessage(wrappedError.message);\n                         setCanRetry(true);\n+                        lastRetryableOperationRef.current = {\n+                            operationKey: sendOperationKey,\n+                            content,\n+                        };\n                         onError?.(wrappedError);\n                     }\n                 },\n@@ -617,41 +644,48 @@ export default function useChat(options: UseChatOptions = {}): UseChatReturn {\n      * and resends the original message with fresh streaming state.\n      */\n     const retryLastMessage = useCallback(async () => {\n+        const retryableOperation = lastRetryableOperationRef.current;\n+\n         // Guard against invalid retry attempts\n-        if (!lastUserMessageRef.current || !canRetry) return;\n-        \n-        // Remove the failed assistant message from history\n-        setMessages((prev) => {\n-            if (prev.length >= 2 && prev[prev.length - 1].role === \"assistant\") {\n-                return prev.slice(0, -1);\n-            }\n-            return prev;\n-        });\n-        setThinkingOutput((prev) => {\n-            if (prev.length >= 1) {\n-                return prev.slice(0, -1);\n-            }\n-            return prev;\n-        });\n+        if (!lastUserMessageRef.current || !canRetry || !retryableOperation) return;\n \n-        // Remove the original user message (we'll resend it fresh)\n-        setMessages((prev) => {\n-            if (prev.length >= 1 && prev[prev.length - 1].role === \"user\") {\n-                return prev.slice(0, -1);\n+        const retryOperationKey = createIdempotencyKey(\"chat-retry\", [\n+            retryableOperation.operationKey,\n+            retryableOperation.content,\n+        ]);\n+\n+        await retryOperationRegistryRef.current.run(retryOperationKey, async () => {\n+            const currentMessages = messagesRef.current;\n+            let nextMessages = [...currentMessages];\n+            let removedCount = 0;\n+\n+            if (nextMessages.length > 0 && nextMessages[nextMessages.length - 1].role === \"assistant\") {\n+                nextMessages = nextMessages.slice(0, -1);\n+                removedCount += 1;\n             }\n-            return prev;\n-        });\n-        setThinkingOutput((prev) => {\n-            if (prev.length >= 1) {\n-                return prev.slice(0, -1);\n+\n+            const lastMessage = nextMessages[nextMessages.length - 1];\n+            if (\n+                lastMessage\n+                && lastMessage.role === \"user\"\n+                && typeof lastMessage.content === \"string\"\n+                && lastMessage.content === retryableOperation.content\n+            ) {\n+                nextMessages = nextMessages.slice(0, -1);\n+                removedCount += 1;\n             }\n-            return prev;\n-        });\n \n-        // Reset retry state and clear error message\n-        setCanRetry(false);\n-        setErrorMessage(null);\n-        await sendMessage(lastUserMessageRef.current);\n+            messagesRef.current = nextMessages;\n+            setMessages(nextMessages);\n+            setThinkingOutput((prev) => prev.slice(0, Math.max(0, prev.length - removedCount)));\n+\n+            // Reset retry state and clear error message\n+            setCanRetry(false);\n+            setErrorMessage(null);\n+            lastRetryableOperationRef.current = null;\n+\n+            await sendMessage(retryableOperation.content);\n+        });\n     }, [canRetry, sendMessage]);\n \n     // =============================================================================\n","title":"Show diff for modified story files","metadata":{"output":"diff --git a/hooks/chat/__tests__/useChat.test.ts b/hooks/chat/__tests__/useChat.test.ts\nindex a966b4b..7a8971f 100644\n--- a/hooks/chat/__tests__/useChat.test.ts\n+++ b/hooks/chat/__tests__/useChat.test.ts\n@@ -453,5 +453,171 @@ describe('useChat', () => {\n       expect(result.current.canRetry).toBe(false);\n       expect(onError).toHaveBeenCalledTimes(0);\n     });\n+\n+    it('deduplicates quick retry taps for the same failed operation', async () => {\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('network flap'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      const retryDeferred = createDeferred<{\n+        success: boolean;\n+        shouldRetryWithFallback: boolean;\n+        accumulated: string;\n+      }>();\n+\n+      mockExecuteStreaming.mockImplementationOnce(async () => retryDeferred.promise);\n+\n+      const { result } = renderHook(() => useChat({}));\n+\n+      await act(async () => {\n+        await result.current.sendMessage('retry me');\n+      });\n+\n+      expect(result.current.canRetry).toBe(true);\n+      expect(result.current.messages).toHaveLength(2);\n+\n+      let firstRetry = Promise.resolve();\n+      let secondRetry = Promise.resolve();\n+\n+      act(() => {\n+        firstRetry = result.current.retryLastMessage();\n+        secondRetry = result.current.retryLastMessage();\n+      });\n+\n+      await act(async () => {\n+        await Promise.resolve();\n+      });\n+\n+      expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n+\n+      await act(async () => {\n+        retryDeferred.resolve({\n+          success: true,\n+          shouldRetryWithFallback: false,\n+          accumulated: 'retry ok',\n+        });\n+\n+        await Promise.all([firstRetry, secondRetry]);\n+      });\n+\n+      expect(result.current.messages).toHaveLength(2);\n+      expect(result.current.messages[0]).toEqual({\n+        role: 'user',\n+        content: 'retry me',\n+      });\n+    });\n+\n+    it('keeps retry state stable when retry is tapped while a retry is inflight', async () => {\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('temporary outage'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      const inflightRetry = createDeferred<{\n+        success: boolean;\n+        shouldRetryWithFallback: boolean;\n+        accumulated: string;\n+      }>();\n+\n+      mockExecuteStreaming.mockImplementationOnce(async () => inflightRetry.promise);\n+\n+      const { result } = renderHook(() => useChat({}));\n+\n+      await act(async () => {\n+        await result.current.sendMessage('inflight retry');\n+      });\n+\n+      let firstRetry = Promise.resolve();\n+      let secondRetry = Promise.resolve();\n+\n+      act(() => {\n+        firstRetry = result.current.retryLastMessage();\n+      });\n+\n+      act(() => {\n+        secondRetry = result.current.retryLastMessage();\n+      });\n+\n+      await act(async () => {\n+        await Promise.resolve();\n+      });\n+\n+      expect(mockExecuteStreaming).toHaveBeenCalledTimes(2);\n+\n+      await act(async () => {\n+        inflightRetry.resolve({\n+          success: true,\n+          shouldRetryWithFallback: false,\n+          accumulated: 'recovered',\n+        });\n+\n+        await Promise.all([firstRetry, secondRetry]);\n+      });\n+\n+      expect(result.current.messages).toHaveLength(2);\n+      expect(result.current.canRetry).toBe(false);\n+    });\n+\n+    it('recovers from repeated network flap retries without duplicating chat entries', async () => {\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('network flap - initial'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      mockExecuteStreaming.mockImplementationOnce(async (options: any) => {\n+        options?.onError?.(new Error('network flap - retry'));\n+        return {\n+          success: false,\n+          shouldRetryWithFallback: false,\n+          accumulated: '',\n+        };\n+      });\n+\n+      mockExecuteStreaming.mockImplementationOnce(async () => ({\n+        success: true,\n+        shouldRetryWithFallback: false,\n+        accumulated: 'eventual success',\n+      }));\n+\n+      const { result } = renderHook(() => useChat({}));\n+\n+      await act(async () => {\n+        await result.current.sendMessage('flap-safe');\n+      });\n+\n+      expect(result.current.canRetry).toBe(true);\n+      expect(result.current.messages).toHaveLength(2);\n+\n+      await act(async () => {\n+        await result.current.retryLastMessage();\n+      });\n+\n+      expect(result.current.canRetry).toBe(true);\n+      expect(result.current.messages).toHaveLength(2);\n+\n+      await act(async () => {\n+        await result.current.retryLastMessage();\n+      });\n+\n+      expect(result.current.canRetry).toBe(false);\n+      expect(result.current.messages).toHaveLength(2);\n+      expect(result.current.messages[0]).toEqual({\n+        role: 'user',\n+        content: 'flap-safe',\n+      });\n+    });\n   });\n });\ndiff --git a/hooks/chat/useChat.ts b/hooks/chat/useChat.ts\nindex a7274a2..7f564a2 100644\n--- a/hooks/chat/useChat.ts\n+++ b/hooks/chat/useChat.ts\n@@ -50,10 +50,19 @@ import { useTitleGeneration } from \"./useTitleGeneration\";\n import { useChatStreaming } from \"./useChatStreaming\";\n import { useStreamLifecycle } from \"./useStreamLifecycle\";\n import type { UseChatOptions, StreamState } from \"@/types/chat.types\";\n-import { createSequenceGuard } from \"@/lib/concurrency\";\n+import {\n+    createIdempotencyKey,\n+    createIdempotencyRegistry,\n+    createSequenceGuard,\n+} from \"@/lib/concurrency\";\n \n type ChunkHandler = (chunk: string, accumulated: string) => void;\n \n+interface RetryableOperation {\n+    operationKey: string;\n+    content: string;\n+}\n+\n const DEFAULT_PLACEHOLDER_TEXT = \"...\";\n \n // =============================================================================\n@@ -217,6 +226,8 @@ export default function useChat(options: UseChatOptions = {}): UseChatReturn {\n     const canceledRef = useRef<boolean>(false);             // Track if streaming was canceled\n     const messagesRef = useRef<ModelMessage[]>(initialMessages);\n     const sendSequenceGuardRef = useRef(createSequenceGuard(`chat-send-${chatId ?? \"default\"}`));\n+    const retryOperationRegistryRef = useRef(createIdempotencyRegistry<void>());\n+    const lastRetryableOperationRef = useRef<RetryableOperation | null>(null);\n \n     useEffect(() => {\n         messagesRef.current = messages;\n@@ -359,6 +370,8 @@ export default function useChat(options: UseChatOptions = {}): UseChatReturn {\n         lastUserMessageRef.current = null;       // Clear retry message\n         setCanRetry(false);                      // Disable retry capability\n         setErrorMessage(null);                   // Clear error message\n+        lastRetryableOperationRef.current = null;\n+        retryOperationRegistryRef.current.clear();\n     }, [effectiveProviderId, effectiveModelId, setTitle]);\n \n     /**\n@@ -410,6 +423,11 @@ export default function useChat(options: UseChatOptions = {}): UseChatReturn {\n             if (!content) return;\n \n             const sendToken = sendSequenceGuardRef.current.next();\n+            const sendOperationKey = createIdempotencyKey(\"chat-send\", [\n+                chatId ?? \"default\",\n+                sendToken.sequence,\n+                content,\n+            ]);\n \n             // ────────────────────────────────────────────────────────────────\n             // STATE INITIALIZATION\n@@ -418,6 +436,7 @@ export default function useChat(options: UseChatOptions = {}): UseChatReturn {\n             setIsThinking(false);                    // Reset thinking state\n             canceledRef.current = false;            // Clear cancellation flag\n             setCanRetry(false);                     // Disable retry until needed\n+            lastRetryableOperationRef.current = null;\n             lastUserMessageRef.current = content;   // Store for retry capability\n             \n             // Initialize stream lifecycle management\n@@ -520,12 +539,20 @@ export default function useChat(options: UseChatOptions = {}): UseChatReturn {\n                         markError(error);\n                         setErrorMessage(error.message);\n                         setCanRetry(true);\n+                        lastRetryableOperationRef.current = {\n+                            operationKey: sendOperationKey,\n+                            content,\n+                        };\n                         onError?.(error);\n                     } else {\n                         const wrappedError = new Error(String(error));\n                         markError(wrappedError);\n                         setErrorMessage(wrappedError.message);\n                         setCanRetry(true);\n+                        lastRetryableOperationRef.current = {\n+                            operationKey: sendOperationKey,\n+                            content,\n+                        };\n                         onError?.(wrappedError);\n                     }\n                 },\n@@ -617,41 +644,48 @@ export default function useChat(options: UseChatOptions = {}): UseChatReturn {\n      * and resends the original message with fresh streaming state.\n      */\n     const retryLastMessage = useCallback(async () => {\n+        const retryableOperation = lastRetryableOperationRef.current;\n+\n         // Guard against invalid retry attempts\n-        if (!lastUserMessageRef.current || !canRetry) return;\n-        \n-        // Remove the failed assistant message from history\n-        setMessages((prev) => {\n-            if (prev.length >= 2 && prev[prev.length - 1].role === \"assistant\") {\n-                return prev.slice(0, -1);\n-            }\n-            return prev;\n-        });\n-        setThinkingOutput((prev) => {\n-            if (prev.length >= 1) {\n-                return prev.slice(0, -1);\n-            }\n-            return prev;\n-        });\n+        if (!lastUserMessageRef.current || !canRetry || !retryableOperation) return;\n \n-        // Remove the original user message (we'll resend it fresh)\n-        setMessages((prev) => {\n-            if (prev.length >= 1 && prev[prev.length - 1].role === \"user\") {\n-                return prev.slice(0, -1);\n+        const retryOperationKey = createIdempotencyKey(\"chat-retry\", [\n+            retryableOperation.operationKey,\n+            retryableOperation.content,\n+        ]);\n+\n+        await retryOperationRegistryRef.current.run(retryOperationKey, async () => {\n+            const currentMessages = messagesRef.current;\n+            let nextMessages = [...currentMessages];\n+            let removedCount = 0;\n+\n+            if (nextMessages.length > 0 && nextMessages[nextMessages.length - 1].role === \"assistant\") {\n+                nextMessages = nextMessages.slice(0, -1);\n+                removedCount += 1;\n             }\n-            return prev;\n-        });\n-        setThinkingOutput((prev) => {\n-            if (prev.length >= 1) {\n-                return prev.slice(0, -1);\n+\n+            const lastMessage = nextMessages[nextMessages.length - 1];\n+            if (\n+                lastMessage\n+                && lastMessage.role === \"user\"\n+                && typeof lastMessage.content === \"string\"\n+                && lastMessage.content === retryableOperation.content\n+            ) {\n+                nextMessages = nextMessages.slice(0, -1);\n+                removedCount += 1;\n             }\n-            return prev;\n-        });\n \n-        // Reset retry state and clear error message\n-        setCanRetry(false);\n-        setErrorMessage(null);\n-        await sendMessage(lastUserMessageRef.current);\n+            messagesRef.current = nextMessages;\n+            setMessages(nextMessages);\n+            setThinkingOutput((prev) => prev.slice(0, Math.max(0, prev.length - removedCount)));\n+\n+            // Reset retry state and clear error message\n+            setCanRetry(false);\n+            setErrorMessage(null);\n+            lastRetryableOperationRef.current = null;\n+\n+            await sendMessage(retryableOperation.content);\n+        });\n     }, [canRetry, sendMessage]);\n \n     // =============================================================================\n","exit":0,"description":"Show diff for modified story files","truncated":false},"time":{"start":1770428935208,"end":1770428935241}},"metadata":{"openai":{"itemId":"fc_0dd970cfa1df93970169869a052de48195a390d149ea7fb431"}}}}
{"type":"step_finish","timestamp":1770428935285,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c9ac4a001eAq7TRc80vvsM7","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c983730018yFwI33lhD3Ksb","type":"step-finish","reason":"tool-calls","snapshot":"e34ae44e4c48d99d294c3ded20943d89986712a9","cost":0,"tokens":{"input":20631,"output":434,"reasoning":361,"cache":{"read":30208,"write":0}}}}
{"type":"step_start","timestamp":1770428936013,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c9af4b001Ahy8my55XbS0uX","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c9acac001FzNtsIpJYb5PqY","type":"step-start","snapshot":"e34ae44e4c48d99d294c3ded20943d89986712a9"}}
{"type":"tool_use","timestamp":1770428946541,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c9b4b7001HXXdOyR8VBw1zH","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c9acac001FzNtsIpJYb5PqY","type":"tool","callID":"call_9TmVochpyhgAHzOu85xRCQza","tool":"apply_patch","state":{"status":"completed","input":{"patchText":"*** Begin Patch\n*** Update File: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/.ralph-tui/progress.md\n@@\n - For overlapping chat sends, assign a new sequence token per send and require all stream-side callbacks/state commits (chunks, errors, provider switches, completion) to pass a shared `canMutateState` gate built from token freshness + abort/cancel flags.\n+- For retry UX, persist a retryable logical operation key on failure and run retry cleanup/send through an in-flight idempotency registry keyed by that operation so rapid taps collapse into one execution.\n@@\n ## 2026-02-06 - US-003\n@@\n - **Learnings:**\n@@\n   - Gotchas encountered\n@@\n     - Mocked streaming tests need deferred promises and captured callback options to deterministically reproduce overlap/cancel races.\n ---\n+\n+## 2026-02-06 - US-004\n+- What was implemented\n+  - Added idempotent retry semantics in `useChat` by tracking a retryable logical send key on failure and deduplicating retry execution with an in-flight idempotency registry.\n+  - Hardened retry cleanup so failed assistant/user tail entries are removed in one deterministic pass before re-send, preventing duplicate message rows and thinking-state drift.\n+  - Added concurrency-focused tests for rapid double-tap retry, retry presses while an earlier retry is still in-flight, and repeated network-flap retry recovery.\n+- Files changed\n+  - `hooks/chat/useChat.ts`\n+  - `hooks/chat/__tests__/useChat.test.ts`\n+  - `.ralph-tui/progress.md`\n+- **Learnings:**\n+  - Patterns discovered\n+    - Retry dedupe is most reliable when logical-operation identity is captured at failure time and reused as the idempotency key for all follow-up retry attempts.\n+    - Tail-pruning both message and thinking arrays in one retry transaction avoids split-state corruption under rapid UI interactions.\n+  - Gotchas encountered\n+    - Triggering retries back-to-back in tests requires a microtask flush before asserting streaming invocations because idempotency-registry tasks are promise-queued.\n+    - Repo-wide `tsc` and `npm test` currently fail due unrelated baseline issues, so targeted story verification was used to confirm retry behavior.\n+---\n*** End Patch"},"output":"Success. Updated the following files:\nM .ralph-tui/progress.md","title":"Success. Updated the following files:\nM .ralph-tui/progress.md","metadata":{"diff":"Index: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/.ralph-tui/progress.md\n===================================================================\n--- /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/.ralph-tui/progress.md\n+++ /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/.ralph-tui/progress.md\n@@ -9,8 +9,9 @@\n \n - Concurrency audits should use a stable schema per entry: `Race Class`, `Vulnerable Flow`, `Modules/Files`, `Severity`, `Reproducibility`, and `Owner Subsystem`, plus class-level fixed evidence gates to make remediation traceable.\n - For async workflows, compose a local trio per scope: `createSequenceGuard` to gate commits, `createAbortManager` to cancel superseded work, and `createIdempotencyRegistry` with deterministic keys to dedupe in-flight side effects.\n - For overlapping chat sends, assign a new sequence token per send and require all stream-side callbacks/state commits (chunks, errors, provider switches, completion) to pass a shared `canMutateState` gate built from token freshness + abort/cancel flags.\n+- For retry UX, persist a retryable logical operation key on failure and run retry cleanup/send through an in-flight idempotency registry keyed by that operation so rapid taps collapse into one execution.\n \n ---\n \n ## 2026-02-06 - US-001\n@@ -71,4 +72,22 @@\n   - Gotchas encountered\n     - Guarding stale completion paths can accidentally leave `isStreaming` stuck `true` unless cancel explicitly clears UI stream flags.\n     - Mocked streaming tests need deferred promises and captured callback options to deterministically reproduce overlap/cancel races.\n ---\n+\n+## 2026-02-06 - US-004\n+- What was implemented\n+  - Added idempotent retry semantics in `useChat` by tracking a retryable logical send key on failure and deduplicating retry execution with an in-flight idempotency registry.\n+  - Hardened retry cleanup so failed assistant/user tail entries are removed in one deterministic pass before re-send, preventing duplicate message rows and thinking-state drift.\n+  - Added concurrency-focused tests for rapid double-tap retry, retry presses while an earlier retry is still in-flight, and repeated network-flap retry recovery.\n+- Files changed\n+  - `hooks/chat/useChat.ts`\n+  - `hooks/chat/__tests__/useChat.test.ts`\n+  - `.ralph-tui/progress.md`\n+- **Learnings:**\n+  - Patterns discovered\n+    - Retry dedupe is most reliable when logical-operation identity is captured at failure time and reused as the idempotency key for all follow-up retry attempts.\n+    - Tail-pruning both message and thinking arrays in one retry transaction avoids split-state corruption under rapid UI interactions.\n+  - Gotchas encountered\n+    - Triggering retries back-to-back in tests requires a microtask flush before asserting streaming invocations because idempotency-registry tasks are promise-queued.\n+    - Repo-wide `tsc` and `npm test` currently fail due unrelated baseline issues, so targeted story verification was used to confirm retry behavior.\n+---\n\n","files":[{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/.ralph-tui/progress.md","relativePath":".ralph-tui/progress.md","type":"update","diff":"Index: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/.ralph-tui/progress.md\n===================================================================\n--- /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/.ralph-tui/progress.md\n+++ /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/.ralph-tui/progress.md\n@@ -9,8 +9,9 @@\n \n - Concurrency audits should use a stable schema per entry: `Race Class`, `Vulnerable Flow`, `Modules/Files`, `Severity`, `Reproducibility`, and `Owner Subsystem`, plus class-level fixed evidence gates to make remediation traceable.\n - For async workflows, compose a local trio per scope: `createSequenceGuard` to gate commits, `createAbortManager` to cancel superseded work, and `createIdempotencyRegistry` with deterministic keys to dedupe in-flight side effects.\n - For overlapping chat sends, assign a new sequence token per send and require all stream-side callbacks/state commits (chunks, errors, provider switches, completion) to pass a shared `canMutateState` gate built from token freshness + abort/cancel flags.\n+- For retry UX, persist a retryable logical operation key on failure and run retry cleanup/send through an in-flight idempotency registry keyed by that operation so rapid taps collapse into one execution.\n \n ---\n \n ## 2026-02-06 - US-001\n@@ -71,4 +72,22 @@\n   - Gotchas encountered\n     - Guarding stale completion paths can accidentally leave `isStreaming` stuck `true` unless cancel explicitly clears UI stream flags.\n     - Mocked streaming tests need deferred promises and captured callback options to deterministically reproduce overlap/cancel races.\n ---\n+\n+## 2026-02-06 - US-004\n+- What was implemented\n+  - Added idempotent retry semantics in `useChat` by tracking a retryable logical send key on failure and deduplicating retry execution with an in-flight idempotency registry.\n+  - Hardened retry cleanup so failed assistant/user tail entries are removed in one deterministic pass before re-send, preventing duplicate message rows and thinking-state drift.\n+  - Added concurrency-focused tests for rapid double-tap retry, retry presses while an earlier retry is still in-flight, and repeated network-flap retry recovery.\n+- Files changed\n+  - `hooks/chat/useChat.ts`\n+  - `hooks/chat/__tests__/useChat.test.ts`\n+  - `.ralph-tui/progress.md`\n+- **Learnings:**\n+  - Patterns discovered\n+    - Retry dedupe is most reliable when logical-operation identity is captured at failure time and reused as the idempotency key for all follow-up retry attempts.\n+    - Tail-pruning both message and thinking arrays in one retry transaction avoids split-state corruption under rapid UI interactions.\n+  - Gotchas encountered\n+    - Triggering retries back-to-back in tests requires a microtask flush before asserting streaming invocations because idempotency-registry tasks are promise-queued.\n+    - Repo-wide `tsc` and `npm test` currently fail due unrelated baseline issues, so targeted story verification was used to confirm retry behavior.\n+---\n","before":"# Ralph Progress Log\n\nThis file tracks progress across iterations. Agents update this file\nafter each iteration and it's included in prompts for context.\n\n## Codebase Patterns (Study These First)\n\n*Add reusable patterns discovered during development here.*\n\n- Concurrency audits should use a stable schema per entry: `Race Class`, `Vulnerable Flow`, `Modules/Files`, `Severity`, `Reproducibility`, and `Owner Subsystem`, plus class-level fixed evidence gates to make remediation traceable.\n- For async workflows, compose a local trio per scope: `createSequenceGuard` to gate commits, `createAbortManager` to cancel superseded work, and `createIdempotencyRegistry` with deterministic keys to dedupe in-flight side effects.\n- For overlapping chat sends, assign a new sequence token per send and require all stream-side callbacks/state commits (chunks, errors, provider switches, completion) to pass a shared `canMutateState` gate built from token freshness + abort/cancel flags.\n\n---\n\n## 2026-02-06 - US-001\n- What was implemented\n  - Added a repository-wide concurrency taxonomy and audit baseline covering stale-response overwrite, double-submit, out-of-order stream events, fallback duplication, hydration/write conflicts, and cancellation leaks.\n  - Produced an inventory of vulnerable flows mapped to files across `app/`, `hooks/`, `stores/`, `providers/`, `db/`, and `lib/`, each tagged with severity, reproducibility, and owner subsystem.\n  - Defined fixed evidence requirements per race class for remediation closure.\n- Files changed\n  - `docs/concurrency-taxonomy-audit-baseline.md`\n  - `.ralph-tui/progress.md`\n- **Learnings:**\n  - Patterns discovered\n    - Chat flow already has partial stale-load protection (`loadIdRef`) in route-based loading, but streaming and fallback paths need equivalent generation/idempotency controls.\n    - Persisted Zustand stores and runtime DB synchronization create repeated hydration precedence risks unless authority order is explicit and tested.\n  - Gotchas encountered\n    - Stream lifecycle utilities define robust transitions, but integration gaps can still produce out-of-order completion semantics if chunk/done/completed markers are not consistently emitted.\n    - New-chat persistence relies on runtime guards rather than DB constraints, so duplicate insert races remain plausible under timing pressure.\n---\n\n## 2026-02-06 - US-002\n- What was implemented\n  - Added shared concurrency primitives in `lib/concurrency.ts` for sequence guards, abort lifecycle management, abort error detection, deterministic idempotency keys, and in-flight idempotency registries.\n  - Introduced typed contracts in `types/concurrency.types.ts` and exported them via `types/index.ts` for use by hooks/providers/stores.\n  - Added contributor-facing usage rules and an integration recipe in `docs/concurrency-primitives.md`.\n  - Added unit tests covering stale token rejection, out-of-order completion gating, superseded abort behavior, and idempotent in-flight deduplication.\n- Files changed\n  - `lib/concurrency.ts`\n  - `lib/__tests__/concurrency.test.ts`\n  - `types/concurrency.types.ts`\n  - `types/index.ts`\n  - `docs/concurrency-primitives.md`\n  - `.ralph-tui/progress.md`\n- **Learnings:**\n  - Patterns discovered\n    - Sequence guards are most reliable when every async request gets a fresh token at launch and every commit path checks token freshness right before mutation.\n    - Abort managers and idempotency registries should be scoped per workflow (not global) to avoid cross-feature cancellation and dedupe collisions.\n  - Gotchas encountered\n    - Deduplication should only cover in-flight work; keeping completed promises in a registry can suppress legitimate retries.\n    - Abort handling is most maintainable when abort outcomes are normalized (`AbortError`) and filtered from fallback/error UX flows.\n---\n\n## 2026-02-06 - US-003\n- What was implemented\n  - Hardened `useChat` send lifecycle ordering by introducing per-send sequence tokens and guarding all async completion paths so stale sends cannot flip stream state or trigger completion callbacks.\n  - Added mutation gating plumbing (`canMutateState`) to `useChatStreaming` so text/reasoning chunks, callbacks, and error-content writes are ignored after cancellation or when a send becomes stale.\n  - Updated cancel behavior to invalidate active sequence tokens and immediately clear streaming/thinking UI state, preventing post-cancel completion races.\n  - Added deterministic concurrency tests covering rapid send overlap ordering, post-cancel stale callback suppression, stale chunk gating, and abort-driven stop/start behavior.\n- Files changed\n  - `hooks/chat/useChat.ts`\n  - `hooks/chat/useChatStreaming.ts`\n  - `hooks/chat/__tests__/useChat.test.ts`\n  - `hooks/chat/__tests__/useChatStreaming.test.ts`\n  - `.ralph-tui/progress.md`\n- **Learnings:**\n  - Patterns discovered\n    - A single `canMutateState` gate shared between orchestrator (`useChat`) and stream worker (`useChatStreaming`) is an effective seam for enforcing ordering without tightly coupling hook internals.\n    - Cancel semantics are safer when cancellation both aborts transport and invalidates sequencing tokens, so late async work self-rejects even if already in flight.\n  - Gotchas encountered\n    - Guarding stale completion paths can accidentally leave `isStreaming` stuck `true` unless cancel explicitly clears UI stream flags.\n    - Mocked streaming tests need deferred promises and captured callback options to deterministically reproduce overlap/cancel races.\n---\n","after":"# Ralph Progress Log\n\nThis file tracks progress across iterations. Agents update this file\nafter each iteration and it's included in prompts for context.\n\n## Codebase Patterns (Study These First)\n\n*Add reusable patterns discovered during development here.*\n\n- Concurrency audits should use a stable schema per entry: `Race Class`, `Vulnerable Flow`, `Modules/Files`, `Severity`, `Reproducibility`, and `Owner Subsystem`, plus class-level fixed evidence gates to make remediation traceable.\n- For async workflows, compose a local trio per scope: `createSequenceGuard` to gate commits, `createAbortManager` to cancel superseded work, and `createIdempotencyRegistry` with deterministic keys to dedupe in-flight side effects.\n- For overlapping chat sends, assign a new sequence token per send and require all stream-side callbacks/state commits (chunks, errors, provider switches, completion) to pass a shared `canMutateState` gate built from token freshness + abort/cancel flags.\n- For retry UX, persist a retryable logical operation key on failure and run retry cleanup/send through an in-flight idempotency registry keyed by that operation so rapid taps collapse into one execution.\n\n---\n\n## 2026-02-06 - US-001\n- What was implemented\n  - Added a repository-wide concurrency taxonomy and audit baseline covering stale-response overwrite, double-submit, out-of-order stream events, fallback duplication, hydration/write conflicts, and cancellation leaks.\n  - Produced an inventory of vulnerable flows mapped to files across `app/`, `hooks/`, `stores/`, `providers/`, `db/`, and `lib/`, each tagged with severity, reproducibility, and owner subsystem.\n  - Defined fixed evidence requirements per race class for remediation closure.\n- Files changed\n  - `docs/concurrency-taxonomy-audit-baseline.md`\n  - `.ralph-tui/progress.md`\n- **Learnings:**\n  - Patterns discovered\n    - Chat flow already has partial stale-load protection (`loadIdRef`) in route-based loading, but streaming and fallback paths need equivalent generation/idempotency controls.\n    - Persisted Zustand stores and runtime DB synchronization create repeated hydration precedence risks unless authority order is explicit and tested.\n  - Gotchas encountered\n    - Stream lifecycle utilities define robust transitions, but integration gaps can still produce out-of-order completion semantics if chunk/done/completed markers are not consistently emitted.\n    - New-chat persistence relies on runtime guards rather than DB constraints, so duplicate insert races remain plausible under timing pressure.\n---\n\n## 2026-02-06 - US-002\n- What was implemented\n  - Added shared concurrency primitives in `lib/concurrency.ts` for sequence guards, abort lifecycle management, abort error detection, deterministic idempotency keys, and in-flight idempotency registries.\n  - Introduced typed contracts in `types/concurrency.types.ts` and exported them via `types/index.ts` for use by hooks/providers/stores.\n  - Added contributor-facing usage rules and an integration recipe in `docs/concurrency-primitives.md`.\n  - Added unit tests covering stale token rejection, out-of-order completion gating, superseded abort behavior, and idempotent in-flight deduplication.\n- Files changed\n  - `lib/concurrency.ts`\n  - `lib/__tests__/concurrency.test.ts`\n  - `types/concurrency.types.ts`\n  - `types/index.ts`\n  - `docs/concurrency-primitives.md`\n  - `.ralph-tui/progress.md`\n- **Learnings:**\n  - Patterns discovered\n    - Sequence guards are most reliable when every async request gets a fresh token at launch and every commit path checks token freshness right before mutation.\n    - Abort managers and idempotency registries should be scoped per workflow (not global) to avoid cross-feature cancellation and dedupe collisions.\n  - Gotchas encountered\n    - Deduplication should only cover in-flight work; keeping completed promises in a registry can suppress legitimate retries.\n    - Abort handling is most maintainable when abort outcomes are normalized (`AbortError`) and filtered from fallback/error UX flows.\n---\n\n## 2026-02-06 - US-003\n- What was implemented\n  - Hardened `useChat` send lifecycle ordering by introducing per-send sequence tokens and guarding all async completion paths so stale sends cannot flip stream state or trigger completion callbacks.\n  - Added mutation gating plumbing (`canMutateState`) to `useChatStreaming` so text/reasoning chunks, callbacks, and error-content writes are ignored after cancellation or when a send becomes stale.\n  - Updated cancel behavior to invalidate active sequence tokens and immediately clear streaming/thinking UI state, preventing post-cancel completion races.\n  - Added deterministic concurrency tests covering rapid send overlap ordering, post-cancel stale callback suppression, stale chunk gating, and abort-driven stop/start behavior.\n- Files changed\n  - `hooks/chat/useChat.ts`\n  - `hooks/chat/useChatStreaming.ts`\n  - `hooks/chat/__tests__/useChat.test.ts`\n  - `hooks/chat/__tests__/useChatStreaming.test.ts`\n  - `.ralph-tui/progress.md`\n- **Learnings:**\n  - Patterns discovered\n    - A single `canMutateState` gate shared between orchestrator (`useChat`) and stream worker (`useChatStreaming`) is an effective seam for enforcing ordering without tightly coupling hook internals.\n    - Cancel semantics are safer when cancellation both aborts transport and invalidates sequencing tokens, so late async work self-rejects even if already in flight.\n  - Gotchas encountered\n    - Guarding stale completion paths can accidentally leave `isStreaming` stuck `true` unless cancel explicitly clears UI stream flags.\n    - Mocked streaming tests need deferred promises and captured callback options to deterministically reproduce overlap/cancel races.\n---\n\n## 2026-02-06 - US-004\n- What was implemented\n  - Added idempotent retry semantics in `useChat` by tracking a retryable logical send key on failure and deduplicating retry execution with an in-flight idempotency registry.\n  - Hardened retry cleanup so failed assistant/user tail entries are removed in one deterministic pass before re-send, preventing duplicate message rows and thinking-state drift.\n  - Added concurrency-focused tests for rapid double-tap retry, retry presses while an earlier retry is still in-flight, and repeated network-flap retry recovery.\n- Files changed\n  - `hooks/chat/useChat.ts`\n  - `hooks/chat/__tests__/useChat.test.ts`\n  - `.ralph-tui/progress.md`\n- **Learnings:**\n  - Patterns discovered\n    - Retry dedupe is most reliable when logical-operation identity is captured at failure time and reused as the idempotency key for all follow-up retry attempts.\n    - Tail-pruning both message and thinking arrays in one retry transaction avoids split-state corruption under rapid UI interactions.\n  - Gotchas encountered\n    - Triggering retries back-to-back in tests requires a microtask flush before asserting streaming invocations because idempotency-registry tasks are promise-queued.\n    - Repo-wide `tsc` and `npm test` currently fail due unrelated baseline issues, so targeted story verification was used to confirm retry behavior.\n---\n","additions":19,"deletions":0}],"diagnostics":{"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts":[{"range":{"start":{"line":46,"character":9},"end":{"line":46,"character":25}},"message":"'executeWithRetry' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":58,"character":5},"end":{"line":58,"character":17}},"message":"'ChunkHandler' is declared but never used.","severity":4,"code":6196,"source":"typescript"},{"range":{"start":{"line":152,"character":8},"end":{"line":152,"character":18}},"message":"'providerId' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/chat.types.ts","range":{"start":{"line":20,"character":6},"end":{"line":20,"character":66}}},"message":"The declaration was marked as deprecated here."}]},{"range":{"start":{"line":153,"character":8},"end":{"line":153,"character":15}},"message":"'modelId' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/chat.types.ts","range":{"start":{"line":22,"character":6},"end":{"line":22,"character":66}}},"message":"The declaration was marked as deprecated here."}]},{"range":{"start":{"line":294,"character":30},"end":{"line":294,"character":50}},"message":"'handleStreamingError' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":306,"character":21},"end":{"line":306,"character":47}},"message":"'isStreamLifecycleStreaming' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":307,"character":8},"end":{"line":307,"character":23}},"message":"'abortController' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":309,"character":8},"end":{"line":309,"character":25}},"message":"'markChunkReceived' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":310,"character":8},"end":{"line":310,"character":30}},"message":"'markDoneSignalReceived' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":311,"character":8},"end":{"line":311,"character":22}},"message":"'markCompleting' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":312,"character":8},"end":{"line":312,"character":21}},"message":"'markCompleted' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"}],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/concurrency.types.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/lib/concurrency.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChatStreaming.ts":[{"range":{"start":{"line":104,"character":26},"end":{"line":104,"character":39}},"message":"'LanguageModel' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":109,"character":9},"end":{"line":109,"character":29}},"message":"'getModelWithFallback' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":109,"character":71},"end":{"line":109,"character":91}},"message":"'hasFallbackAvailable' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":111,"character":51},"end":{"line":111,"character":66}},"message":"'shouldShowRetry' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":246,"character":34},"end":{"line":246,"character":50}},"message":"'MutableRefObject' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/%40types/react/index.d.ts","range":{"start":{"line":1658,"character":7},"end":{"line":1659,"character":5}}},"message":"The declaration was marked as deprecated here."}]}]},"truncated":false},"time":{"start":1770428946512,"end":1770428946539}},"metadata":{"openai":{"itemId":"fc_0574054b296b7afd0169869a09456481949673ea7ef9fad870"}}}}
{"type":"step_finish","timestamp":1770428946593,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c9d86c001PBNPuNX9Weqptg","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c9acac001FzNtsIpJYb5PqY","type":"step-finish","reason":"tool-calls","snapshot":"01207a2c1e58a5d897a4e0c815583620455bde0b","cost":0,"tokens":{"input":23846,"output":568,"reasoning":31,"cache":{"read":30208,"write":0}}}}
{"type":"step_start","timestamp":1770428947280,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c9db4f001k6pqQw69l7j6TV","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c9d8df001eRQTZgZxU3Uv77","type":"step-start","snapshot":"01207a2c1e58a5d897a4e0c815583620455bde0b"}}
{"type":"tool_use","timestamp":1770428952881,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c9f0e0001vawUhneMkexXzp","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c9d8df001eRQTZgZxU3Uv77","type":"tool","callID":"call_0HFsTFqDAznIUCaE7yHoI3XK","tool":"prune","state":{"status":"completed","input":{"ids":["21","22"]},"output":"Context pruning complete. Pruned 2 tool outputs.\n\nSemantically pruned (2):\n→ bash: Run TypeScript typecheck\n→ bash: Run full Jest test suite","title":"","metadata":{"truncated":false},"time":{"start":1770428952806,"end":1770428952880}},"metadata":{"openai":{"itemId":"fc_02a9eddb5aa400f20169869a18add88196b1cf021b17145b59"}}}}
{"type":"tool_use","timestamp":1770428955797,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c9f08c001PaGGGnqjqsER5b","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c9d8df001eRQTZgZxU3Uv77","type":"tool","callID":"call_oOepzvhUoGT1mqAw4e8uOL8S","tool":"bash","state":{"status":"completed","input":{"command":"npx jest hooks/chat/__tests__/useChat.test.ts","workdir":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2","description":"Verify useChat tests after retry changes"},"output":"  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { previousState: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'new-stream-initialization' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { previousState: 'streaming' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'network flap',\n      stack: 'Error: network flap\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:459:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:465:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:478:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:477:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'temporary outage',\n      stack: 'Error: temporary outage\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:517:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:523:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:536:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:535:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'network flap - initial',\n      stack: 'Error: network flap - initial\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:572:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:578:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:598:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:597:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\nPASS hooks/chat/__tests__/useChat.test.ts\n  useChat\n    basic functionality\n      ✓ should initialize with default values (13 ms)\n      ✓ should initialize with provided initial text (2 ms)\n      ✓ should update text when setText is called (2 ms)\n      ✓ should not send empty message (1 ms)\n      ✓ should not send whitespace-only message (2 ms)\n    message sending\n      ✓ should send message and add to history (37 ms)\n      ✓ should set isThinking while reasoning streams (8 ms)\n      ✓ should ignore thinking output when disabled (12 ms)\n      ✓ should skip placeholder text when disabled (6 ms)\n      ✓ should handle message with override text (5 ms)\n      ✓ should pass thinking level to streaming options (6 ms)\n    state management\n      ✓ should reset all state to initial values (1 ms)\n      ✓ should not throw when cancel is called (3 ms)\n    provider configuration\n      ✓ should use legacy provider when no chatId provided (1 ms)\n      ✓ should use chat state when chatId is provided (1 ms)\n    title functionality\n      ✓ should update title when setTitle is called (1 ms)\n      ✓ should generate title when generateTitle is called (1 ms)\n    edge cases\n      ✓ should handle non-string input gracefully (1 ms)\n      ✓ keeps completion ordering stable under rapid sends (10 ms)\n      ✓ prevents post-cancel error mutation from stale stream callbacks (7 ms)\n      ✓ deduplicates quick retry taps for the same failed operation (26 ms)\n      ✓ keeps retry state stable when retry is tapped while a retry is inflight (15 ms)\n      ✓ recovers from repeated network flap retries without duplicating chat entries (12 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       23 passed, 23 total\nSnapshots:   0 total\nTime:        0.8 s, estimated 1 s\nRan all test suites matching /hooks\\/chat\\/__tests__\\/useChat.test.ts/i.\n","title":"Verify useChat tests after retry changes","metadata":{"output":"  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { previousState: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'new-stream-initialization' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { previousState: 'streaming' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'network flap',\n      stack: 'Error: network flap\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:459:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:465:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:478:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:477:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'temporary outage',\n      stack: 'Error: temporary outage\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:517:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:523:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:536:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:535:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'network flap - initial',\n      stack: 'Error: network flap - initial\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:572:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:578:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:598:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:597:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\nPASS hooks/chat/__tests__/useChat.test.ts\n  useChat\n    basic functionality\n      ✓ should initialize with default values (13 ms)\n      ✓ should initialize with provided initial text (2 ms)\n      ✓ should update text when setText is called (2 ms)\n      ✓ should not send empty message (1 ms)\n      ✓ should not send whitespace-only message (2 ms)\n    message sending\n      ✓ should send message and add to history (37 ms)\n      ✓ should set isThinking while reasoning streams (8 ms)\n      ✓ should ignore thinking output when disabled (12 ms)\n      ✓ should skip placeholder text when disabled (6 ms)\n      ✓ should handle message with override text (5 ms)\n      ✓ should pass thinking level to streaming options (6 ms)\n    state management\n      ✓ should reset all state to initial values (1 ms)\n      ✓ should not throw when cancel is called (3 ms)\n    provider configuration\n      ✓ should use legacy provider when no chatId provided (1 ms)\n      ✓ should use chat state when chatId is provided (1 ms)\n    title functionality\n      ✓ should update title when setTitle is called (1 ms)\n      ✓ should generate title when generateTitle is called (1 ms)\n    edge cases\n      ✓ should handle non-string input gracefully (1 ms)\n      ✓ keeps completion ordering stable under rapid sends (10 ms)\n      ✓ prevents post-cancel error mutation from stale stream callbacks (7 ms)\n      ✓ deduplicates quick retry taps for the same failed operation (26 ms)\n      ✓ keeps retry state stable when retry is tapped while a retry is inflight (15 ms)\n      ✓ recovers from repeated network flap retries without duplicating chat entries (12 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       23 passed, 23 total\nSnapshots:   0 total\nTime:        0.8 s, estimated 1 s\nRan all test suites matching /hooks\\/chat\\/__tests__\\/useChat.test.ts/i.\n","exit":0,"description":"Verify useChat tests after retry changes","truncated":false},"time":{"start":1770428952775,"end":1770428955795}},"metadata":{"openai":{"itemId":"fc_02a9eddb5aa400f20169869a18adc88196863aba7278432a5b"}}}}
{"type":"step_finish","timestamp":1770428955844,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c9fc94001Hj2v9XpVOOB3N1","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c9d8df001eRQTZgZxU3Uv77","type":"step-finish","reason":"tool-calls","snapshot":"01207a2c1e58a5d897a4e0c815583620455bde0b","cost":0,"tokens":{"input":3994,"output":282,"reasoning":188,"cache":{"read":50688,"write":0}}}}
{"type":"step_start","timestamp":1770428956554,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35c9ff89001C6KzVPev9xZO6F","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c9fcff001Yfi4vxZV3CNJ34","type":"step-start","snapshot":"01207a2c1e58a5d897a4e0c815583620455bde0b"}}
{"type":"tool_use","timestamp":1770428964191,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35ca13a1001hN72ZnZQe7XL7R","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c9fcff001Yfi4vxZV3CNJ34","type":"tool","callID":"call_cO8GXqQpbtvRtLvc8IB3wjqu","tool":"bash","state":{"status":"completed","input":{"command":"npm run lint","workdir":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2","description":"Run lint check"},"output":"\n> seabreeze@1.0.0 lint\n> expo lint\n\n","title":"Run lint check","metadata":{"output":"\n> seabreeze@1.0.0 lint\n> expo lint\n\n","exit":0,"description":"Run lint check","truncated":false},"time":{"start":1770428961752,"end":1770428964191}},"metadata":{"openai":{"itemId":"fc_01164f7a7203c0730169869a21a6348193932f75de25866d82"}}}}
{"type":"tool_use","timestamp":1770428967191,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35ca13e8001aS52iVUQSDcA5V","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c9fcff001Yfi4vxZV3CNJ34","type":"tool","callID":"call_BrYN59JX680ZH2pxulXZpVXj","tool":"bash","state":{"status":"completed","input":{"command":"npx tsc --noEmit","workdir":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2","description":"Run TypeScript noEmit check"},"output":"app/index.tsx(99,14): error TS2339: Property 'chat' does not exist on type '{}'.\nhooks/__tests__/useChatState.test.ts(23,3): error TS2698: Spread types may only be created from object types.\nhooks/__tests__/useChatState.test.ts(152,7): error TS2554: Expected 1 arguments, but got 0.\nhooks/__tests__/useErrorRecovery.test.ts(73,57): error TS2345: Argument of type '\"success\"' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(81,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(92,32): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(93,32): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(94,28): error TS2345: Argument of type '\"success\"' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(104,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(114,57): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(122,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(132,57): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(140,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(173,57): error TS2345: Argument of type '\"success\"' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(185,54): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(188,33): error TS2454: Variable 'promise' is used before being assigned.\nhooks/__tests__/useErrorRecovery.test.ts(239,57): error TS2345: Argument of type '\"success\"' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(250,44): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(251,44): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(252,44): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(292,57): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(295,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(303,57): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(318,40): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nproviders/__tests__/ollama-provider.test.ts(355,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(382,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(400,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(433,51): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(435,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(475,51): error TS2345: Argument of type '{ models: never[]; }' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(477,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(489,51): error TS2345: Argument of type '{ models: never[]; }' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(491,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(505,51): error TS2345: Argument of type '{}' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(507,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(518,51): error TS2345: Argument of type 'null' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(520,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(547,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(600,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(635,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\n","title":"Run TypeScript noEmit check","metadata":{"output":"app/index.tsx(99,14): error TS2339: Property 'chat' does not exist on type '{}'.\nhooks/__tests__/useChatState.test.ts(23,3): error TS2698: Spread types may only be created from object types.\nhooks/__tests__/useChatState.test.ts(152,7): error TS2554: Expected 1 arguments, but got 0.\nhooks/__tests__/useErrorRecovery.test.ts(73,57): error TS2345: Argument of type '\"success\"' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(81,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(92,32): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(93,32): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(94,28): error TS2345: Argument of type '\"success\"' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(104,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(114,57): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(122,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(132,57): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(140,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(173,57): error TS2345: Argument of type '\"success\"' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(185,54): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(188,33): error TS2454: Variable 'promise' is used before being assigned.\nhooks/__tests__/useErrorRecovery.test.ts(239,57): error TS2345: Argument of type '\"success\"' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(250,44): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(251,44): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(252,44): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(292,57): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(295,45): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nhooks/__tests__/useErrorRecovery.test.ts(303,57): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nhooks/__tests__/useErrorRecovery.test.ts(318,40): error TS2345: Argument of type 'Mock<UnknownFunction>' is not assignable to parameter of type '() => Promise<unknown>'.\n  Type 'unknown' is not assignable to type 'Promise<unknown>'.\nproviders/__tests__/ollama-provider.test.ts(355,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(382,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(400,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(433,51): error TS2345: Argument of type 'Error' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(435,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(475,51): error TS2345: Argument of type '{ models: never[]; }' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(477,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(489,51): error TS2345: Argument of type '{ models: never[]; }' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(491,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(505,51): error TS2345: Argument of type '{}' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(507,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(518,51): error TS2345: Argument of type 'null' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(520,13): error TS2322: Type 'Mock<UnknownFunction>' is not assignable to type 'MockedFunction<Mock<UnknownFunction>>'.\n  Type 'Mock<UnknownFunction>' is not assignable to type 'MockInstance<Mock<UnknownFunction>>'.\n    The types returned by 'getMockImplementation()' are incompatible between these types.\n      Type 'UnknownFunction | undefined' is not assignable to type 'Mock<UnknownFunction> | undefined'.\n        Type 'UnknownFunction' is missing the following properties from type 'Mock<UnknownFunction>': _isMockFunction, _protoImpl, getMockImplementation, getMockName, and 15 more.\nproviders/__tests__/ollama-provider.test.ts(547,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(600,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\nproviders/__tests__/ollama-provider.test.ts(635,51): error TS2345: Argument of type 'any' is not assignable to parameter of type 'never'.\n","exit":2,"description":"Run TypeScript noEmit check","truncated":false},"time":{"start":1770428961773,"end":1770428967189}},"metadata":{"openai":{"itemId":"fc_01164f7a7203c0730169869a21a64c8193b4f2bbbb67e5e039"}}}}
{"type":"step_finish","timestamp":1770428967239,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35ca29170018AspLmgsKr4Piw","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35c9fcff001Yfi4vxZV3CNJ34","type":"step-finish","reason":"tool-calls","snapshot":"01207a2c1e58a5d897a4e0c815583620455bde0b","cost":0,"tokens":{"input":18215,"output":267,"reasoning":154,"cache":{"read":25088,"write":0}}}}
{"type":"step_start","timestamp":1770428967965,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35ca2c1d001cl3paUMOIbjxIL","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35ca29820017SQenPur26sc6Z","type":"step-start","snapshot":"01207a2c1e58a5d897a4e0c815583620455bde0b"}}
{"type":"tool_use","timestamp":1770428971985,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35ca3b8a001pjixHZgohIdAJe","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35ca29820017SQenPur26sc6Z","type":"tool","callID":"call_B8VLfCePlWdgzdPQCXMQyF74","tool":"prune","state":{"status":"completed","input":{"ids":["23","6"]},"output":"Context pruning complete. Pruned 2 tool outputs.\n\nSemantically pruned (2):\n→ bash: Show diff for modified story files\n→ read: lib/concurrency.ts","title":"","metadata":{"truncated":false},"time":{"start":1770428971915,"end":1770428971984}},"metadata":{"openai":{"itemId":"fc_08fafec8ec40c39e0169869a2bbd948197b1e7dfde09646cd2"}}}}
{"type":"tool_use","timestamp":1770429092030,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35ca3b85001RmP8IvykQAzPDJ","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35ca29820017SQenPur26sc6Z","type":"tool","callID":"call_pNVrTWn52lGBAfer4owaKUyE","tool":"bash","state":{"status":"completed","input":{"command":"npm test -- --watch=false","workdir":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2","description":"Run full test suite"},"output":"\n> seabreeze@1.0.0 test\n> jest --watchAll --watch=false\n\nFAIL hooks/__tests__/useDatabase.test.ts\n  ● useDatabase › database name configuration › should export correct database name\n\n    expect(received).toBe(expected) // Object.is equality\n\n    Expected: \"seabreeze\"\n    Received: \"seabreeze-v2\"\n\n      48 |   describe('database name configuration', () => {\n      49 |     it('should export correct database name', () => {\n    > 50 |       expect(dbname).toBe('seabreeze');\n         |                      ^\n      51 |     });\n      52 |\n      53 |     it('should use consistent database name across calls', () => {\n\n      at Object.toBe (hooks/__tests__/useDatabase.test.ts:50:22)\n\n  ● useDatabase › database name configuration › should use consistent database name across calls\n\n    expect(received).toBe(expected) // Object.is equality\n\n    Expected: \"seabreeze\"\n    Received: \"seabreeze-v2\"\n\n      55 |       const name2 = dbname;\n      56 |       expect(name1).toBe(name2);\n    > 57 |       expect(name1).toBe('seabreeze');\n         |                     ^\n      58 |     });\n      59 |   });\n      60 |\n\n      at Object.toBe (hooks/__tests__/useDatabase.test.ts:57:21)\n\n  ● useDatabase › initialization side effects › should have imported all dependencies successfully\n\n    expect(received).toBe(expected) // Object.is equality\n\n    Expected: \"seabreeze\"\n    Received: \"seabreeze-v2\"\n\n      113 |     it('should have imported all dependencies successfully', () => {\n      114 |       // If we get to this point, all imports were successful\n    > 115 |       expect(dbname).toBe('seabreeze');\n          |                      ^\n      116 |       expect(typeof useDatabase).toBe('function');\n      117 |     });\n      118 |   });\n\n      at Object.toBe (hooks/__tests__/useDatabase.test.ts:115:22)\n\nFAIL components/ui/__tests__/ThemeProvider.test.tsx\n  ● ThemeProvider › light theme › should render light theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      35 |             renderThemeProvider('light');\n      36 |             \n    > 37 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#f2f2f7');\n         |                           ^\n      38 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#ffffff');\n      39 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#000000');\n      40 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#007AFF');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:37:27)\n\n  ● ThemeProvider › light theme › should set themeType to light\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      45 |         it('should set themeType to light', () => {\n      46 |             renderThemeProvider('light');\n    > 47 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('light');\n         |                           ^\n      48 |         });\n      49 |\n      50 |         it('should set themeMode to light', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:47:27)\n\n  ● ThemeProvider › light theme › should set themeMode to light\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      50 |         it('should set themeMode to light', () => {\n      51 |             renderThemeProvider('light');\n    > 52 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('light');\n         |                           ^\n      53 |         });\n      54 |     });\n      55 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:52:27)\n\n  ● ThemeProvider › dark theme › should render dark theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      58 |             renderThemeProvider('dark');\n      59 |             \n    > 60 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#000000');\n         |                           ^\n      61 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#1a1a1a');\n      62 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#ffffff');\n      63 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#0567d1');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:60:27)\n\n  ● ThemeProvider › dark theme › should set themeType to dark\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      68 |         it('should set themeType to dark', () => {\n      69 |             renderThemeProvider('dark');\n    > 70 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('dark');\n         |                           ^\n      71 |         });\n      72 |\n      73 |         it('should set themeMode to dark', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:70:27)\n\n  ● ThemeProvider › dark theme › should set themeMode to dark\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      73 |         it('should set themeMode to dark', () => {\n      74 |             renderThemeProvider('dark');\n    > 75 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('dark');\n         |                           ^\n      76 |         });\n      77 |     });\n      78 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:75:27)\n\n  ● ThemeProvider › nord theme › should render nord theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      81 |             renderThemeProvider('nord');\n      82 |             \n    > 83 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#2E3440');\n         |                           ^\n      84 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#3B4252');\n      85 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#ECEFF4');\n      86 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#88C0D0');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:83:27)\n\n  ● ThemeProvider › nord theme › should set themeType to nord\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      91 |         it('should set themeType to nord', () => {\n      92 |             renderThemeProvider('nord');\n    > 93 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('nord');\n         |                           ^\n      94 |         });\n      95 |\n      96 |         it('should set themeMode to nord', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:93:27)\n\n  ● ThemeProvider › nord theme › should set themeMode to nord\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n       96 |         it('should set themeMode to nord', () => {\n       97 |             renderThemeProvider('nord');\n    >  98 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('nord');\n          |                           ^\n       99 |         });\n      100 |     });\n      101 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:98:27)\n\n  ● ThemeProvider › catppuccin theme › should render catppuccin theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      104 |             renderThemeProvider('catppuccin');\n      105 |             \n    > 106 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#1E1E2E');\n          |                           ^\n      107 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#313244');\n      108 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#CDD6F4');\n      109 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#89B4FA');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:106:27)\n\n  ● ThemeProvider › catppuccin theme › should set themeType to catppuccin\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      114 |         it('should set themeType to catppuccin', () => {\n      115 |             renderThemeProvider('catppuccin');\n    > 116 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('catppuccin');\n          |                           ^\n      117 |         });\n      118 |\n      119 |         it('should set themeMode to catppuccin', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:116:27)\n\n  ● ThemeProvider › catppuccin theme › should set themeMode to catppuccin\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      119 |         it('should set themeMode to catppuccin', () => {\n      120 |             renderThemeProvider('catppuccin');\n    > 121 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('catppuccin');\n          |                           ^\n      122 |         });\n      123 |     });\n      124 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:121:27)\n\n  ● ThemeProvider › tokyo-night theme › should render tokyo-night theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      127 |             renderThemeProvider('tokyo-night');\n      128 |             \n    > 129 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#1a1b26');\n          |                           ^\n      130 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#24283b');\n      131 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#c0caf5');\n      132 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#7aa2f7');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:129:27)\n\n  ● ThemeProvider › tokyo-night theme › should set themeType to tokyo-night\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      137 |         it('should set themeType to tokyo-night', () => {\n      138 |             renderThemeProvider('tokyo-night');\n    > 139 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('tokyo-night');\n          |                           ^\n      140 |         });\n      141 |\n      142 |         it('should set themeMode to tokyo-night', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:139:27)\n\n  ● ThemeProvider › tokyo-night theme › should set themeMode to tokyo-night\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      142 |         it('should set themeMode to tokyo-night', () => {\n      143 |             renderThemeProvider('tokyo-night');\n    > 144 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('tokyo-night');\n          |                           ^\n      145 |         });\n      146 |     });\n      147 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:144:27)\n\nFAIL app/settings/__tests__/ollama.test.tsx\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should render URL input field with correct label\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      88 |     it('should render URL input field with correct label', () => {\n      89 |       const { getByTestId } = render(<OllamaSettings />);\n    > 90 |       expect(getByTestId('setting-input-Ollama Base URL')).toBeTruthy();\n         |              ^\n      91 |     });\n      92 |\n      93 |     it('should display default URL in input field', () => {\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:90:14)\n\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should display default URL in input field\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      93 |     it('should display default URL in input field', () => {\n      94 |       const { getByTestId } = render(<OllamaSettings />);\n    > 95 |       const input = getByTestId('setting-input-Ollama Base URL') as HTMLInputElement;\n         |                     ^\n      96 |       expect(input.value).toBe('http://localhost:11434');\n      97 |     });\n      98 |\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:95:21)\n\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should have correct placeholder text\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n       99 |     it('should have correct placeholder text', () => {\n      100 |       const { getByTestId } = render(<OllamaSettings />);\n    > 101 |       const input = getByTestId('setting-input-Ollama Base URL') as HTMLInputElement;\n          |                     ^\n      102 |       expect(input.placeholder).toBe('http://localhost:11434');\n      103 |     });\n      104 |\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:101:21)\n\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should allow user to modify the URL\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      105 |     it('should allow user to modify the URL', () => {\n      106 |       const { getByTestId } = render(<OllamaSettings />);\n    > 107 |       const input = getByTestId('setting-input-Ollama Base URL') as any;\n          |                     ^\n      108 |       \n      109 |       fireEvent(input, 'changeText', 'http://192.168.1.100:11434');\n      110 |       expect(input.value).toBe('http://192.168.1.100:11434');\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:107:21)\n\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should disable autocapitalization for URL input\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      113 |     it('should disable autocapitalization for URL input', () => {\n      114 |       const { getByTestId } = render(<OllamaSettings />);\n    > 115 |       const input = getByTestId('setting-input-Ollama Base URL') as HTMLInputElement;\n          |                     ^\n      116 |       // In React Native, autoCapitalize=\"none\" is a prop that prevents uppercase conversion\n      117 |       expect(input).toBeTruthy();\n      118 |     });\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:115:21)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should render Save & Test button\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      122 |     it('should render Save & Test button', () => {\n      123 |       const { getByTestId } = render(<OllamaSettings />);\n    > 124 |       expect(getByTestId('save-button-Save & Test')).toBeTruthy();\n          |              ^\n      125 |     });\n      126 |\n      127 |     it('should render Load Models button', () => {\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:124:14)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should render Load Models button\n\n    Unable to find an element with testID: save-button-Load Models\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      127 |     it('should render Load Models button', () => {\n      128 |       const { getByTestId } = render(<OllamaSettings />);\n    > 129 |       expect(getByTestId('save-button-Load Models')).toBeTruthy();\n          |              ^\n      130 |     });\n      131 |\n      132 |     it('should have both buttons in a row layout', () => {\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:129:14)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should have both buttons in a row layout\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      132 |     it('should have both buttons in a row layout', () => {\n      133 |       const { getByTestId } = render(<OllamaSettings />);\n    > 134 |       const saveButton = getByTestId('save-button-Save & Test');\n          |                          ^\n      135 |       const loadButton = getByTestId('save-button-Load Models');\n      136 |       expect(saveButton).toBeTruthy();\n      137 |       expect(loadButton).toBeTruthy();\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:134:26)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should call handleSave when Save & Test button is pressed\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      140 |     it('should call handleSave when Save & Test button is pressed', async () => {\n      141 |       const { getByTestId } = render(<OllamaSettings />);\n    > 142 |       const saveButton = getByTestId('save-button-Save & Test');\n          |                          ^\n      143 |       \n      144 |       fireEvent(saveButton, 'press');\n      145 |       \n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:142:26)\n      at asyncGeneratorStep (node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\n      at _next (node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\n      at node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\n      at Object.<anonymous> (node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should call handleFetchModels when Load Models button is pressed\n\n    Unable to find an element with testID: save-button-Load Models\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      151 |     it('should call handleFetchModels when Load Models button is pressed', async () => {\n      152 |       const { getByTestId } = render(<OllamaSettings />);\n    > 153 |       const loadButton = getByTestId('save-button-Load Models');\n          |                          ^\n      154 |       \n      155 |       fireEvent(loadButton, 'press');\n      156 |       \n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:153:26)\n      at asyncGeneratorStep (node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\n      at _next (node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\n      at node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\n      at Object.<anonymous> (node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\n\n  ● OllamaSettings Component › SECTION 3: Connection Test Result Message › should display success message color when connection succeeds\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      173 |       \n      174 |       const { getByTestId } = render(<OllamaSettings />);\n    > 175 |       const saveButton = getByTestId('save-button-Save & Test');\n          |                          ^\n      176 |       \n      177 |       fireEvent(saveButton, 'press');\n      178 |       \n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:175:26)\n      at asyncGeneratorStep (node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\n      at _next (node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\n      at node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\n      at Object.<anonymous> (node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\n\n  ● OllamaSettings Component › SECTION 3: Connection Test Result Message › should display error message color when connection fails\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      188 |       \n      189 |       const { getByTestId } = render(<OllamaSettings />);\n    > 190 |       const saveButton = getByTestId('save-button-Save & Test');\n          |                          ^\n      191 |       \n      192 |       fireEvent(saveButton, 'press');\n      193 |       \n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:190:26)\n      at asyncGeneratorStep (node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\n      at _next (node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\n      at node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\n      at Object.<anonymous> (node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\n\n  ● OllamaSettings Component › SECTION 4: Model Selection Manager › should render ModelListManager component\n\n    Unable to find an element with testID: model-list-manager\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      201 |     it('should render ModelListManager component', () => {\n      202 |       const { getByTestId } = render(<OllamaSettings />);\n    > 203 |       expect(getByTestId('model-list-manager')).toBeTruthy();\n          |              ^\n      204 |     });\n      205 |\n      206 |     it('should pass ollama provider ID to ModelListManager', () => {\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:203:14)\n\n  ● OllamaSettings Component › SECTION 4: Model Selection Manager › should pass ollama provider ID to ModelListManager\n\n    Unable to find an element with testID: model-list-manager\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      206 |     it('should pass ollama provider ID to ModelListManager', () => {\n      207 |       const { getByTestId } = render(<OllamaSettings />);\n    > 208 |       const manager = getByTestId('model-list-manager');\n          |                       ^\n      209 |       expect(manager.textContent).toBe('ollama');\n      210 |     });\n      211 |\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:208:23)\n\n  ● OllamaSettings Component › SECTION 4: Model Selection Manager › should render model manager with available models\n\n    Unable to find an element with testID: model-list-manager\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      212 |     it('should render model manager with available models', () => {\n      213 |       const { getByTestId } = render(<OllamaSettings />);\n    > 214 |       expect(getByTestId('model-list-manager')).toBeTruthy();\n          |              ^\n      215 |     });\n      216 |   });\n      217 |\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:214:14)\n\n  ● OllamaSettings Component › Component Rendering › should render without crashing\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      219 |     it('should render without crashing', () => {\n      220 |       const { getByTestId } = render(<OllamaSettings />);\n    > 221 |       expect(getByTestId('setting-input-Ollama Base URL')).toBeTruthy();\n          |              ^\n      222 |     });\n      223 |\n      224 |     it('should render all four main sections', () => {\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:221:14)\n\n  ● OllamaSettings Component › Component Rendering › should render all four main sections\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      225 |       const { getByTestId } = render(<OllamaSettings />);\n      226 |       // Section 1: URL Input\n    > 227 |       expect(getByTestId('setting-input-Ollama Base URL')).toBeTruthy();\n          |              ^\n      228 |       // Section 2: Action Buttons\n      229 |       expect(getByTestId('save-button-Save & Test')).toBeTruthy();\n      230 |       expect(getByTestId('save-button-Load Models')).toBeTruthy();\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:227:14)\n\n  ● OllamaSettings Component › Component Rendering › should have proper view hierarchy\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      235 |     it('should have proper view hierarchy', () => {\n      236 |       const { getByTestId } = render(<OllamaSettings />);\n    > 237 |       expect(getByTestId('setting-input-Ollama Base URL')).toBeTruthy();\n          |              ^\n      238 |       expect(getByTestId('save-button-Save & Test')).toBeTruthy();\n      239 |       expect(getByTestId('model-list-manager')).toBeTruthy();\n      240 |     });\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:237:14)\n\n  ● OllamaSettings Component › State Management › should initialize with correct default URL from auth store\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      244 |     it('should initialize with correct default URL from auth store', () => {\n      245 |       const { getByTestId } = render(<OllamaSettings />);\n    > 246 |       const input = getByTestId('setting-input-Ollama Base URL') as HTMLInputElement;\n          |                     ^\n      247 |       expect(input.value).toBe('http://localhost:11434');\n      248 |     });\n      249 |\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:246:21)\n\n  ● OllamaSettings Component › State Management › should handle URL changes in local state\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      250 |     it('should handle URL changes in local state', () => {\n      251 |       const { getByTestId } = render(<OllamaSettings />);\n    > 252 |       const input = getByTestId('setting-input-Ollama Base URL') as any;\n          |                     ^\n      253 |       \n      254 |       fireEvent(input, 'changeText', 'http://example.com:11434');\n      255 |       expect(input.value).toBe('http://example.com:11434');\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:252:21)\n\n  ● OllamaSettings Component › Accessibility and Layout › should render sections in proper order\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      269 |     it('should render sections in proper order', () => {\n      270 |       const { getByTestId } = render(<OllamaSettings />);\n    > 271 |       const urlInput = getByTestId('setting-input-Ollama Base URL');\n          |                        ^\n      272 |       const saveButton = getByTestId('save-button-Save & Test');\n      273 |       const modelManager = getByTestId('model-list-manager');\n      274 |       \n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:271:24)\n\n  ● OllamaSettings Component › Accessibility and Layout › should have gap between sections\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      280 |     it('should have gap between sections', () => {\n      281 |       const { getByTestId } = render(<OllamaSettings />);\n    > 282 |       expect(getByTestId('setting-input-Ollama Base URL')).toBeTruthy();\n          |              ^\n      283 |       expect(getByTestId('save-button-Save & Test')).toBeTruthy();\n      284 |     });\n      285 |   });\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:282:14)\n\nFAIL components/chat/__tests__/ChatListItem.test.tsx\n  ● ChatListItem Component › renders chat title and preview correctly\n\n    TypeError: Cannot read properties of undefined (reading 'Tap')\n\n      57 |      */\n      58 |     it(\"renders chat title and preview correctly\", () => {\n    > 59 |         render(\n         |               ^\n      60 |             <ChatListItem\n      61 |                 id={1}\n      62 |                 title=\"Test Chat\"\n\n      at Tap (node_modules/react-native-gesture-handler/src/components/ReanimatedSwipeable/ReanimatedSwipeable.tsx:469:25)\n      at mountMemo (node_modules/react-test-renderer/cjs/react-test-renderer.development.js:3859:23)\n      at Object.useMemo (node_modules/react-test-renderer/cjs/react-test-renderer.development.js:13093:18)\n      at Object.<anonymous>.process.env.NODE_ENV.exports.useMemo (node_modules/react/cjs/react.development.js:1209:34)\n      at Swipeable (node_modules/react-native-gesture-handler/src/components/ReanimatedSwipeable/ReanimatedSwipeable.tsx:468:29)\n      at Object.react-stack-bottom-frame (node_modules/react-test-renderer/cjs/react-test-renderer.development.js:13976:20)\n      at renderWithHooks (node_modules/react-test-renderer/cjs/react-test-renderer.development.js:2866:22)\n\n...397188 bytes truncated...\n\nThe tool call succeeded but the output was truncated. Full output saved to: /Users/davidfanaro/.local/share/opencode/tool-output/tool_c35cc10b9001oNiJIw7tz4VHWZ\nUse the Task tool to have explore agent process this file with Grep and Read (with offset/limit). Do NOT read the full file yourself - delegate to save context.","title":"Run full test suite","metadata":{"output":"\n> seabreeze@1.0.0 test\n> jest --watchAll --watch=false\n\nFAIL hooks/__tests__/useDatabase.test.ts\n  ● useDatabase › database name configuration › should export correct database name\n\n    expect(received).toBe(expected) // Object.is equality\n\n    Expected: \"seabreeze\"\n    Received: \"seabreeze-v2\"\n\n      48 |   describe('database name configuration', () => {\n      49 |     it('should export correct database name', () => {\n    > 50 |       expect(dbname).toBe('seabreeze');\n         |                      ^\n      51 |     });\n      52 |\n      53 |     it('should use consistent database name across calls', () => {\n\n      at Object.toBe (hooks/__tests__/useDatabase.test.ts:50:22)\n\n  ● useDatabase › database name configuration › should use consistent database name across calls\n\n    expect(received).toBe(expected) // Object.is equality\n\n    Expected: \"seabreeze\"\n    Received: \"seabreeze-v2\"\n\n      55 |       const name2 = dbname;\n      56 |       expect(name1).toBe(name2);\n    > 57 |       expect(name1).toBe('seabreeze');\n         |                     ^\n      58 |     });\n      59 |   });\n      60 |\n\n      at Object.toBe (hooks/__tests__/useDatabase.test.ts:57:21)\n\n  ● useDatabase › initialization side effects › should have imported all dependencies successfully\n\n    expect(received).toBe(expected) // Object.is equality\n\n    Expected: \"seabreeze\"\n    Received: \"seabreeze-v2\"\n\n      113 |     it('should have imported all dependencies successfully', () => {\n      114 |       // If we get to this point, all imports were successful\n    > 115 |       expect(dbname).toBe('seabreeze');\n          |                      ^\n      116 |       expect(typeof useDatabase).toBe('function');\n      117 |     });\n      118 |   });\n\n      at Object.toBe (hooks/__tests__/useDatabase.test.ts:115:22)\n\nFAIL components/ui/__tests__/ThemeProvider.test.tsx\n  ● ThemeProvider › light theme › should render light theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      35 |             renderThemeProvider('light');\n      36 |             \n    > 37 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#f2f2f7');\n         |                           ^\n      38 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#ffffff');\n      39 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#000000');\n      40 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#007AFF');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:37:27)\n\n  ● ThemeProvider › light theme › should set themeType to light\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      45 |         it('should set themeType to light', () => {\n      46 |             renderThemeProvider('light');\n    > 47 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('light');\n         |                           ^\n      48 |         });\n      49 |\n      50 |         it('should set themeMode to light', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:47:27)\n\n  ● ThemeProvider › light theme › should set themeMode to light\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      50 |         it('should set themeMode to light', () => {\n      51 |             renderThemeProvider('light');\n    > 52 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('light');\n         |                           ^\n      53 |         });\n      54 |     });\n      55 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:52:27)\n\n  ● ThemeProvider › dark theme › should render dark theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      58 |             renderThemeProvider('dark');\n      59 |             \n    > 60 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#000000');\n         |                           ^\n      61 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#1a1a1a');\n      62 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#ffffff');\n      63 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#0567d1');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:60:27)\n\n  ● ThemeProvider › dark theme › should set themeType to dark\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      68 |         it('should set themeType to dark', () => {\n      69 |             renderThemeProvider('dark');\n    > 70 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('dark');\n         |                           ^\n      71 |         });\n      72 |\n      73 |         it('should set themeMode to dark', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:70:27)\n\n  ● ThemeProvider › dark theme › should set themeMode to dark\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      73 |         it('should set themeMode to dark', () => {\n      74 |             renderThemeProvider('dark');\n    > 75 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('dark');\n         |                           ^\n      76 |         });\n      77 |     });\n      78 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:75:27)\n\n  ● ThemeProvider › nord theme › should render nord theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      81 |             renderThemeProvider('nord');\n      82 |             \n    > 83 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#2E3440');\n         |                           ^\n      84 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#3B4252');\n      85 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#ECEFF4');\n      86 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#88C0D0');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:83:27)\n\n  ● ThemeProvider › nord theme › should set themeType to nord\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      91 |         it('should set themeType to nord', () => {\n      92 |             renderThemeProvider('nord');\n    > 93 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('nord');\n         |                           ^\n      94 |         });\n      95 |\n      96 |         it('should set themeMode to nord', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:93:27)\n\n  ● ThemeProvider › nord theme › should set themeMode to nord\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n       96 |         it('should set themeMode to nord', () => {\n       97 |             renderThemeProvider('nord');\n    >  98 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('nord');\n          |                           ^\n       99 |         });\n      100 |     });\n      101 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:98:27)\n\n  ● ThemeProvider › catppuccin theme › should render catppuccin theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      104 |             renderThemeProvider('catppuccin');\n      105 |             \n    > 106 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#1E1E2E');\n          |                           ^\n      107 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#313244');\n      108 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#CDD6F4');\n      109 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#89B4FA');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:106:27)\n\n  ● ThemeProvider › catppuccin theme › should set themeType to catppuccin\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      114 |         it('should set themeType to catppuccin', () => {\n      115 |             renderThemeProvider('catppuccin');\n    > 116 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('catppuccin');\n          |                           ^\n      117 |         });\n      118 |\n      119 |         it('should set themeMode to catppuccin', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:116:27)\n\n  ● ThemeProvider › catppuccin theme › should set themeMode to catppuccin\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      119 |         it('should set themeMode to catppuccin', () => {\n      120 |             renderThemeProvider('catppuccin');\n    > 121 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('catppuccin');\n          |                           ^\n      122 |         });\n      123 |     });\n      124 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:121:27)\n\n  ● ThemeProvider › tokyo-night theme › should render tokyo-night theme colors correctly\n\n    Unable to find an element with testID: theme-background\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      127 |             renderThemeProvider('tokyo-night');\n      128 |             \n    > 129 |             expect(screen.getByTestId('theme-background')).toHaveTextContent('#1a1b26');\n          |                           ^\n      130 |             expect(screen.getByTestId('theme-surface')).toHaveTextContent('#24283b');\n      131 |             expect(screen.getByTestId('theme-text')).toHaveTextContent('#c0caf5');\n      132 |             expect(screen.getByTestId('theme-accent')).toHaveTextContent('#7aa2f7');\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:129:27)\n\n  ● ThemeProvider › tokyo-night theme › should set themeType to tokyo-night\n\n    Unable to find an element with testID: theme-type\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      137 |         it('should set themeType to tokyo-night', () => {\n      138 |             renderThemeProvider('tokyo-night');\n    > 139 |             expect(screen.getByTestId('theme-type')).toHaveTextContent('tokyo-night');\n          |                           ^\n      140 |         });\n      141 |\n      142 |         it('should set themeMode to tokyo-night', () => {\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:139:27)\n\n  ● ThemeProvider › tokyo-night theme › should set themeMode to tokyo-night\n\n    Unable to find an element with testID: theme-mode\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<ActivityIndicator />\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      142 |         it('should set themeMode to tokyo-night', () => {\n      143 |             renderThemeProvider('tokyo-night');\n    > 144 |             expect(screen.getByTestId('theme-mode')).toHaveTextContent('tokyo-night');\n          |                           ^\n      145 |         });\n      146 |     });\n      147 |\n\n      at Object.getByTestId (components/ui/__tests__/ThemeProvider.test.tsx:144:27)\n\nFAIL app/settings/__tests__/ollama.test.tsx\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should render URL input field with correct label\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      88 |     it('should render URL input field with correct label', () => {\n      89 |       const { getByTestId } = render(<OllamaSettings />);\n    > 90 |       expect(getByTestId('setting-input-Ollama Base URL')).toBeTruthy();\n         |              ^\n      91 |     });\n      92 |\n      93 |     it('should display default URL in input field', () => {\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:90:14)\n\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should display default URL in input field\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      93 |     it('should display default URL in input field', () => {\n      94 |       const { getByTestId } = render(<OllamaSettings />);\n    > 95 |       const input = getByTestId('setting-input-Ollama Base URL') as HTMLInputElement;\n         |                     ^\n      96 |       expect(input.value).toBe('http://localhost:11434');\n      97 |     });\n      98 |\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:95:21)\n\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should have correct placeholder text\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n       99 |     it('should have correct placeholder text', () => {\n      100 |       const { getByTestId } = render(<OllamaSettings />);\n    > 101 |       const input = getByTestId('setting-input-Ollama Base URL') as HTMLInputElement;\n          |                     ^\n      102 |       expect(input.placeholder).toBe('http://localhost:11434');\n      103 |     });\n      104 |\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:101:21)\n\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should allow user to modify the URL\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      105 |     it('should allow user to modify the URL', () => {\n      106 |       const { getByTestId } = render(<OllamaSettings />);\n    > 107 |       const input = getByTestId('setting-input-Ollama Base URL') as any;\n          |                     ^\n      108 |       \n      109 |       fireEvent(input, 'changeText', 'http://192.168.1.100:11434');\n      110 |       expect(input.value).toBe('http://192.168.1.100:11434');\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:107:21)\n\n  ● OllamaSettings Component › SECTION 1: URL Input Field › should disable autocapitalization for URL input\n\n    Unable to find an element with testID: setting-input-Ollama Base URL\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      113 |     it('should disable autocapitalization for URL input', () => {\n      114 |       const { getByTestId } = render(<OllamaSettings />);\n    > 115 |       const input = getByTestId('setting-input-Ollama Base URL') as HTMLInputElement;\n          |                     ^\n      116 |       // In React Native, autoCapitalize=\"none\" is a prop that prevents uppercase conversion\n      117 |       expect(input).toBeTruthy();\n      118 |     });\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:115:21)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should render Save & Test button\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      122 |     it('should render Save & Test button', () => {\n      123 |       const { getByTestId } = render(<OllamaSettings />);\n    > 124 |       expect(getByTestId('save-button-Save & Test')).toBeTruthy();\n          |              ^\n      125 |     });\n      126 |\n      127 |     it('should render Load Models button', () => {\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:124:14)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should render Load Models button\n\n    Unable to find an element with testID: save-button-Load Models\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      127 |     it('should render Load Models button', () => {\n      128 |       const { getByTestId } = render(<OllamaSettings />);\n    > 129 |       expect(getByTestId('save-button-Load Models')).toBeTruthy();\n          |              ^\n      130 |     });\n      131 |\n      132 |     it('should have both buttons in a row layout', () => {\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:129:14)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should have both buttons in a row layout\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      132 |     it('should have both buttons in a row layout', () => {\n      133 |       const { getByTestId } = render(<OllamaSettings />);\n    > 134 |       const saveButton = getByTestId('save-button-Save & Test');\n          |                          ^\n      135 |       const loadButton = getByTestId('save-button-Load Models');\n      136 |       expect(saveButton).toBeTruthy();\n      137 |       expect(loadButton).toBeTruthy();\n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:134:26)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should call handleSave when Save & Test button is pressed\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      140 |     it('should call handleSave when Save & Test button is pressed', async () => {\n      141 |       const { getByTestId } = render(<OllamaSettings />);\n    > 142 |       const saveButton = getByTestId('save-button-Save & Test');\n          |                          ^\n      143 |       \n      144 |       fireEvent(saveButton, 'press');\n      145 |       \n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:142:26)\n      at asyncGeneratorStep (node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\n      at _next (node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\n      at node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\n      at Object.<anonymous> (node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\n\n  ● OllamaSettings Component › SECTION 2: Action Buttons Row › should call handleFetchModels when Load Models button is pressed\n\n    Unable to find an element with testID: save-button-Load Models\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mSave & Test\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n                  \u001b[0mLoad Models\u001b[0m\n                \u001b[36m</button>\u001b[39m\n              \u001b[36m</View>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<div>\u001b[39m\n                \u001b[0mollama\u001b[0m\n              \u001b[36m</div>\u001b[39m\n            \u001b[36m</View>\u001b[39m\n            \u001b[36m<View />\u001b[39m\n          \u001b[36m</View>\u001b[39m\n        \u001b[36m</RCTScrollView>\u001b[39m\n      \u001b[36m</RCTSafeAreaView>\u001b[39m\n    \u001b[36m</View>\u001b[39m\n\n      151 |     it('should call handleFetchModels when Load Models button is pressed', async () => {\n      152 |       const { getByTestId } = render(<OllamaSettings />);\n    > 153 |       const loadButton = getByTestId('save-button-Load Models');\n          |                          ^\n      154 |       \n      155 |       fireEvent(loadButton, 'press');\n      156 |       \n\n      at Object.getByTestId (app/settings/__tests__/ollama.test.tsx:153:26)\n      at asyncGeneratorStep (node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\n      at _next (node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\n      at node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\n      at Object.<anonymous> (node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\n\n  ● OllamaSettings Component › SECTION 3: Connection Test Result Message › should display success message color when connection succeeds\n\n    Unable to find an element with testID: save-button-Save & Test\n\n    \u001b[36m<View>\u001b[39m\n      \u001b[36m<RCTSafeAreaView>\u001b[39m\n        \u001b[36m<RCTScrollView>\u001b[39m\n          \u001b[36m<View>\u001b[39m\n            \u001b[36m<input\u001b[39m\n              \u001b[33mplaceholder\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n              \u001b[33mvalue\u001b[39m=\u001b[32m\"http://localhost:11434\"\u001b[39m\n            \u001b[36m/>\u001b[39m\n            \u001b[36m<View>\u001b[39m\n              \u001b[36m<View>\u001b[39m\n                \u001b[36m<button>\u001b[39m\n   \n\n...","exit":1,"description":"Run full test suite","truncated":true,"outputPath":"/Users/davidfanaro/.local/share/opencode/tool-output/tool_c35cc10b9001oNiJIw7tz4VHWZ"},"time":{"start":1770428971911,"end":1770429092027}},"metadata":{"openai":{"itemId":"fc_08fafec8ec40c39e0169869a2bbd80819792ecacbac2d51e1e"}}}}
{"type":"step_finish","timestamp":1770429092079,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc10bd0017SpUmBuyIzfDLg","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35ca29820017SQenPur26sc6Z","type":"step-finish","reason":"tool-calls","snapshot":"01207a2c1e58a5d897a4e0c815583620455bde0b","cost":0,"tokens":{"input":11812,"output":202,"reasoning":117,"cache":{"read":34304,"write":0}}}}
{"type":"step_start","timestamp":1770429093801,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc17a8001dhg4p7UGBR6XHj","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc112b001Dt4BSFhkQqF1w2","type":"step-start","snapshot":"01207a2c1e58a5d897a4e0c815583620455bde0b"}}
{"type":"tool_use","timestamp":1770429101488,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc28500010Npdcwcs0XAe4Q","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc112b001Dt4BSFhkQqF1w2","type":"tool","callID":"call_7AoPlDY83BqxPFotGJ7PoIeU","tool":"bash","state":{"status":"completed","input":{"command":"npx eslint hooks/chat/useChat.ts hooks/chat/__tests__/useChat.test.ts","workdir":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2","description":"Lint changed hook and test files"},"output":"\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n  332:38  warning  A `require()` style import is forbidden  @typescript-eslint/no-require-imports\n  344:38  warning  A `require()` style import is forbidden  @typescript-eslint/no-require-imports\n\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n   47:10  warning  'executeWithRetry' is defined but never used                                                                                                                          @typescript-eslint/no-unused-vars\n   59:6   warning  'ChunkHandler' is defined but never used                                                                                                                              @typescript-eslint/no-unused-vars\n  295:31  warning  'handleStreamingError' is assigned a value but never used                                                                                                             @typescript-eslint/no-unused-vars\n  307:22  warning  'isStreamLifecycleStreaming' is assigned a value but never used                                                                                                       @typescript-eslint/no-unused-vars\n  308:9   warning  'abortController' is assigned a value but never used                                                                                                                  @typescript-eslint/no-unused-vars\n  310:9   warning  'markChunkReceived' is assigned a value but never used                                                                                                                @typescript-eslint/no-unused-vars\n  311:9   warning  'markDoneSignalReceived' is assigned a value but never used                                                                                                           @typescript-eslint/no-unused-vars\n  312:9   warning  'markCompleting' is assigned a value but never used                                                                                                                   @typescript-eslint/no-unused-vars\n  313:9   warning  'markCompleted' is assigned a value but never used                                                                                                                    @typescript-eslint/no-unused-vars\n  607:9   warning  React Hook useCallback has missing dependencies: 'chatId', 'enableFallback', 'initializeStream', and 'markError'. Either include them or remove the dependency array  react-hooks/exhaustive-deps\n\n✖ 12 problems (0 errors, 12 warnings)\n\n","title":"Lint changed hook and test files","metadata":{"output":"\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n  332:38  warning  A `require()` style import is forbidden  @typescript-eslint/no-require-imports\n  344:38  warning  A `require()` style import is forbidden  @typescript-eslint/no-require-imports\n\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n   47:10  warning  'executeWithRetry' is defined but never used                                                                                                                          @typescript-eslint/no-unused-vars\n   59:6   warning  'ChunkHandler' is defined but never used                                                                                                                              @typescript-eslint/no-unused-vars\n  295:31  warning  'handleStreamingError' is assigned a value but never used                                                                                                             @typescript-eslint/no-unused-vars\n  307:22  warning  'isStreamLifecycleStreaming' is assigned a value but never used                                                                                                       @typescript-eslint/no-unused-vars\n  308:9   warning  'abortController' is assigned a value but never used                                                                                                                  @typescript-eslint/no-unused-vars\n  310:9   warning  'markChunkReceived' is assigned a value but never used                                                                                                                @typescript-eslint/no-unused-vars\n  311:9   warning  'markDoneSignalReceived' is assigned a value but never used                                                                                                           @typescript-eslint/no-unused-vars\n  312:9   warning  'markCompleting' is assigned a value but never used                                                                                                                   @typescript-eslint/no-unused-vars\n  313:9   warning  'markCompleted' is assigned a value but never used                                                                                                                    @typescript-eslint/no-unused-vars\n  607:9   warning  React Hook useCallback has missing dependencies: 'chatId', 'enableFallback', 'initializeStream', and 'markError'. Either include them or remove the dependency array  react-hooks/exhaustive-deps\n\n✖ 12 problems (0 errors, 12 warnings)\n\n","exit":0,"description":"Lint changed hook and test files","truncated":false},"time":{"start":1770429098989,"end":1770429101487}},"metadata":{"openai":{"itemId":"fc_08332f88cc2a82630169869aaa007c8195a521df9cf477edc4"}}}}
{"type":"step_finish","timestamp":1770429101536,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc35b0001lIsvReH1LeWN2o","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc112b001Dt4BSFhkQqF1w2","type":"step-finish","reason":"tool-calls","snapshot":"01207a2c1e58a5d897a4e0c815583620455bde0b","cost":0,"tokens":{"input":39367,"output":231,"reasoning":166,"cache":{"read":19968,"write":0}}}}
{"type":"step_start","timestamp":1770429102223,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc388e001iiqElAKuj9Jdrp","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc361d001ZWDT1hIiy8bNen","type":"step-start","snapshot":"01207a2c1e58a5d897a4e0c815583620455bde0b"}}
{"type":"step_finish","timestamp":1770429109282,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc53f2001PpEZhmikhx45J3","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc361d001ZWDT1hIiy8bNen","type":"step-finish","reason":"tool-calls","snapshot":"01207a2c1e58a5d897a4e0c815583620455bde0b","cost":0,"tokens":{"input":40327,"output":277,"reasoning":159,"cache":{"read":19968,"write":0}}}}
{"type":"step_start","timestamp":1770429109995,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc56e9001xtz4CeTlPs8W4D","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc54610018lE7AKAm0aflrR","type":"step-start","snapshot":"01207a2c1e58a5d897a4e0c815583620455bde0b"}}
{"type":"tool_use","timestamp":1770429111642,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc5b1d001QW4aq4qpKoxOZ6","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc54610018lE7AKAm0aflrR","type":"tool","callID":"call_NlSH7XqQjVDDyV3ga4pfzlYP","tool":"read","state":{"status":"completed","input":{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts","offset":620,"limit":120},"output":"<file>\n00621|             onFallback,\n00622|             effectiveProviderId,\n00623|             enableThinking,\n00624|             thinkingLevel,\n00625|             onThinkingChunk\n00626|         ],\n00627|     );\n00628| \n00629|         // =============================================================================\n00630|     // RETRY FUNCTIONALITY\n00631|     // =============================================================================\n00632|     // \n00633|     // Retry functionality allows users to resend their last message when the\n00634|     // AI response failed or was incomplete. This involves:\n00635|     // 1. Removing the failed assistant response\n00636|     // 2. Optionally removing the user message (if they want to edit)\n00637|     // 3. Resending the original message with fresh state\n00638| \n00639|     /**\n00640|      * Retry the last failed message\n00641|      * \n00642|      * This function enables users to retry their last message when the AI\n00643|      * response failed or was cut off. It cleans up the conversation history\n00644|      * and resends the original message with fresh streaming state.\n00645|      */\n00646|     const retryLastMessage = useCallback(async () => {\n00647|         const retryableOperation = lastRetryableOperationRef.current;\n00648| \n00649|         // Guard against invalid retry attempts\n00650|         if (!lastUserMessageRef.current || !canRetry || !retryableOperation) return;\n00651| \n00652|         const retryOperationKey = createIdempotencyKey(\"chat-retry\", [\n00653|             retryableOperation.operationKey,\n00654|             retryableOperation.content,\n00655|         ]);\n00656| \n00657|         await retryOperationRegistryRef.current.run(retryOperationKey, async () => {\n00658|             const currentMessages = messagesRef.current;\n00659|             let nextMessages = [...currentMessages];\n00660|             let removedCount = 0;\n00661| \n00662|             if (nextMessages.length > 0 && nextMessages[nextMessages.length - 1].role === \"assistant\") {\n00663|                 nextMessages = nextMessages.slice(0, -1);\n00664|                 removedCount += 1;\n00665|             }\n00666| \n00667|             const lastMessage = nextMessages[nextMessages.length - 1];\n00668|             if (\n00669|                 lastMessage\n00670|                 && lastMessage.role === \"user\"\n00671|                 && typeof lastMessage.content === \"string\"\n00672|                 && lastMessage.content === retryableOperation.content\n00673|             ) {\n00674|                 nextMessages = nextMessages.slice(0, -1);\n00675|                 removedCount += 1;\n00676|             }\n00677| \n00678|             messagesRef.current = nextMessages;\n00679|             setMessages(nextMessages);\n00680|             setThinkingOutput((prev) => prev.slice(0, Math.max(0, prev.length - removedCount)));\n00681| \n00682|             // Reset retry state and clear error message\n00683|             setCanRetry(false);\n00684|             setErrorMessage(null);\n00685|             lastRetryableOperationRef.current = null;\n00686| \n00687|             await sendMessage(retryableOperation.content);\n00688|         });\n00689|     }, [canRetry, sendMessage]);\n00690| \n00691|     // =============================================================================\n00692|     // PUBLIC INTERFACE\n00693|     // =============================================================================\n00694|     // \n00695|     // Return the complete chat interface. All values are stable references\n00696|     // where appropriate to prevent unnecessary re-renders in consuming components.\n00697|     // The interface provides both state accessors and action functions.\n00698| \n00699|     return {\n00700|         // ────────────────────────────────────────────────────────────────\n00701|         // CORE CHAT STATE\n00702|         // ────────────────────────────────────────────────────────────────\n00703|         text,                           // Current input text\n00704|         setText,                        // Update input text\n00705|         messages,                       // Message history\n00706|         setMessages,                    // Update message history\n00707|         thinkingOutput,                 // Reasoning output\n00708|         setThinkingOutput,              // Update reasoning output\n00709|         isThinking,                     // Thinking status\n00710|         isStreaming,                    // Streaming status\n00711|         streamState,                    // Stream lifecycle state (streaming | completing | completed | error)\n00712| \n00713|         // ────────────────────────────────────────────────────────────────\n00714|         // ACTIONS\n00715|         // ────────────────────────────────────────────────────────────────\n00716|         sendMessage,                    // Send message\n00717|         cancel,                         // Cancel streaming\n00718|         reset,                          // Reset all state\n00719| \n00720|         // ────────────────────────────────────────────────────────────────\n00721|         // TITLE MANAGEMENT\n00722|         // ────────────────────────────────────────────────────────────────\n00723|         title,                          // Current title\n00724|         setTitle,                       // Update title\n00725|         generateTitle,                  // Generate new title\n00726| \n00727|         // ────────────────────────────────────────────────────────────────\n00728|         // PROVIDER STATE\n00729|         // ────────────────────────────────────────────────────────────────\n00730|         currentProvider: activeProvider, // Active AI provider\n00731|         currentModel: activeModel,      // Active model\n00732|         isUsingFallback,                // Fallback status\n00733| \n00734|         // ────────────────────────────────────────────────────────────────\n00735|         // RETRY FUNCTIONALITY\n00736|         // ────────────────────────────────────────────────────────────────\n00737|         retryLastMessage,               // Retry last message\n00738|         canRetry,                       // Whether retry is available\n00739|         errorMessage,                   // Error message for display\n00740|     };\n\n(File has more lines. Use 'offset' parameter to read beyond line 740)\n</file>","title":"hooks/chat/useChat.ts","metadata":{"preview":"            onFallback,\n            effectiveProviderId,\n            enableThinking,\n            thinkingLevel,\n            onThinkingChunk\n        ],\n    );\n\n        // =============================================================================\n    // RETRY FUNCTIONALITY\n    // =============================================================================\n    // \n    // Retry functionality allows users to resend their last message when the\n    // AI response failed or was incomplete. This involves:\n    // 1. Removing the failed assistant response\n    // 2. Optionally removing the user message (if they want to edit)\n    // 3. Resending the original message with fresh state\n\n    /**\n     * Retry the last failed message","truncated":true},"time":{"start":1770429111638,"end":1770429111641}},"metadata":{"openai":{"itemId":"fc_0364700b484f6c9d0169869ab70134819496abdbb50f6336b1"}}}}
{"type":"step_finish","timestamp":1770429111733,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc5d87001xBzcUbpwYtfE77","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc54610018lE7AKAm0aflrR","type":"step-finish","reason":"tool-calls","snapshot":"01207a2c1e58a5d897a4e0c815583620455bde0b","cost":0,"tokens":{"input":1802,"output":82,"reasoning":34,"cache":{"read":58880,"write":0}}}}
{"type":"step_start","timestamp":1770429112361,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc6027001CFe5EbS8rsKiKY","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc5df1001xV73jj16p3JNFl","type":"step-start","snapshot":"01207a2c1e58a5d897a4e0c815583620455bde0b"}}
{"type":"tool_use","timestamp":1770429114487,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc66b8001qh0BfIFh4P2M6H","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc5df1001xV73jj16p3JNFl","type":"tool","callID":"call_MHA09hA4Wc4EMC0xMcRiUZec","tool":"read","state":{"status":"completed","input":{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts","offset":585,"limit":50},"output":"<file>\n00586|             // ────────────────────────────────────────────────────────────────\n00587|             // FALLBACK RETRY LOGIC\n00588|             // ────────────────────────────────────────────────────────────────\n00589|             if (result.shouldRetryWithFallback && !canceledRef.current) {\n00590|                 setIsStreaming(false);\n00591|                 setIsThinking(false);\n00592|                 // Small delay to ensure clean state transition\n00593|                 await new Promise(resolve => setTimeout(resolve, 100));\n00594|                 await sendMessage(content);\n00595|                 return;\n00596|             }\n00597| \n00598|             // ────────────────────────────────────────────────────────────────\n00599|             // COMPLETION\n00600|             // ────────────────────────────────────────────────────────────────\n00601|             if (canMutateForCurrentSend()) {\n00602|                 setIsStreaming(false);\n00603|                 setIsThinking(false);\n00604|                 onComplete?.();\n00605|             }\n00606|         },\n00607|         [\n00608|             text, \n00609|             placeholderText, \n00610|             model, \n00611|             activeProvider, \n00612|             activeModel, \n00613|             isUsingFallback,\n00614|             enableRetry, \n00615|             mergedRetryConfig,\n00616|             executeStreaming,\n00617|             onChunk, \n00618|             onThinkingChunk,\n00619|             onComplete, \n00620|             onError, \n00621|             onFallback,\n00622|             effectiveProviderId,\n00623|             enableThinking,\n00624|             thinkingLevel,\n00625|             onThinkingChunk\n00626|         ],\n00627|     );\n00628| \n00629|         // =============================================================================\n00630|     // RETRY FUNCTIONALITY\n00631|     // =============================================================================\n00632|     // \n00633|     // Retry functionality allows users to resend their last message when the\n00634|     // AI response failed or was incomplete. This involves:\n00635|     // 1. Removing the failed assistant response\n\n(File has more lines. Use 'offset' parameter to read beyond line 635)\n</file>","title":"hooks/chat/useChat.ts","metadata":{"preview":"            // ────────────────────────────────────────────────────────────────\n            // FALLBACK RETRY LOGIC\n            // ────────────────────────────────────────────────────────────────\n            if (result.shouldRetryWithFallback && !canceledRef.current) {\n                setIsStreaming(false);\n                setIsThinking(false);\n                // Small delay to ensure clean state transition\n                await new Promise(resolve => setTimeout(resolve, 100));\n                await sendMessage(content);\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // COMPLETION\n            // ────────────────────────────────────────────────────────────────\n            if (canMutateForCurrentSend()) {\n                setIsStreaming(false);\n                setIsThinking(false);\n                onComplete?.();\n            }","truncated":true},"time":{"start":1770429114484,"end":1770429114486}},"metadata":{"openai":{"itemId":"fc_0f2f9b46782356dc0169869ab9ec6881978e62b23ef63d4d6c"}}}}
{"type":"step_finish","timestamp":1770429114558,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc68900017euj7DUqLb3x9p","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc5df1001xV73jj16p3JNFl","type":"step-finish","reason":"tool-calls","snapshot":"01207a2c1e58a5d897a4e0c815583620455bde0b","cost":0,"tokens":{"input":2250,"output":92,"reasoning":44,"cache":{"read":59904,"write":0}}}}
{"type":"step_start","timestamp":1770429115279,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc6b8d001QnzbCupNNHcSgm","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc68fb001OjmMrpkTfrKQY9","type":"step-start","snapshot":"01207a2c1e58a5d897a4e0c815583620455bde0b"}}
{"type":"tool_use","timestamp":1770429120674,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc712f001nTO3QXtPaV6bN4","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc68fb001OjmMrpkTfrKQY9","type":"tool","callID":"call_ACrDKPUi2gHjylylIBKRbGrt","tool":"apply_patch","state":{"status":"completed","input":{"patchText":"*** Begin Patch\n*** Update File: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n@@\n             onFallback,\n+            chatId,\n+            enableFallback,\n             effectiveProviderId,\n+            initializeStream,\n+            markError,\n             enableThinking,\n             thinkingLevel,\n             onThinkingChunk\n*** End Patch"},"output":"Success. Updated the following files:\nM hooks/chat/useChat.ts","title":"Success. Updated the following files:\nM hooks/chat/useChat.ts","metadata":{"diff":"Index: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n===================================================================\n--- /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n+++ /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n@@ -618,9 +618,13 @@\n     onThinkingChunk,\n     onComplete, \n     onError, \n     onFallback,\n+    chatId,\n+    enableFallback,\n     effectiveProviderId,\n+    initializeStream,\n+    markError,\n     enableThinking,\n     thinkingLevel,\n     onThinkingChunk\n ],\n\n","files":[{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts","relativePath":"hooks/chat/useChat.ts","type":"update","diff":"Index: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n===================================================================\n--- /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n+++ /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n@@ -618,9 +618,13 @@\n     onThinkingChunk,\n     onComplete, \n     onError, \n     onFallback,\n+    chatId,\n+    enableFallback,\n     effectiveProviderId,\n+    initializeStream,\n+    markError,\n     enableThinking,\n     thinkingLevel,\n     onThinkingChunk\n ],\n","before":"/**\n * @file useChat.ts\n * @purpose Main chat orchestrator with comprehensive state management\n * @connects-to useChatStreaming, useTitleGeneration, useChatState\n * \n * =============================================================================\n * COMPREHENSIVE HOOK OVERVIEW\n * =============================================================================\n * \n * useChat is the central hook that manages all chat functionality in the seabreeze\n * application. It orchestrates message handling, streaming responses, provider\n * management, fallback mechanisms, title generation, and error recovery.\n * \n * KEY RESPONSIBILITIES:\n * ────────────────────────────────────────────────────────────────────────\n * • Message state management (input text, message history)\n * • Streaming response handling with real-time updates\n * • AI provider and model management with fallback support\n * • Error handling with automatic retry mechanisms\n * • Chat title generation based on conversation content\n * • Persistent chat state across app sessions\n * \n * ARCHITECTURAL PATTERNS:\n * ────────────────────────────────────────────────────────────────────────\n * • Composition over inheritance - combines specialized hooks\n * • Unidirectional data flow - state flows down, actions flow up\n * • Immutable state updates - ensures React re-renders correctly\n * • Referential stability - uses useCallback/useMemo for performance\n * \n * PROVIDER ECOSYSTEM:\n * ────────────────────────────────────────────────────────────────────────\n * Supports Apple Intelligence, OpenAI, OpenRouter, and Ollama providers with:\n * • Automatic fallback on failures\n * • Model caching for performance\n * • Per-chat provider overrides\n * • Retry with exponential backoff\n * \n * =============================================================================\n */\n\nimport { useCallback, useState, useRef, useEffect, useMemo } from \"react\";\nimport type { LanguageModel, ModelMessage } from \"ai\";\nimport { ProviderId } from \"@/types/provider.types\";\nimport { getProviderModel } from \"@/providers/provider-factory\";\nimport { getCachedModel } from \"@/providers/provider-cache\";\nimport { type FallbackResult } from \"@/providers/fallback-chain\";\nimport { executeWithRetry, DEFAULT_RETRY_CONFIG, type RetryConfig } from \"@/hooks/useErrorRecovery\";\nimport { useChatState } from \"@/hooks/useChatState\";\nimport { useTitleGeneration } from \"./useTitleGeneration\";\nimport { useChatStreaming } from \"./useChatStreaming\";\nimport { useStreamLifecycle } from \"./useStreamLifecycle\";\nimport type { UseChatOptions, StreamState } from \"@/types/chat.types\";\nimport {\n    createIdempotencyKey,\n    createIdempotencyRegistry,\n    createSequenceGuard,\n} from \"@/lib/concurrency\";\n\ntype ChunkHandler = (chunk: string, accumulated: string) => void;\n\ninterface RetryableOperation {\n    operationKey: string;\n    content: string;\n}\n\nconst DEFAULT_PLACEHOLDER_TEXT = \"...\";\n\n// =============================================================================\n// TYPE DEFINITIONS\n// =============================================================================\n// \n// These types define the public interface of the useChat hook, ensuring type\n// safety for all returned values and callbacks.\n\n/**\n * Return type for the useChat hook\n * \n * This interface defines all the values and functions that the hook exposes to\n * consuming components. Each property serves a specific purpose in the chat\n * interaction flow.\n */\nexport interface UseChatReturn {\n    /** Current input text in the chat field */\n    text: string;\n    /** Function to update the input text */\n    setText: (value: string) => void;\n    /** Array of all messages in the conversation */\n    messages: ModelMessage[];\n    /** Function to update the messages array */\n    setMessages: React.Dispatch<React.SetStateAction<ModelMessage[]>>;\n    /** Array of reasoning output aligned with messages */\n    thinkingOutput: string[];\n    /** Function to update the thinking output array */\n    setThinkingOutput: React.Dispatch<React.SetStateAction<string[]>>;\n    /** Whether the AI is currently streaming reasoning text */\n    isThinking: boolean;\n    /** Whether the AI is currently streaming a response */\n    isStreaming: boolean;\n    /** Current stream state for lifecycle tracking */\n    streamState: StreamState;\n    /** Send a message to the AI (optionally override current text) */\n    sendMessage: (overrideText?: string) => Promise<void>;\n    /** Cancel the current streaming response */\n    cancel: () => void;\n    /** Reset all chat state to initial values */\n    reset: () => void;\n    /** Current chat title (generated from conversation) */\n    title: string;\n    /** Function to update the chat title */\n    setTitle: (title: string) => void;\n    /** Generate a new title based on conversation content */\n    generateTitle: () => Promise<string>;\n    /** Currently active AI provider */\n    currentProvider: ProviderId;\n    /** Currently active model within the provider */\n    currentModel: string;\n    /** Whether we're currently using a fallback provider */\n    isUsingFallback: boolean;\n    /** Retry the last failed message */\n    retryLastMessage: () => Promise<void>;\n    /** Whether retry is available for the last message */\n    canRetry: boolean;\n    /** Error message for display when stream fails */\n    errorMessage: string | null;\n}\n\n// =============================================================================\n// MAIN HOOK IMPLEMENTATION\n// =============================================================================\n\n/**\n * Main useChat hook - orchestrates all chat functionality\n * \n * This hook serves as the central hub for chat operations, combining message\n * management, AI provider handling, streaming responses, and error recovery into\n * a cohesive interface.\n * \n * @param options - Configuration options for the chat instance\n * @returns Complete chat interface with state and actions\n */\nexport default function useChat(options: UseChatOptions = {}): UseChatReturn {\n    // =============================================================================\n    // OPTIONS DESTRUCTURING AND DEFAULTS\n    // =============================================================================\n    // \n    // Extract all options with sensible defaults. The hook is designed to work\n    // out-of-the-box with minimal configuration while allowing deep customization.\n    \n    const {\n        initialMessages = [],              // Start with empty message history\n        initialText = \"\",                  // Start with empty input field\n        placeholder = true,                // Enable placeholder for AI responses\n        providerId: legacyProviderId,      // Deprecated: use chatId instead\n        modelId: legacyModelId,           // Deprecated: use chatId instead\n        chatId,                           // Modern unified state management\n        model: providedModel,             // Direct model injection (testing)\n        onChunk,                          // Callback for streaming chunks\n        onThinkingChunk,                  // Callback for streaming thinking chunks\n        enableThinking = true,            // Enable thinking output updates\n        thinkingLevel,                    // Control reasoning effort when supported\n        onError,                          // Error handling callback\n        onComplete,                       // Completion callback\n        onFallback,                       // Provider fallback notification\n        enableFallback = true,            // Enable automatic fallback\n        enableRetry = true,               // Enable automatic retry\n        retryConfig = {},                 // Custom retry configuration\n    } = options;\n\n    // =============================================================================\n    // CHAT STATE MANAGEMENT\n    // =============================================================================\n    // \n    // Initialize chat state management. This handles both the new unified approach\n    // (using chatId) and legacy providerId/modelId for backward compatibility.\n    \n    const chatState = useChatState(chatId || null);\n    \n    // Resolve effective provider/model based on whether we're using unified state\n    // or legacy direct provider specification\n    const effectiveProviderId = chatId \n        ? chatState.provider                    // Use unified chat state\n        : (legacyProviderId || \"apple\");       // Fallback to legacy or default\n    const effectiveModelId = chatId \n        ? chatState.model                      // Use unified chat state  \n        : (legacyModelId || \"system-default\"); // Fallback to legacy or default\n\n    // =============================================================================\n    // CORE REACT STATE\n    // =============================================================================\n    // \n    // These are the fundamental React state variables that drive the chat interface.\n    // Each piece of state has a specific responsibility in the chat flow.\n    \n    const [text, setText] = useState<string>(initialText);           // Input field content\n    const [messages, setMessages] = useState<ModelMessage[]>(initialMessages); // Message history\n    const [thinkingOutput, setThinkingOutput] = useState<string[]>(\n        () => initialMessages.map(() => \"\")\n    );\n    const [isThinking, setIsThinking] = useState<boolean>(false);\n    const [isStreaming, setIsStreaming] = useState<boolean>(false);  // Streaming status\n    \n    // =============================================================================\n    // PROVIDER AND FALLBACK STATE\n    // =============================================================================\n    // \n    // These state variables manage the AI provider ecosystem, including fallback\n    // handling and provider switching during failures.\n    \n    const [activeProvider, setActiveProvider] = useState<ProviderId>(effectiveProviderId);\n    const [activeModel, setActiveModel] = useState<string>(effectiveModelId);\n    const [isUsingFallback, setIsUsingFallback] = useState<boolean>(false);\n    \n    // =============================================================================\n    // REFERENCES FOR STABLE OPERATIONS\n    // =============================================================================\n    // \n    // useRef values that persist across re-renders without triggering them.\n    // These are used for tracking operation state and maintaining data integrity.\n    \n    const failedProvidersRef = useRef<ProviderId[]>([]);     // Track failed providers for fallback\n    \n    // Retry and cancellation tracking\n    const lastUserMessageRef = useRef<string | null>(null); // Store last user message for retry\n    const [canRetry, setCanRetry] = useState<boolean>(false); // Whether retry is available\n    const [errorMessage, setErrorMessage] = useState<string | null>(null); // Error message for display\n    const canceledRef = useRef<boolean>(false);             // Track if streaming was canceled\n    const messagesRef = useRef<ModelMessage[]>(initialMessages);\n    const sendSequenceGuardRef = useRef(createSequenceGuard(`chat-send-${chatId ?? \"default\"}`));\n    const retryOperationRegistryRef = useRef(createIdempotencyRegistry<void>());\n    const lastRetryableOperationRef = useRef<RetryableOperation | null>(null);\n\n    useEffect(() => {\n        messagesRef.current = messages;\n    }, [messages]);\n\n    // =============================================================================\n    // CONFIGURATION MERGING\n    // =============================================================================\n    // \n    // Merge user-provided retry configuration with system defaults to create\n    // the final configuration used throughout the hook.\n    \n    const mergedRetryConfig: RetryConfig = { ...DEFAULT_RETRY_CONFIG, ...retryConfig };\n    const placeholderText = placeholder ? DEFAULT_PLACEHOLDER_TEXT : \"\";\n\n        // =============================================================================\n    // MODEL RESOLUTION AND CACHING\n    // =============================================================================\n    // \n    // Resolve the actual AI model to use for chat operations. This involves:\n    // 1. Using directly provided model (for testing/special cases)\n    // 2. Looking up cached model for performance\n    // 3. Creating new model instance if needed\n    // \n    // The useMemo ensures we only recompute when provider/model actually changes.\n    \n    const model: LanguageModel | null = useMemo(() => {\n        // Direct model injection takes precedence (useful for testing)\n        if (providedModel) {\n            return providedModel as LanguageModel;\n        }\n\n        // Try to get cached model for performance\n        const cachedModel = getCachedModel(\n            activeProvider,\n            activeModel,\n            () => getProviderModel(activeProvider, activeModel).model\n        );\n\n        return cachedModel || null;\n    }, [providedModel, activeProvider, activeModel]);\n\n    // =============================================================================\n    // TITLE GENERATION INTEGRATION\n    // =============================================================================\n    // \n    // Connect to the title generation subsystem. Titles are automatically\n    // generated based on conversation content and used for chat identification\n    // in the UI and database storage.\n    \n    const { title, setTitle, generateTitle } = useTitleGeneration(\n        messages.map(m => ({ role: m.role, content: typeof m.content === 'string' ? m.content : '' })),\n        model,\n        enableRetry,\n        mergedRetryConfig\n    );\n\n    // =============================================================================\n    // STREAMING INFRASTRUCTURE\n    // =============================================================================\n    // \n    // Connect to the streaming subsystem that handles real-time AI responses.\n    // This provides the core functionality for streaming text from AI providers.\n    \n    const { executeStreaming, handleStreamingError } = useChatStreaming();\n\n    // =============================================================================\n    // STREAM LIFECYCLE MANAGEMENT\n    // =============================================================================\n    // \n    // Manages stream state transitions, timeout detection, and cleanup.\n    // Ensures streams always complete fully and handles edge cases like\n    // app backgrounding and navigation away.\n    \n    const {\n        streamState,\n        isStreaming: isStreamLifecycleStreaming,\n        abortController,\n        initializeStream,\n        markChunkReceived,\n        markDoneSignalReceived,\n        markCompleting,\n        markCompleted,\n        markError,\n        cancelStream,\n    } = useStreamLifecycle({\n        timeoutMs: 30000, // 30 second fallback timeout\n        backgroundBehavior: \"cancel\",\n        enableLogging: __DEV__,\n        onError: (error) => {\n            console.error(\"[StreamLifecycle] Error:\", error.message);\n            onError?.(error);\n        },\n    });\n\n        // =============================================================================\n    // PROVIDER RESET EFFECT\n    // =============================================================================\n    // \n    // This effect ensures that when streaming completes (either successfully or\n    // with failure), we reset the provider state to the originally intended\n    // provider/model. This prevents fallback state from persisting between\n    // messages.\n    \n    useEffect(() => {\n        // Only reset when not actively streaming to avoid race conditions\n        if (!isStreaming) {\n            setActiveProvider(effectiveProviderId);\n            setActiveModel(effectiveModelId);\n            setIsUsingFallback(false);\n            failedProvidersRef.current = [];\n        }\n    }, [effectiveProviderId, effectiveModelId, isStreaming]);\n\n    // =============================================================================\n    // UTILITY FUNCTIONS\n    // =============================================================================\n    // \n    // Core utility functions that control chat state and flow. These are\n    // memoized with useCallback to maintain referential stability and prevent\n    // unnecessary re-renders in child components.\n\n    /**\n     * Reset all chat state to initial values\n     * \n     * This function completely clears the chat history, resets the input field,\n     * restores the original title, and resets all provider and fallback state.\n     * It's typically used when starting a new chat conversation.\n     */\n    const reset = useCallback(() => {\n        setText(\"\");                              // Clear input field\n        setMessages([]);                          // Clear message history\n        setThinkingOutput([]);                    // Clear reasoning output\n        setIsThinking(false);                     // Clear thinking state\n        setTitle(\"Chat\");                         // Reset to default title\n        setActiveProvider(effectiveProviderId);   // Reset to intended provider\n        setActiveModel(effectiveModelId);        // Reset to intended model\n        setIsUsingFallback(false);                // Clear fallback state\n        failedProvidersRef.current = [];         // Clear failed providers list\n        lastUserMessageRef.current = null;       // Clear retry message\n        setCanRetry(false);                      // Disable retry capability\n        setErrorMessage(null);                   // Clear error message\n        lastRetryableOperationRef.current = null;\n        retryOperationRegistryRef.current.clear();\n    }, [effectiveProviderId, effectiveModelId, setTitle]);\n\n    /**\n     * Cancel the current streaming operation\n     *\n     * Sets a flag that the streaming loop checks to determine if it should\n     * stop processing chunks. This provides a clean way to interrupt AI responses.\n     */\n    const cancel = useCallback(() => {\n        canceledRef.current = true;\n        sendSequenceGuardRef.current.next();\n        setIsStreaming(false);\n        setIsThinking(false);\n        cancelStream(); // Use stream lifecycle cancel for comprehensive cancellation\n    }, [cancelStream]);\n\n        // =============================================================================\n    // CORE MESSAGE SENDING LOGIC\n    // =============================================================================\n    // \n    // This is the heart of the chat functionality. The sendMessage function:\n    // 1. Validates and prepares the user message\n    // 2. Updates the message history\n    // 3. Initiates streaming with the AI provider\n    // 4. Handles fallback and retry logic\n    // 5. Manages the complete message flow lifecycle\n\n    /**\n     * Send a message to the AI and initiate streaming response\n     * \n     * @param overrideText - Optional text to send instead of current input\n     * \n     * This function orchestrates the complete message sending flow:\n     * 1. Input validation and preprocessing\n     * 2. Message history updates\n     * 3. AI provider streaming initiation\n     * 4. Error handling with fallback mechanisms\n     * 5. Completion callbacks\n     */\n    const sendMessage = useCallback(\n        async (overrideText?: string) => {\n            // ────────────────────────────────────────────────────────────────\n            // INPUT VALIDATION AND PREPARATION\n            // ────────────────────────────────────────────────────────────────\n            const rawValue: unknown = overrideText ?? (text as unknown);\n            const content = typeof rawValue === \"string\" ? rawValue.trim() : \"\";\n            \n            // Exit early if no valid content to send\n            if (!content) return;\n\n            const sendToken = sendSequenceGuardRef.current.next();\n            const sendOperationKey = createIdempotencyKey(\"chat-send\", [\n                chatId ?? \"default\",\n                sendToken.sequence,\n                content,\n            ]);\n\n            // ────────────────────────────────────────────────────────────────\n            // STATE INITIALIZATION\n            // ────────────────────────────────────────────────────────────────\n            setIsStreaming(true);                    // Start streaming state\n            setIsThinking(false);                    // Reset thinking state\n            canceledRef.current = false;            // Clear cancellation flag\n            setCanRetry(false);                     // Disable retry until needed\n            lastRetryableOperationRef.current = null;\n            lastUserMessageRef.current = content;   // Store for retry capability\n            \n            // Initialize stream lifecycle management\n            const streamController = initializeStream();\n            const abortSignal = streamController.signal;\n            const canMutateForCurrentSend = (): boolean => (\n                sendSequenceGuardRef.current.isCurrent(sendToken)\n                && !canceledRef.current\n                && !abortSignal.aborted\n            );\n\n            // ────────────────────────────────────────────────────────────────\n            // MESSAGE HISTORY MANAGEMENT\n            // ────────────────────────────────────────────────────────────────\n            const userMessage: ModelMessage = { role: \"user\", content };\n            const updatedMessages = [...messagesRef.current, userMessage];\n            setMessages(updatedMessages);\n            setThinkingOutput((prev) => [...prev, \"\"]);\n\n            // Clear input field if we're using the current text (not override)\n            if (overrideText === undefined) {\n                setText(\"\");\n            }\n\n            // Add placeholder for assistant response\n            const assistantIndex = updatedMessages.length;\n            setMessages((prev) => [\n                ...prev,\n                {\n                    role: \"assistant\",\n                    content: placeholderText,\n                },\n            ]);\n            setThinkingOutput((prev) => [...prev, \"\"]);\n\n            // ────────────────────────────────────────────────────────────────\n            // MODEL VALIDATION\n            // ────────────────────────────────────────────────────────────────\n            if (!model) {\n                // Show helpful error message when no provider is configured\n                setMessages((prev) => {\n                    const next = [...prev];\n                    next[assistantIndex] = {\n                        role: \"assistant\",\n                        content: \"**Setup Required**\\n\\nNo AI provider configured. Please set up a provider in settings.\\n\\n*Go to Settings to configure an AI provider.*\",\n                    };\n                    return next;\n                });\n                \n                onError?.(new Error(\"No AI provider configured\"));\n                setIsStreaming(false);\n                setIsThinking(false);\n                onComplete?.();\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // STREAMING CONFIGURATION\n            // ────────────────────────────────────────────────────────────────\n            const handleThinkingChunk = enableThinking\n                ? (chunk: string, accumulated: string) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    setIsThinking(true);\n                    setThinkingOutput((prev) => {\n                        const next = [...prev];\n                        next[assistantIndex] = accumulated;\n                        return next;\n                    });\n                    onThinkingChunk?.(chunk, accumulated);\n                }\n                : undefined;\n\n            const streamingOptions = {\n                model: {\n                    model,\n                    provider: activeProvider,\n                    modelId: activeModel,\n                    isOriginal: !isUsingFallback,\n                    attemptedProviders: failedProvidersRef.current,\n                } as FallbackResult,\n                enableRetry,\n                retryConfig: mergedRetryConfig,\n                enableFallback,\n                activeProvider,\n                effectiveProviderId,\n                thinkingLevel,\n                abortSignal,\n                onChunk,\n                onThinkingChunk: handleThinkingChunk,\n                canMutateState: canMutateForCurrentSend,\n                onError: (error: unknown) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    if (error instanceof Error) {\n                        markError(error);\n                        setErrorMessage(error.message);\n                        setCanRetry(true);\n                        lastRetryableOperationRef.current = {\n                            operationKey: sendOperationKey,\n                            content,\n                        };\n                        onError?.(error);\n                    } else {\n                        const wrappedError = new Error(String(error));\n                        markError(wrappedError);\n                        setErrorMessage(wrappedError.message);\n                        setCanRetry(true);\n                        lastRetryableOperationRef.current = {\n                            operationKey: sendOperationKey,\n                            content,\n                        };\n                        onError?.(wrappedError);\n                    }\n                },\n                onFallback,\n                onProviderChange: (provider: ProviderId, model: string, isFallback: boolean) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    setActiveProvider(provider);\n                    setActiveModel(model);\n                    setIsUsingFallback(isFallback);\n                },\n            };\n\n            // ────────────────────────────────────────────────────────────────\n            // STREAMING EXECUTION\n            // ────────────────────────────────────────────────────────────────\n            const result = await executeStreaming(\n                streamingOptions,\n                updatedMessages,\n                setMessages,\n                assistantIndex,\n                failedProvidersRef\n            );\n\n            if (!sendSequenceGuardRef.current.isCurrent(sendToken)) {\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // FALLBACK RETRY LOGIC\n            // ────────────────────────────────────────────────────────────────\n            if (result.shouldRetryWithFallback && !canceledRef.current) {\n                setIsStreaming(false);\n                setIsThinking(false);\n                // Small delay to ensure clean state transition\n                await new Promise(resolve => setTimeout(resolve, 100));\n                await sendMessage(content);\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // COMPLETION\n            // ────────────────────────────────────────────────────────────────\n            if (canMutateForCurrentSend()) {\n                setIsStreaming(false);\n                setIsThinking(false);\n                onComplete?.();\n            }\n        },\n        [\n            text, \n            placeholderText, \n            model, \n            activeProvider, \n            activeModel, \n            isUsingFallback,\n            enableRetry, \n            mergedRetryConfig,\n            executeStreaming,\n            onChunk, \n            onThinkingChunk,\n            onComplete, \n            onError, \n            onFallback,\n            effectiveProviderId,\n            enableThinking,\n            thinkingLevel,\n            onThinkingChunk\n        ],\n    );\n\n        // =============================================================================\n    // RETRY FUNCTIONALITY\n    // =============================================================================\n    // \n    // Retry functionality allows users to resend their last message when the\n    // AI response failed or was incomplete. This involves:\n    // 1. Removing the failed assistant response\n    // 2. Optionally removing the user message (if they want to edit)\n    // 3. Resending the original message with fresh state\n\n    /**\n     * Retry the last failed message\n     * \n     * This function enables users to retry their last message when the AI\n     * response failed or was cut off. It cleans up the conversation history\n     * and resends the original message with fresh streaming state.\n     */\n    const retryLastMessage = useCallback(async () => {\n        const retryableOperation = lastRetryableOperationRef.current;\n\n        // Guard against invalid retry attempts\n        if (!lastUserMessageRef.current || !canRetry || !retryableOperation) return;\n\n        const retryOperationKey = createIdempotencyKey(\"chat-retry\", [\n            retryableOperation.operationKey,\n            retryableOperation.content,\n        ]);\n\n        await retryOperationRegistryRef.current.run(retryOperationKey, async () => {\n            const currentMessages = messagesRef.current;\n            let nextMessages = [...currentMessages];\n            let removedCount = 0;\n\n            if (nextMessages.length > 0 && nextMessages[nextMessages.length - 1].role === \"assistant\") {\n                nextMessages = nextMessages.slice(0, -1);\n                removedCount += 1;\n            }\n\n            const lastMessage = nextMessages[nextMessages.length - 1];\n            if (\n                lastMessage\n                && lastMessage.role === \"user\"\n                && typeof lastMessage.content === \"string\"\n                && lastMessage.content === retryableOperation.content\n            ) {\n                nextMessages = nextMessages.slice(0, -1);\n                removedCount += 1;\n            }\n\n            messagesRef.current = nextMessages;\n            setMessages(nextMessages);\n            setThinkingOutput((prev) => prev.slice(0, Math.max(0, prev.length - removedCount)));\n\n            // Reset retry state and clear error message\n            setCanRetry(false);\n            setErrorMessage(null);\n            lastRetryableOperationRef.current = null;\n\n            await sendMessage(retryableOperation.content);\n        });\n    }, [canRetry, sendMessage]);\n\n    // =============================================================================\n    // PUBLIC INTERFACE\n    // =============================================================================\n    // \n    // Return the complete chat interface. All values are stable references\n    // where appropriate to prevent unnecessary re-renders in consuming components.\n    // The interface provides both state accessors and action functions.\n\n    return {\n        // ────────────────────────────────────────────────────────────────\n        // CORE CHAT STATE\n        // ────────────────────────────────────────────────────────────────\n        text,                           // Current input text\n        setText,                        // Update input text\n        messages,                       // Message history\n        setMessages,                    // Update message history\n        thinkingOutput,                 // Reasoning output\n        setThinkingOutput,              // Update reasoning output\n        isThinking,                     // Thinking status\n        isStreaming,                    // Streaming status\n        streamState,                    // Stream lifecycle state (streaming | completing | completed | error)\n\n        // ────────────────────────────────────────────────────────────────\n        // ACTIONS\n        // ────────────────────────────────────────────────────────────────\n        sendMessage,                    // Send message\n        cancel,                         // Cancel streaming\n        reset,                          // Reset all state\n\n        // ────────────────────────────────────────────────────────────────\n        // TITLE MANAGEMENT\n        // ────────────────────────────────────────────────────────────────\n        title,                          // Current title\n        setTitle,                       // Update title\n        generateTitle,                  // Generate new title\n\n        // ────────────────────────────────────────────────────────────────\n        // PROVIDER STATE\n        // ────────────────────────────────────────────────────────────────\n        currentProvider: activeProvider, // Active AI provider\n        currentModel: activeModel,      // Active model\n        isUsingFallback,                // Fallback status\n\n        // ────────────────────────────────────────────────────────────────\n        // RETRY FUNCTIONALITY\n        // ────────────────────────────────────────────────────────────────\n        retryLastMessage,               // Retry last message\n        canRetry,                       // Whether retry is available\n        errorMessage,                   // Error message for display\n    };\n}\n\n/*\n * =============================================================================\n * HOOK COMPREHENSIVE DOCUMENTATION\n * =============================================================================\n * \n * ARCHITECTURAL SUMMARY:\n * ────────────────────────────────────────────────────────────────────────\n * useChat is a sophisticated hook that combines multiple concerns into a\n * cohesive chat interface. It follows the composition pattern, building upon\n * specialized hooks for different aspects of chat functionality.\n * \n * KEY PRINCIPLES:\n * ────────────────────────────────────────────────────────────────────────\n * 1. Separation of Concerns: Different aspects (streaming, title generation,\n *    state management) are handled by dedicated hooks\n * 2. Referential Stability: useCallback and useMemo prevent unnecessary re-renders\n * 3. Unidirectional Data Flow: State flows down, actions flow up\n * 4. Error Resilience: Multiple layers of error handling and fallback\n * 5. Performance Optimization: Caching, memoization, and efficient updates\n * \n * PROVIDER ECOSYSTEM INTEGRATION:\n * ────────────────────────────────────────────────────────────────────────\n * The hook integrates with a robust provider system that supports:\n * • Multiple AI providers (Apple, OpenAI, OpenRouter, Ollama)\n * • Automatic fallback on failures\n * • Model caching for performance\n * • Per-chat provider overrides\n * • Retry with exponential backoff\n * \n * STATE MANAGEMENT STRATEGY:\n * ────────────────────────────────────────────────────────────────────────\n * • Local React state for immediate UI updates\n * • Zustand stores for persistent data\n * • Refs for operation tracking without re-renders\n * • Unified chat state system for consistency\n * \n * ERROR HANDLING APPROACH:\n * ────────────────────────────────────────────────────────────────────────\n * • Graceful degradation when providers fail\n * • User-friendly error messages\n * • Automatic retry with configurable backoff\n * • Fallback chain through multiple providers\n * • Recovery mechanisms for common failure scenarios\n * \n * PERFORMANCE OPTIMIZATIONS:\n * ────────────────────────────────────────────────────────────────────────\n * • Model caching to avoid repeated initialization\n * • Memoized callbacks to prevent child re-renders\n * • Efficient state updates with minimal re-renders\n * • Lazy loading of provider resources\n * • Streaming to provide immediate feedback\n * \n * =============================================================================\n */\n","after":"/**\n * @file useChat.ts\n * @purpose Main chat orchestrator with comprehensive state management\n * @connects-to useChatStreaming, useTitleGeneration, useChatState\n * \n * =============================================================================\n * COMPREHENSIVE HOOK OVERVIEW\n * =============================================================================\n * \n * useChat is the central hook that manages all chat functionality in the seabreeze\n * application. It orchestrates message handling, streaming responses, provider\n * management, fallback mechanisms, title generation, and error recovery.\n * \n * KEY RESPONSIBILITIES:\n * ────────────────────────────────────────────────────────────────────────\n * • Message state management (input text, message history)\n * • Streaming response handling with real-time updates\n * • AI provider and model management with fallback support\n * • Error handling with automatic retry mechanisms\n * • Chat title generation based on conversation content\n * • Persistent chat state across app sessions\n * \n * ARCHITECTURAL PATTERNS:\n * ────────────────────────────────────────────────────────────────────────\n * • Composition over inheritance - combines specialized hooks\n * • Unidirectional data flow - state flows down, actions flow up\n * • Immutable state updates - ensures React re-renders correctly\n * • Referential stability - uses useCallback/useMemo for performance\n * \n * PROVIDER ECOSYSTEM:\n * ────────────────────────────────────────────────────────────────────────\n * Supports Apple Intelligence, OpenAI, OpenRouter, and Ollama providers with:\n * • Automatic fallback on failures\n * • Model caching for performance\n * • Per-chat provider overrides\n * • Retry with exponential backoff\n * \n * =============================================================================\n */\n\nimport { useCallback, useState, useRef, useEffect, useMemo } from \"react\";\nimport type { LanguageModel, ModelMessage } from \"ai\";\nimport { ProviderId } from \"@/types/provider.types\";\nimport { getProviderModel } from \"@/providers/provider-factory\";\nimport { getCachedModel } from \"@/providers/provider-cache\";\nimport { type FallbackResult } from \"@/providers/fallback-chain\";\nimport { executeWithRetry, DEFAULT_RETRY_CONFIG, type RetryConfig } from \"@/hooks/useErrorRecovery\";\nimport { useChatState } from \"@/hooks/useChatState\";\nimport { useTitleGeneration } from \"./useTitleGeneration\";\nimport { useChatStreaming } from \"./useChatStreaming\";\nimport { useStreamLifecycle } from \"./useStreamLifecycle\";\nimport type { UseChatOptions, StreamState } from \"@/types/chat.types\";\nimport {\n    createIdempotencyKey,\n    createIdempotencyRegistry,\n    createSequenceGuard,\n} from \"@/lib/concurrency\";\n\ntype ChunkHandler = (chunk: string, accumulated: string) => void;\n\ninterface RetryableOperation {\n    operationKey: string;\n    content: string;\n}\n\nconst DEFAULT_PLACEHOLDER_TEXT = \"...\";\n\n// =============================================================================\n// TYPE DEFINITIONS\n// =============================================================================\n// \n// These types define the public interface of the useChat hook, ensuring type\n// safety for all returned values and callbacks.\n\n/**\n * Return type for the useChat hook\n * \n * This interface defines all the values and functions that the hook exposes to\n * consuming components. Each property serves a specific purpose in the chat\n * interaction flow.\n */\nexport interface UseChatReturn {\n    /** Current input text in the chat field */\n    text: string;\n    /** Function to update the input text */\n    setText: (value: string) => void;\n    /** Array of all messages in the conversation */\n    messages: ModelMessage[];\n    /** Function to update the messages array */\n    setMessages: React.Dispatch<React.SetStateAction<ModelMessage[]>>;\n    /** Array of reasoning output aligned with messages */\n    thinkingOutput: string[];\n    /** Function to update the thinking output array */\n    setThinkingOutput: React.Dispatch<React.SetStateAction<string[]>>;\n    /** Whether the AI is currently streaming reasoning text */\n    isThinking: boolean;\n    /** Whether the AI is currently streaming a response */\n    isStreaming: boolean;\n    /** Current stream state for lifecycle tracking */\n    streamState: StreamState;\n    /** Send a message to the AI (optionally override current text) */\n    sendMessage: (overrideText?: string) => Promise<void>;\n    /** Cancel the current streaming response */\n    cancel: () => void;\n    /** Reset all chat state to initial values */\n    reset: () => void;\n    /** Current chat title (generated from conversation) */\n    title: string;\n    /** Function to update the chat title */\n    setTitle: (title: string) => void;\n    /** Generate a new title based on conversation content */\n    generateTitle: () => Promise<string>;\n    /** Currently active AI provider */\n    currentProvider: ProviderId;\n    /** Currently active model within the provider */\n    currentModel: string;\n    /** Whether we're currently using a fallback provider */\n    isUsingFallback: boolean;\n    /** Retry the last failed message */\n    retryLastMessage: () => Promise<void>;\n    /** Whether retry is available for the last message */\n    canRetry: boolean;\n    /** Error message for display when stream fails */\n    errorMessage: string | null;\n}\n\n// =============================================================================\n// MAIN HOOK IMPLEMENTATION\n// =============================================================================\n\n/**\n * Main useChat hook - orchestrates all chat functionality\n * \n * This hook serves as the central hub for chat operations, combining message\n * management, AI provider handling, streaming responses, and error recovery into\n * a cohesive interface.\n * \n * @param options - Configuration options for the chat instance\n * @returns Complete chat interface with state and actions\n */\nexport default function useChat(options: UseChatOptions = {}): UseChatReturn {\n    // =============================================================================\n    // OPTIONS DESTRUCTURING AND DEFAULTS\n    // =============================================================================\n    // \n    // Extract all options with sensible defaults. The hook is designed to work\n    // out-of-the-box with minimal configuration while allowing deep customization.\n    \n    const {\n        initialMessages = [],              // Start with empty message history\n        initialText = \"\",                  // Start with empty input field\n        placeholder = true,                // Enable placeholder for AI responses\n        providerId: legacyProviderId,      // Deprecated: use chatId instead\n        modelId: legacyModelId,           // Deprecated: use chatId instead\n        chatId,                           // Modern unified state management\n        model: providedModel,             // Direct model injection (testing)\n        onChunk,                          // Callback for streaming chunks\n        onThinkingChunk,                  // Callback for streaming thinking chunks\n        enableThinking = true,            // Enable thinking output updates\n        thinkingLevel,                    // Control reasoning effort when supported\n        onError,                          // Error handling callback\n        onComplete,                       // Completion callback\n        onFallback,                       // Provider fallback notification\n        enableFallback = true,            // Enable automatic fallback\n        enableRetry = true,               // Enable automatic retry\n        retryConfig = {},                 // Custom retry configuration\n    } = options;\n\n    // =============================================================================\n    // CHAT STATE MANAGEMENT\n    // =============================================================================\n    // \n    // Initialize chat state management. This handles both the new unified approach\n    // (using chatId) and legacy providerId/modelId for backward compatibility.\n    \n    const chatState = useChatState(chatId || null);\n    \n    // Resolve effective provider/model based on whether we're using unified state\n    // or legacy direct provider specification\n    const effectiveProviderId = chatId \n        ? chatState.provider                    // Use unified chat state\n        : (legacyProviderId || \"apple\");       // Fallback to legacy or default\n    const effectiveModelId = chatId \n        ? chatState.model                      // Use unified chat state  \n        : (legacyModelId || \"system-default\"); // Fallback to legacy or default\n\n    // =============================================================================\n    // CORE REACT STATE\n    // =============================================================================\n    // \n    // These are the fundamental React state variables that drive the chat interface.\n    // Each piece of state has a specific responsibility in the chat flow.\n    \n    const [text, setText] = useState<string>(initialText);           // Input field content\n    const [messages, setMessages] = useState<ModelMessage[]>(initialMessages); // Message history\n    const [thinkingOutput, setThinkingOutput] = useState<string[]>(\n        () => initialMessages.map(() => \"\")\n    );\n    const [isThinking, setIsThinking] = useState<boolean>(false);\n    const [isStreaming, setIsStreaming] = useState<boolean>(false);  // Streaming status\n    \n    // =============================================================================\n    // PROVIDER AND FALLBACK STATE\n    // =============================================================================\n    // \n    // These state variables manage the AI provider ecosystem, including fallback\n    // handling and provider switching during failures.\n    \n    const [activeProvider, setActiveProvider] = useState<ProviderId>(effectiveProviderId);\n    const [activeModel, setActiveModel] = useState<string>(effectiveModelId);\n    const [isUsingFallback, setIsUsingFallback] = useState<boolean>(false);\n    \n    // =============================================================================\n    // REFERENCES FOR STABLE OPERATIONS\n    // =============================================================================\n    // \n    // useRef values that persist across re-renders without triggering them.\n    // These are used for tracking operation state and maintaining data integrity.\n    \n    const failedProvidersRef = useRef<ProviderId[]>([]);     // Track failed providers for fallback\n    \n    // Retry and cancellation tracking\n    const lastUserMessageRef = useRef<string | null>(null); // Store last user message for retry\n    const [canRetry, setCanRetry] = useState<boolean>(false); // Whether retry is available\n    const [errorMessage, setErrorMessage] = useState<string | null>(null); // Error message for display\n    const canceledRef = useRef<boolean>(false);             // Track if streaming was canceled\n    const messagesRef = useRef<ModelMessage[]>(initialMessages);\n    const sendSequenceGuardRef = useRef(createSequenceGuard(`chat-send-${chatId ?? \"default\"}`));\n    const retryOperationRegistryRef = useRef(createIdempotencyRegistry<void>());\n    const lastRetryableOperationRef = useRef<RetryableOperation | null>(null);\n\n    useEffect(() => {\n        messagesRef.current = messages;\n    }, [messages]);\n\n    // =============================================================================\n    // CONFIGURATION MERGING\n    // =============================================================================\n    // \n    // Merge user-provided retry configuration with system defaults to create\n    // the final configuration used throughout the hook.\n    \n    const mergedRetryConfig: RetryConfig = { ...DEFAULT_RETRY_CONFIG, ...retryConfig };\n    const placeholderText = placeholder ? DEFAULT_PLACEHOLDER_TEXT : \"\";\n\n        // =============================================================================\n    // MODEL RESOLUTION AND CACHING\n    // =============================================================================\n    // \n    // Resolve the actual AI model to use for chat operations. This involves:\n    // 1. Using directly provided model (for testing/special cases)\n    // 2. Looking up cached model for performance\n    // 3. Creating new model instance if needed\n    // \n    // The useMemo ensures we only recompute when provider/model actually changes.\n    \n    const model: LanguageModel | null = useMemo(() => {\n        // Direct model injection takes precedence (useful for testing)\n        if (providedModel) {\n            return providedModel as LanguageModel;\n        }\n\n        // Try to get cached model for performance\n        const cachedModel = getCachedModel(\n            activeProvider,\n            activeModel,\n            () => getProviderModel(activeProvider, activeModel).model\n        );\n\n        return cachedModel || null;\n    }, [providedModel, activeProvider, activeModel]);\n\n    // =============================================================================\n    // TITLE GENERATION INTEGRATION\n    // =============================================================================\n    // \n    // Connect to the title generation subsystem. Titles are automatically\n    // generated based on conversation content and used for chat identification\n    // in the UI and database storage.\n    \n    const { title, setTitle, generateTitle } = useTitleGeneration(\n        messages.map(m => ({ role: m.role, content: typeof m.content === 'string' ? m.content : '' })),\n        model,\n        enableRetry,\n        mergedRetryConfig\n    );\n\n    // =============================================================================\n    // STREAMING INFRASTRUCTURE\n    // =============================================================================\n    // \n    // Connect to the streaming subsystem that handles real-time AI responses.\n    // This provides the core functionality for streaming text from AI providers.\n    \n    const { executeStreaming, handleStreamingError } = useChatStreaming();\n\n    // =============================================================================\n    // STREAM LIFECYCLE MANAGEMENT\n    // =============================================================================\n    // \n    // Manages stream state transitions, timeout detection, and cleanup.\n    // Ensures streams always complete fully and handles edge cases like\n    // app backgrounding and navigation away.\n    \n    const {\n        streamState,\n        isStreaming: isStreamLifecycleStreaming,\n        abortController,\n        initializeStream,\n        markChunkReceived,\n        markDoneSignalReceived,\n        markCompleting,\n        markCompleted,\n        markError,\n        cancelStream,\n    } = useStreamLifecycle({\n        timeoutMs: 30000, // 30 second fallback timeout\n        backgroundBehavior: \"cancel\",\n        enableLogging: __DEV__,\n        onError: (error) => {\n            console.error(\"[StreamLifecycle] Error:\", error.message);\n            onError?.(error);\n        },\n    });\n\n        // =============================================================================\n    // PROVIDER RESET EFFECT\n    // =============================================================================\n    // \n    // This effect ensures that when streaming completes (either successfully or\n    // with failure), we reset the provider state to the originally intended\n    // provider/model. This prevents fallback state from persisting between\n    // messages.\n    \n    useEffect(() => {\n        // Only reset when not actively streaming to avoid race conditions\n        if (!isStreaming) {\n            setActiveProvider(effectiveProviderId);\n            setActiveModel(effectiveModelId);\n            setIsUsingFallback(false);\n            failedProvidersRef.current = [];\n        }\n    }, [effectiveProviderId, effectiveModelId, isStreaming]);\n\n    // =============================================================================\n    // UTILITY FUNCTIONS\n    // =============================================================================\n    // \n    // Core utility functions that control chat state and flow. These are\n    // memoized with useCallback to maintain referential stability and prevent\n    // unnecessary re-renders in child components.\n\n    /**\n     * Reset all chat state to initial values\n     * \n     * This function completely clears the chat history, resets the input field,\n     * restores the original title, and resets all provider and fallback state.\n     * It's typically used when starting a new chat conversation.\n     */\n    const reset = useCallback(() => {\n        setText(\"\");                              // Clear input field\n        setMessages([]);                          // Clear message history\n        setThinkingOutput([]);                    // Clear reasoning output\n        setIsThinking(false);                     // Clear thinking state\n        setTitle(\"Chat\");                         // Reset to default title\n        setActiveProvider(effectiveProviderId);   // Reset to intended provider\n        setActiveModel(effectiveModelId);        // Reset to intended model\n        setIsUsingFallback(false);                // Clear fallback state\n        failedProvidersRef.current = [];         // Clear failed providers list\n        lastUserMessageRef.current = null;       // Clear retry message\n        setCanRetry(false);                      // Disable retry capability\n        setErrorMessage(null);                   // Clear error message\n        lastRetryableOperationRef.current = null;\n        retryOperationRegistryRef.current.clear();\n    }, [effectiveProviderId, effectiveModelId, setTitle]);\n\n    /**\n     * Cancel the current streaming operation\n     *\n     * Sets a flag that the streaming loop checks to determine if it should\n     * stop processing chunks. This provides a clean way to interrupt AI responses.\n     */\n    const cancel = useCallback(() => {\n        canceledRef.current = true;\n        sendSequenceGuardRef.current.next();\n        setIsStreaming(false);\n        setIsThinking(false);\n        cancelStream(); // Use stream lifecycle cancel for comprehensive cancellation\n    }, [cancelStream]);\n\n        // =============================================================================\n    // CORE MESSAGE SENDING LOGIC\n    // =============================================================================\n    // \n    // This is the heart of the chat functionality. The sendMessage function:\n    // 1. Validates and prepares the user message\n    // 2. Updates the message history\n    // 3. Initiates streaming with the AI provider\n    // 4. Handles fallback and retry logic\n    // 5. Manages the complete message flow lifecycle\n\n    /**\n     * Send a message to the AI and initiate streaming response\n     * \n     * @param overrideText - Optional text to send instead of current input\n     * \n     * This function orchestrates the complete message sending flow:\n     * 1. Input validation and preprocessing\n     * 2. Message history updates\n     * 3. AI provider streaming initiation\n     * 4. Error handling with fallback mechanisms\n     * 5. Completion callbacks\n     */\n    const sendMessage = useCallback(\n        async (overrideText?: string) => {\n            // ────────────────────────────────────────────────────────────────\n            // INPUT VALIDATION AND PREPARATION\n            // ────────────────────────────────────────────────────────────────\n            const rawValue: unknown = overrideText ?? (text as unknown);\n            const content = typeof rawValue === \"string\" ? rawValue.trim() : \"\";\n            \n            // Exit early if no valid content to send\n            if (!content) return;\n\n            const sendToken = sendSequenceGuardRef.current.next();\n            const sendOperationKey = createIdempotencyKey(\"chat-send\", [\n                chatId ?? \"default\",\n                sendToken.sequence,\n                content,\n            ]);\n\n            // ────────────────────────────────────────────────────────────────\n            // STATE INITIALIZATION\n            // ────────────────────────────────────────────────────────────────\n            setIsStreaming(true);                    // Start streaming state\n            setIsThinking(false);                    // Reset thinking state\n            canceledRef.current = false;            // Clear cancellation flag\n            setCanRetry(false);                     // Disable retry until needed\n            lastRetryableOperationRef.current = null;\n            lastUserMessageRef.current = content;   // Store for retry capability\n            \n            // Initialize stream lifecycle management\n            const streamController = initializeStream();\n            const abortSignal = streamController.signal;\n            const canMutateForCurrentSend = (): boolean => (\n                sendSequenceGuardRef.current.isCurrent(sendToken)\n                && !canceledRef.current\n                && !abortSignal.aborted\n            );\n\n            // ────────────────────────────────────────────────────────────────\n            // MESSAGE HISTORY MANAGEMENT\n            // ────────────────────────────────────────────────────────────────\n            const userMessage: ModelMessage = { role: \"user\", content };\n            const updatedMessages = [...messagesRef.current, userMessage];\n            setMessages(updatedMessages);\n            setThinkingOutput((prev) => [...prev, \"\"]);\n\n            // Clear input field if we're using the current text (not override)\n            if (overrideText === undefined) {\n                setText(\"\");\n            }\n\n            // Add placeholder for assistant response\n            const assistantIndex = updatedMessages.length;\n            setMessages((prev) => [\n                ...prev,\n                {\n                    role: \"assistant\",\n                    content: placeholderText,\n                },\n            ]);\n            setThinkingOutput((prev) => [...prev, \"\"]);\n\n            // ────────────────────────────────────────────────────────────────\n            // MODEL VALIDATION\n            // ────────────────────────────────────────────────────────────────\n            if (!model) {\n                // Show helpful error message when no provider is configured\n                setMessages((prev) => {\n                    const next = [...prev];\n                    next[assistantIndex] = {\n                        role: \"assistant\",\n                        content: \"**Setup Required**\\n\\nNo AI provider configured. Please set up a provider in settings.\\n\\n*Go to Settings to configure an AI provider.*\",\n                    };\n                    return next;\n                });\n                \n                onError?.(new Error(\"No AI provider configured\"));\n                setIsStreaming(false);\n                setIsThinking(false);\n                onComplete?.();\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // STREAMING CONFIGURATION\n            // ────────────────────────────────────────────────────────────────\n            const handleThinkingChunk = enableThinking\n                ? (chunk: string, accumulated: string) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    setIsThinking(true);\n                    setThinkingOutput((prev) => {\n                        const next = [...prev];\n                        next[assistantIndex] = accumulated;\n                        return next;\n                    });\n                    onThinkingChunk?.(chunk, accumulated);\n                }\n                : undefined;\n\n            const streamingOptions = {\n                model: {\n                    model,\n                    provider: activeProvider,\n                    modelId: activeModel,\n                    isOriginal: !isUsingFallback,\n                    attemptedProviders: failedProvidersRef.current,\n                } as FallbackResult,\n                enableRetry,\n                retryConfig: mergedRetryConfig,\n                enableFallback,\n                activeProvider,\n                effectiveProviderId,\n                thinkingLevel,\n                abortSignal,\n                onChunk,\n                onThinkingChunk: handleThinkingChunk,\n                canMutateState: canMutateForCurrentSend,\n                onError: (error: unknown) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    if (error instanceof Error) {\n                        markError(error);\n                        setErrorMessage(error.message);\n                        setCanRetry(true);\n                        lastRetryableOperationRef.current = {\n                            operationKey: sendOperationKey,\n                            content,\n                        };\n                        onError?.(error);\n                    } else {\n                        const wrappedError = new Error(String(error));\n                        markError(wrappedError);\n                        setErrorMessage(wrappedError.message);\n                        setCanRetry(true);\n                        lastRetryableOperationRef.current = {\n                            operationKey: sendOperationKey,\n                            content,\n                        };\n                        onError?.(wrappedError);\n                    }\n                },\n                onFallback,\n                onProviderChange: (provider: ProviderId, model: string, isFallback: boolean) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    setActiveProvider(provider);\n                    setActiveModel(model);\n                    setIsUsingFallback(isFallback);\n                },\n            };\n\n            // ────────────────────────────────────────────────────────────────\n            // STREAMING EXECUTION\n            // ────────────────────────────────────────────────────────────────\n            const result = await executeStreaming(\n                streamingOptions,\n                updatedMessages,\n                setMessages,\n                assistantIndex,\n                failedProvidersRef\n            );\n\n            if (!sendSequenceGuardRef.current.isCurrent(sendToken)) {\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // FALLBACK RETRY LOGIC\n            // ────────────────────────────────────────────────────────────────\n            if (result.shouldRetryWithFallback && !canceledRef.current) {\n                setIsStreaming(false);\n                setIsThinking(false);\n                // Small delay to ensure clean state transition\n                await new Promise(resolve => setTimeout(resolve, 100));\n                await sendMessage(content);\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // COMPLETION\n            // ────────────────────────────────────────────────────────────────\n            if (canMutateForCurrentSend()) {\n                setIsStreaming(false);\n                setIsThinking(false);\n                onComplete?.();\n            }\n        },\n        [\n            text, \n            placeholderText, \n            model, \n            activeProvider, \n            activeModel, \n            isUsingFallback,\n            enableRetry, \n            mergedRetryConfig,\n            executeStreaming,\n            onChunk, \n            onThinkingChunk,\n            onComplete, \n            onError, \n            onFallback,\n            chatId,\n            enableFallback,\n            effectiveProviderId,\n            initializeStream,\n            markError,\n            enableThinking,\n            thinkingLevel,\n            onThinkingChunk\n        ],\n    );\n\n        // =============================================================================\n    // RETRY FUNCTIONALITY\n    // =============================================================================\n    // \n    // Retry functionality allows users to resend their last message when the\n    // AI response failed or was incomplete. This involves:\n    // 1. Removing the failed assistant response\n    // 2. Optionally removing the user message (if they want to edit)\n    // 3. Resending the original message with fresh state\n\n    /**\n     * Retry the last failed message\n     * \n     * This function enables users to retry their last message when the AI\n     * response failed or was cut off. It cleans up the conversation history\n     * and resends the original message with fresh streaming state.\n     */\n    const retryLastMessage = useCallback(async () => {\n        const retryableOperation = lastRetryableOperationRef.current;\n\n        // Guard against invalid retry attempts\n        if (!lastUserMessageRef.current || !canRetry || !retryableOperation) return;\n\n        const retryOperationKey = createIdempotencyKey(\"chat-retry\", [\n            retryableOperation.operationKey,\n            retryableOperation.content,\n        ]);\n\n        await retryOperationRegistryRef.current.run(retryOperationKey, async () => {\n            const currentMessages = messagesRef.current;\n            let nextMessages = [...currentMessages];\n            let removedCount = 0;\n\n            if (nextMessages.length > 0 && nextMessages[nextMessages.length - 1].role === \"assistant\") {\n                nextMessages = nextMessages.slice(0, -1);\n                removedCount += 1;\n            }\n\n            const lastMessage = nextMessages[nextMessages.length - 1];\n            if (\n                lastMessage\n                && lastMessage.role === \"user\"\n                && typeof lastMessage.content === \"string\"\n                && lastMessage.content === retryableOperation.content\n            ) {\n                nextMessages = nextMessages.slice(0, -1);\n                removedCount += 1;\n            }\n\n            messagesRef.current = nextMessages;\n            setMessages(nextMessages);\n            setThinkingOutput((prev) => prev.slice(0, Math.max(0, prev.length - removedCount)));\n\n            // Reset retry state and clear error message\n            setCanRetry(false);\n            setErrorMessage(null);\n            lastRetryableOperationRef.current = null;\n\n            await sendMessage(retryableOperation.content);\n        });\n    }, [canRetry, sendMessage]);\n\n    // =============================================================================\n    // PUBLIC INTERFACE\n    // =============================================================================\n    // \n    // Return the complete chat interface. All values are stable references\n    // where appropriate to prevent unnecessary re-renders in consuming components.\n    // The interface provides both state accessors and action functions.\n\n    return {\n        // ────────────────────────────────────────────────────────────────\n        // CORE CHAT STATE\n        // ────────────────────────────────────────────────────────────────\n        text,                           // Current input text\n        setText,                        // Update input text\n        messages,                       // Message history\n        setMessages,                    // Update message history\n        thinkingOutput,                 // Reasoning output\n        setThinkingOutput,              // Update reasoning output\n        isThinking,                     // Thinking status\n        isStreaming,                    // Streaming status\n        streamState,                    // Stream lifecycle state (streaming | completing | completed | error)\n\n        // ────────────────────────────────────────────────────────────────\n        // ACTIONS\n        // ────────────────────────────────────────────────────────────────\n        sendMessage,                    // Send message\n        cancel,                         // Cancel streaming\n        reset,                          // Reset all state\n\n        // ────────────────────────────────────────────────────────────────\n        // TITLE MANAGEMENT\n        // ────────────────────────────────────────────────────────────────\n        title,                          // Current title\n        setTitle,                       // Update title\n        generateTitle,                  // Generate new title\n\n        // ────────────────────────────────────────────────────────────────\n        // PROVIDER STATE\n        // ────────────────────────────────────────────────────────────────\n        currentProvider: activeProvider, // Active AI provider\n        currentModel: activeModel,      // Active model\n        isUsingFallback,                // Fallback status\n\n        // ────────────────────────────────────────────────────────────────\n        // RETRY FUNCTIONALITY\n        // ────────────────────────────────────────────────────────────────\n        retryLastMessage,               // Retry last message\n        canRetry,                       // Whether retry is available\n        errorMessage,                   // Error message for display\n    };\n}\n\n/*\n * =============================================================================\n * HOOK COMPREHENSIVE DOCUMENTATION\n * =============================================================================\n * \n * ARCHITECTURAL SUMMARY:\n * ────────────────────────────────────────────────────────────────────────\n * useChat is a sophisticated hook that combines multiple concerns into a\n * cohesive chat interface. It follows the composition pattern, building upon\n * specialized hooks for different aspects of chat functionality.\n * \n * KEY PRINCIPLES:\n * ────────────────────────────────────────────────────────────────────────\n * 1. Separation of Concerns: Different aspects (streaming, title generation,\n *    state management) are handled by dedicated hooks\n * 2. Referential Stability: useCallback and useMemo prevent unnecessary re-renders\n * 3. Unidirectional Data Flow: State flows down, actions flow up\n * 4. Error Resilience: Multiple layers of error handling and fallback\n * 5. Performance Optimization: Caching, memoization, and efficient updates\n * \n * PROVIDER ECOSYSTEM INTEGRATION:\n * ────────────────────────────────────────────────────────────────────────\n * The hook integrates with a robust provider system that supports:\n * • Multiple AI providers (Apple, OpenAI, OpenRouter, Ollama)\n * • Automatic fallback on failures\n * • Model caching for performance\n * • Per-chat provider overrides\n * • Retry with exponential backoff\n * \n * STATE MANAGEMENT STRATEGY:\n * ────────────────────────────────────────────────────────────────────────\n * • Local React state for immediate UI updates\n * • Zustand stores for persistent data\n * • Refs for operation tracking without re-renders\n * • Unified chat state system for consistency\n * \n * ERROR HANDLING APPROACH:\n * ────────────────────────────────────────────────────────────────────────\n * • Graceful degradation when providers fail\n * • User-friendly error messages\n * • Automatic retry with configurable backoff\n * • Fallback chain through multiple providers\n * • Recovery mechanisms for common failure scenarios\n * \n * PERFORMANCE OPTIMIZATIONS:\n * ────────────────────────────────────────────────────────────────────────\n * • Model caching to avoid repeated initialization\n * • Memoized callbacks to prevent child re-renders\n * • Efficient state updates with minimal re-renders\n * • Lazy loading of provider resources\n * • Streaming to provide immediate feedback\n * \n * =============================================================================\n */\n","additions":4,"deletions":0}],"diagnostics":{"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts":[{"range":{"start":{"line":46,"character":9},"end":{"line":46,"character":25}},"message":"'executeWithRetry' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":58,"character":5},"end":{"line":58,"character":17}},"message":"'ChunkHandler' is declared but never used.","severity":4,"code":6196,"source":"typescript"},{"range":{"start":{"line":152,"character":8},"end":{"line":152,"character":18}},"message":"'providerId' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/chat.types.ts","range":{"start":{"line":20,"character":6},"end":{"line":20,"character":66}}},"message":"The declaration was marked as deprecated here."}]},{"range":{"start":{"line":153,"character":8},"end":{"line":153,"character":15}},"message":"'modelId' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/chat.types.ts","range":{"start":{"line":22,"character":6},"end":{"line":22,"character":66}}},"message":"The declaration was marked as deprecated here."}]},{"range":{"start":{"line":294,"character":30},"end":{"line":294,"character":50}},"message":"'handleStreamingError' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":306,"character":21},"end":{"line":306,"character":47}},"message":"'isStreamLifecycleStreaming' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":307,"character":8},"end":{"line":307,"character":23}},"message":"'abortController' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":309,"character":8},"end":{"line":309,"character":25}},"message":"'markChunkReceived' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":310,"character":8},"end":{"line":310,"character":30}},"message":"'markDoneSignalReceived' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":311,"character":8},"end":{"line":311,"character":22}},"message":"'markCompleting' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":312,"character":8},"end":{"line":312,"character":21}},"message":"'markCompleted' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"}],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/concurrency.types.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/lib/concurrency.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChatStreaming.ts":[{"range":{"start":{"line":104,"character":26},"end":{"line":104,"character":39}},"message":"'LanguageModel' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":109,"character":9},"end":{"line":109,"character":29}},"message":"'getModelWithFallback' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":109,"character":71},"end":{"line":109,"character":91}},"message":"'hasFallbackAvailable' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":111,"character":51},"end":{"line":111,"character":66}},"message":"'shouldShowRetry' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":246,"character":34},"end":{"line":246,"character":50}},"message":"'MutableRefObject' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/%40types/react/index.d.ts","range":{"start":{"line":1658,"character":7},"end":{"line":1659,"character":5}}},"message":"The declaration was marked as deprecated here."}]}]},"truncated":false},"time":{"start":1770429117639,"end":1770429120671}},"metadata":{"openai":{"itemId":"fc_06d2025cf3c9a86f0169869abcaeb08195b8702588fcd3281e"}}}}
{"type":"step_finish","timestamp":1770429120724,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc80a2001C5v4K262d7ZcIC","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc68fb001OjmMrpkTfrKQY9","type":"step-finish","reason":"tool-calls","snapshot":"08123000fdc64b81aa3154100ded6b23ff505e28","cost":0,"tokens":{"input":2865,"output":126,"reasoning":20,"cache":{"read":59904,"write":0}}}}
{"type":"step_start","timestamp":1770429122179,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc8683001jOzpZEaZyiCQyR","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc8112001E27dUSk5sXDRVQ","type":"step-start","snapshot":"08123000fdc64b81aa3154100ded6b23ff505e28"}}
{"type":"tool_use","timestamp":1770429129423,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc9779001sDMxVPe73Ioqyg","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc8112001E27dUSk5sXDRVQ","type":"tool","callID":"call_eq6c8cwUoQL5f5NqMQB7n36l","tool":"bash","state":{"status":"completed","input":{"command":"npx eslint hooks/chat/useChat.ts hooks/chat/__tests__/useChat.test.ts","workdir":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2","description":"Re-lint changed files after dependency fix"},"output":"\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n  332:38  warning  A `require()` style import is forbidden  @typescript-eslint/no-require-imports\n  344:38  warning  A `require()` style import is forbidden  @typescript-eslint/no-require-imports\n\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n   47:10  warning  'executeWithRetry' is defined but never used                                                                         @typescript-eslint/no-unused-vars\n   59:6   warning  'ChunkHandler' is defined but never used                                                                             @typescript-eslint/no-unused-vars\n  295:31  warning  'handleStreamingError' is assigned a value but never used                                                            @typescript-eslint/no-unused-vars\n  307:22  warning  'isStreamLifecycleStreaming' is assigned a value but never used                                                      @typescript-eslint/no-unused-vars\n  308:9   warning  'abortController' is assigned a value but never used                                                                 @typescript-eslint/no-unused-vars\n  310:9   warning  'markChunkReceived' is assigned a value but never used                                                               @typescript-eslint/no-unused-vars\n  311:9   warning  'markDoneSignalReceived' is assigned a value but never used                                                          @typescript-eslint/no-unused-vars\n  312:9   warning  'markCompleting' is assigned a value but never used                                                                  @typescript-eslint/no-unused-vars\n  313:9   warning  'markCompleted' is assigned a value but never used                                                                   @typescript-eslint/no-unused-vars\n  607:9   warning  React Hook useCallback has a duplicate dependency: 'onThinkingChunk'. Either omit it or remove the dependency array  react-hooks/exhaustive-deps\n\n✖ 12 problems (0 errors, 12 warnings)\n\n","title":"Re-lint changed files after dependency fix","metadata":{"output":"\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n  332:38  warning  A `require()` style import is forbidden  @typescript-eslint/no-require-imports\n  344:38  warning  A `require()` style import is forbidden  @typescript-eslint/no-require-imports\n\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n   47:10  warning  'executeWithRetry' is defined but never used                                                                         @typescript-eslint/no-unused-vars\n   59:6   warning  'ChunkHandler' is defined but never used                                                                             @typescript-eslint/no-unused-vars\n  295:31  warning  'handleStreamingError' is assigned a value but never used                                                            @typescript-eslint/no-unused-vars\n  307:22  warning  'isStreamLifecycleStreaming' is assigned a value but never used                                                      @typescript-eslint/no-unused-vars\n  308:9   warning  'abortController' is assigned a value but never used                                                                 @typescript-eslint/no-unused-vars\n  310:9   warning  'markChunkReceived' is assigned a value but never used                                                               @typescript-eslint/no-unused-vars\n  311:9   warning  'markDoneSignalReceived' is assigned a value but never used                                                          @typescript-eslint/no-unused-vars\n  312:9   warning  'markCompleting' is assigned a value but never used                                                                  @typescript-eslint/no-unused-vars\n  313:9   warning  'markCompleted' is assigned a value but never used                                                                   @typescript-eslint/no-unused-vars\n  607:9   warning  React Hook useCallback has a duplicate dependency: 'onThinkingChunk'. Either omit it or remove the dependency array  react-hooks/exhaustive-deps\n\n✖ 12 problems (0 errors, 12 warnings)\n\n","exit":0,"description":"Re-lint changed files after dependency fix","truncated":false},"time":{"start":1770429126523,"end":1770429129422}},"metadata":{"openai":{"itemId":"fc_096952091cc5ef770169869ac664008197b18e9a1fb598c2a9"}}}}
{"type":"tool_use","timestamp":1770429131006,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cc977d001pIoYg5yqAw4UPo","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc8112001E27dUSk5sXDRVQ","type":"tool","callID":"call_urVU0AE2zeZbtwdQRU3oELJl","tool":"bash","state":{"status":"completed","input":{"command":"npx jest hooks/chat/__tests__/useChat.test.ts","workdir":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2","description":"Re-run retry-focused useChat tests"},"output":"  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { previousState: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'new-stream-initialization' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { previousState: 'streaming' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'network flap',\n      stack: 'Error: network flap\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:459:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:465:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:478:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:477:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'temporary outage',\n      stack: 'Error: temporary outage\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:517:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:523:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:536:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:535:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'network flap - initial',\n      stack: 'Error: network flap - initial\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:572:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:578:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:598:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:597:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\nPASS hooks/chat/__tests__/useChat.test.ts\n  useChat\n    basic functionality\n      ✓ should initialize with default values (19 ms)\n      ✓ should initialize with provided initial text (1 ms)\n      ✓ should update text when setText is called (2 ms)\n      ✓ should not send empty message (2 ms)\n      ✓ should not send whitespace-only message (1 ms)\n    message sending\n      ✓ should send message and add to history (26 ms)\n      ✓ should set isThinking while reasoning streams (7 ms)\n      ✓ should ignore thinking output when disabled (7 ms)\n      ✓ should skip placeholder text when disabled (6 ms)\n      ✓ should handle message with override text (5 ms)\n      ✓ should pass thinking level to streaming options (5 ms)\n    state management\n      ✓ should reset all state to initial values (3 ms)\n      ✓ should not throw when cancel is called (4 ms)\n    provider configuration\n      ✓ should use legacy provider when no chatId provided (1 ms)\n      ✓ should use chat state when chatId is provided (1 ms)\n    title functionality\n      ✓ should update title when setTitle is called (1 ms)\n      ✓ should generate title when generateTitle is called (1 ms)\n    edge cases\n      ✓ should handle non-string input gracefully\n      ✓ keeps completion ordering stable under rapid sends (12 ms)\n      ✓ prevents post-cancel error mutation from stale stream callbacks (8 ms)\n      ✓ deduplicates quick retry taps for the same failed operation (36 ms)\n      ✓ keeps retry state stable when retry is tapped while a retry is inflight (12 ms)\n      ✓ recovers from repeated network flap retries without duplicating chat entries (19 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       23 passed, 23 total\nSnapshots:   0 total\nTime:        1.248 s\nRan all test suites matching /hooks\\/chat\\/__tests__\\/useChat.test.ts/i.\n","title":"Re-run retry-focused useChat tests","metadata":{"output":"  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { previousState: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'new-stream-initialization' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cancelled { previousState: 'streaming' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'network flap',\n      stack: 'Error: network flap\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:459:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:465:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:478:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:477:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'temporary outage',\n      stack: 'Error: temporary outage\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:517:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:523:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:536:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:535:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] streaming { from: 'idle' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      from: 'streaming',\n      error: 'network flap - initial',\n      stack: 'Error: network flap - initial\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:572:28\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:578:8)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:397:39\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:404:13\\n' +\n        '    at mockConstructor (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-mock/build/index.js:148:19)\\n' +\n        '    at apply (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:51:63)\\n' +\n        '    at Object.executeStreaming (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:574:34)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Object.apply [as sendMessage] (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts:606:10)\\n' +\n        '    at sendMessage (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:598:30)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12\\n' +\n        '    at callback (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:31:24)\\n' +\n        '    at Object.<anonymous>.process.env.NODE_ENV.exports.act (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/react/cjs/react.development.js:789:22)\\n' +\n        '    at actImplementation (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@testing-library/react-native/src/act.ts:30:25)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts:597:16)\\n' +\n        '    at Generator.next (<anonymous>)\\n' +\n        '    at asyncGeneratorStep (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:3:17)\\n' +\n        '    at _next (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:17:9)\\n' +\n        '    at /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:22:7\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at Object.<anonymous> (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/@babel/runtime/helpers/asyncToGenerator.js:14:12)\\n' +\n        '    at Promise.then.completed (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:298:28)\\n' +\n        '    at new Promise (<anonymous>)\\n' +\n        '    at callAsyncCircusFn (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/utils.js:231:10)\\n' +\n        '    at _callCircusTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:316:40)\\n' +\n        '    at _runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:252:3)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:126:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at _runTestsForDescribeBlock (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:121:9)\\n' +\n        '    at run (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/run.js:71:3)\\n' +\n        '    at runAndTransformResultsToJestFormat (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapterInit.js:122:21)\\n' +\n        '    at jestAdapter (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-circus/build/legacy-code-todo-rewrite/jestAdapter.js:79:19)\\n' +\n        '    at runTestInternal (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:367:16)\\n' +\n        '    at runTest (/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/jest-runner/build/runTest.js:444:34)'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] initialized\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] timeout-started { timeoutMs: 30000 }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] error {\n      message: 'Invalid state transition attempted',\n      from: 'error',\n      to: 'streaming'\n    }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\n  console.log\n    [StreamLifecycle] cleanup { reason: 'component-unmount' }\n\n      at log (hooks/chat/useStreamLifecycle.ts:166:11)\n\nPASS hooks/chat/__tests__/useChat.test.ts\n  useChat\n    basic functionality\n      ✓ should initialize with default values (19 ms)\n      ✓ should initialize with provided initial text (1 ms)\n      ✓ should update text when setText is called (2 ms)\n      ✓ should not send empty message (2 ms)\n      ✓ should not send whitespace-only message (1 ms)\n    message sending\n      ✓ should send message and add to history (26 ms)\n      ✓ should set isThinking while reasoning streams (7 ms)\n      ✓ should ignore thinking output when disabled (7 ms)\n      ✓ should skip placeholder text when disabled (6 ms)\n      ✓ should handle message with override text (5 ms)\n      ✓ should pass thinking level to streaming options (5 ms)\n    state management\n      ✓ should reset all state to initial values (3 ms)\n      ✓ should not throw when cancel is called (4 ms)\n    provider configuration\n      ✓ should use legacy provider when no chatId provided (1 ms)\n      ✓ should use chat state when chatId is provided (1 ms)\n    title functionality\n      ✓ should update title when setTitle is called (1 ms)\n      ✓ should generate title when generateTitle is called (1 ms)\n    edge cases\n      ✓ should handle non-string input gracefully\n      ✓ keeps completion ordering stable under rapid sends (12 ms)\n      ✓ prevents post-cancel error mutation from stale stream callbacks (8 ms)\n      ✓ deduplicates quick retry taps for the same failed operation (36 ms)\n      ✓ keeps retry state stable when retry is tapped while a retry is inflight (12 ms)\n      ✓ recovers from repeated network flap retries without duplicating chat entries (19 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       23 passed, 23 total\nSnapshots:   0 total\nTime:        1.248 s\nRan all test suites matching /hooks\\/chat\\/__tests__\\/useChat.test.ts/i.\n","exit":0,"description":"Re-run retry-focused useChat tests","truncated":false},"time":{"start":1770429126529,"end":1770429131003}},"metadata":{"openai":{"itemId":"fc_096952091cc5ef770169869ac6641881978781d2faf1efe2f1"}}}}
{"type":"step_finish","timestamp":1770429131054,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cca8fd0014YHxNnsLeIZp7t","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cc8112001E27dUSk5sXDRVQ","type":"step-finish","reason":"tool-calls","snapshot":"08123000fdc64b81aa3154100ded6b23ff505e28","cost":0,"tokens":{"input":2021,"output":209,"reasoning":71,"cache":{"read":60928,"write":0}}}}
{"type":"step_start","timestamp":1770429131838,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35ccac3d001WhW8YjZf3T2sT7","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cca96f0011HVtiNoPqPMbpg","type":"step-start","snapshot":"08123000fdc64b81aa3154100ded6b23ff505e28"}}
{"type":"tool_use","timestamp":1770429141211,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35ccd053001ES4OA8ZTGfFaD1","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cca96f0011HVtiNoPqPMbpg","type":"tool","callID":"call_XcH7UplIQHsYKEcaDAKc890n","tool":"bash","state":{"status":"completed","input":{"command":"git status --short","workdir":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2","description":"List modified files in workspace"},"output":" M .ralph-tui/progress.md\n M .ralph-tui/session-meta.json\n M .ralph-tui/session.json\n M hooks/chat/__tests__/useChat.test.ts\n M hooks/chat/useChat.ts\n M tasks/prd.json\n?? .ralph-tui/iterations/b6187319_2026-02-06_20-36-01_US-003.log\n","title":"List modified files in workspace","metadata":{"output":" M .ralph-tui/progress.md\n M .ralph-tui/session-meta.json\n M .ralph-tui/session.json\n M hooks/chat/__tests__/useChat.test.ts\n M hooks/chat/useChat.ts\n M tasks/prd.json\n?? .ralph-tui/iterations/b6187319_2026-02-06_20-36-01_US-003.log\n","exit":0,"description":"List modified files in workspace","truncated":false},"time":{"start":1770429141078,"end":1770429141210}},"metadata":{"openai":{"itemId":"fc_08771b42ed1595940169869ad4ee7481968cd3bd0944dc2c47"}}}}
{"type":"tool_use","timestamp":1770429141219,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35ccd05a001OYYH5FKMlBPRmX","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cca96f0011HVtiNoPqPMbpg","type":"tool","callID":"call_fxh9kf6WRVSQBhcnKRG4hJu0","tool":"distill","state":{"status":"completed","input":{"targets":[{"id":"28","distillation":"`npx tsc --noEmit` fails with many pre-existing repository errors unrelated to US-004 changes. Representative failures include:\n- `app/index.tsx:99` (`Property 'chat' does not exist on type '{}'`).\n- Multiple test typing issues in `hooks/__tests__/useErrorRecovery.test.ts` (mock type mismatches, `'never'` argument errors, unassigned variable), `hooks/__tests__/useChatState.test.ts`, and `providers/__tests__/ollama-provider.test.ts`.\n- Error set indicates repo-wide TypeScript baseline is currently red before/independent of retry-idempotency work."},{"id":"29","distillation":"`npm test -- --watch=false` fails repo-wide due pre-existing unrelated test failures. Key failing suites include:\n- `hooks/__tests__/useDatabase.test.ts`: expects db name `seabreeze`, receives `seabreeze-v2`.\n- `components/ui/__tests__/ThemeProvider.test.tsx`: cannot find expected test IDs due rendered fallback/loading state.\n- `app/settings/__tests__/ollama.test.tsx`: missing expected test IDs (`setting-input-*`, `save-button-*`, `model-list-manager`).\n- `components/chat/__tests__/ChatListItem.test.tsx`: runtime error in gesture handler (`Cannot read properties of undefined (reading 'Tap')`).\nThese failures are outside the US-004 files and indicate existing test-suite instability."},{"id":"37","distillation":"`npx jest hooks/chat/__tests__/useChat.test.ts` passes after US-004 changes:\n- Test suite status: PASS.\n- 1 suite passed, 23 tests passed.\n- New US-004 scenarios pass:\n  - deduplicates quick retry taps for same failed op,\n  - stable retry while previous retry inflight,\n  - repeated network-flap retries recover without duplicate entries.\n- Console logs from stream lifecycle appear but do not fail tests."}]},"output":"Context pruning complete. Pruned 3 tool outputs.\n\nSemantically pruned (3):\n→ bash: Run TypeScript noEmit check\n→ bash: Run full test suite\n→ bash: Re-run retry-focused useChat tests","title":"","metadata":{"truncated":false},"time":{"start":1770429141083,"end":1770429141218}},"metadata":{"openai":{"itemId":"fc_08771b42ed1595940169869ad4ee8481968019dba516a1a490"}}}}
{"type":"step_finish","timestamp":1770429141261,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35ccd0e3001PSw5cEUBdJGUyg","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cca96f0011HVtiNoPqPMbpg","type":"step-finish","reason":"tool-calls","snapshot":"08123000fdc64b81aa3154100ded6b23ff505e28","cost":0,"tokens":{"input":11590,"output":618,"reasoning":117,"cache":{"read":59904,"write":0}}}}
{"type":"step_start","timestamp":1770429141868,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35ccd36b001ruq59X5lixrh5A","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35ccd14c0016DmF3OceIXQ1YI","type":"step-start","snapshot":"08123000fdc64b81aa3154100ded6b23ff505e28"}}
{"type":"tool_use","timestamp":1770429148003,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35ccdb85001U33KvMqsW80GGY","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35ccd14c0016DmF3OceIXQ1YI","type":"tool","callID":"call_X59TqISTNSMcIZW1WG9D8fzP","tool":"apply_patch","state":{"status":"completed","input":{"patchText":"*** Begin Patch\n*** Update File: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n@@\n             executeStreaming,\n             onChunk, \n-            onThinkingChunk,\n             onComplete, \n             onError, \n             onFallback,\n*** End Patch"},"output":"Success. Updated the following files:\nM hooks/chat/useChat.ts","title":"Success. Updated the following files:\nM hooks/chat/useChat.ts","metadata":{"diff":"Index: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n===================================================================\n--- /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n+++ /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n@@ -614,9 +614,8 @@\n enableRetry, \n mergedRetryConfig,\n executeStreaming,\n onChunk, \n-onThinkingChunk,\n onComplete, \n onError, \n onFallback,\n chatId,\n\n","files":[{"filePath":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts","relativePath":"hooks/chat/useChat.ts","type":"update","diff":"Index: /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n===================================================================\n--- /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n+++ /Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n@@ -614,9 +614,8 @@\n enableRetry, \n mergedRetryConfig,\n executeStreaming,\n onChunk, \n-onThinkingChunk,\n onComplete, \n onError, \n onFallback,\n chatId,\n","before":"/**\n * @file useChat.ts\n * @purpose Main chat orchestrator with comprehensive state management\n * @connects-to useChatStreaming, useTitleGeneration, useChatState\n * \n * =============================================================================\n * COMPREHENSIVE HOOK OVERVIEW\n * =============================================================================\n * \n * useChat is the central hook that manages all chat functionality in the seabreeze\n * application. It orchestrates message handling, streaming responses, provider\n * management, fallback mechanisms, title generation, and error recovery.\n * \n * KEY RESPONSIBILITIES:\n * ────────────────────────────────────────────────────────────────────────\n * • Message state management (input text, message history)\n * • Streaming response handling with real-time updates\n * • AI provider and model management with fallback support\n * • Error handling with automatic retry mechanisms\n * • Chat title generation based on conversation content\n * • Persistent chat state across app sessions\n * \n * ARCHITECTURAL PATTERNS:\n * ────────────────────────────────────────────────────────────────────────\n * • Composition over inheritance - combines specialized hooks\n * • Unidirectional data flow - state flows down, actions flow up\n * • Immutable state updates - ensures React re-renders correctly\n * • Referential stability - uses useCallback/useMemo for performance\n * \n * PROVIDER ECOSYSTEM:\n * ────────────────────────────────────────────────────────────────────────\n * Supports Apple Intelligence, OpenAI, OpenRouter, and Ollama providers with:\n * • Automatic fallback on failures\n * • Model caching for performance\n * • Per-chat provider overrides\n * • Retry with exponential backoff\n * \n * =============================================================================\n */\n\nimport { useCallback, useState, useRef, useEffect, useMemo } from \"react\";\nimport type { LanguageModel, ModelMessage } from \"ai\";\nimport { ProviderId } from \"@/types/provider.types\";\nimport { getProviderModel } from \"@/providers/provider-factory\";\nimport { getCachedModel } from \"@/providers/provider-cache\";\nimport { type FallbackResult } from \"@/providers/fallback-chain\";\nimport { executeWithRetry, DEFAULT_RETRY_CONFIG, type RetryConfig } from \"@/hooks/useErrorRecovery\";\nimport { useChatState } from \"@/hooks/useChatState\";\nimport { useTitleGeneration } from \"./useTitleGeneration\";\nimport { useChatStreaming } from \"./useChatStreaming\";\nimport { useStreamLifecycle } from \"./useStreamLifecycle\";\nimport type { UseChatOptions, StreamState } from \"@/types/chat.types\";\nimport {\n    createIdempotencyKey,\n    createIdempotencyRegistry,\n    createSequenceGuard,\n} from \"@/lib/concurrency\";\n\ntype ChunkHandler = (chunk: string, accumulated: string) => void;\n\ninterface RetryableOperation {\n    operationKey: string;\n    content: string;\n}\n\nconst DEFAULT_PLACEHOLDER_TEXT = \"...\";\n\n// =============================================================================\n// TYPE DEFINITIONS\n// =============================================================================\n// \n// These types define the public interface of the useChat hook, ensuring type\n// safety for all returned values and callbacks.\n\n/**\n * Return type for the useChat hook\n * \n * This interface defines all the values and functions that the hook exposes to\n * consuming components. Each property serves a specific purpose in the chat\n * interaction flow.\n */\nexport interface UseChatReturn {\n    /** Current input text in the chat field */\n    text: string;\n    /** Function to update the input text */\n    setText: (value: string) => void;\n    /** Array of all messages in the conversation */\n    messages: ModelMessage[];\n    /** Function to update the messages array */\n    setMessages: React.Dispatch<React.SetStateAction<ModelMessage[]>>;\n    /** Array of reasoning output aligned with messages */\n    thinkingOutput: string[];\n    /** Function to update the thinking output array */\n    setThinkingOutput: React.Dispatch<React.SetStateAction<string[]>>;\n    /** Whether the AI is currently streaming reasoning text */\n    isThinking: boolean;\n    /** Whether the AI is currently streaming a response */\n    isStreaming: boolean;\n    /** Current stream state for lifecycle tracking */\n    streamState: StreamState;\n    /** Send a message to the AI (optionally override current text) */\n    sendMessage: (overrideText?: string) => Promise<void>;\n    /** Cancel the current streaming response */\n    cancel: () => void;\n    /** Reset all chat state to initial values */\n    reset: () => void;\n    /** Current chat title (generated from conversation) */\n    title: string;\n    /** Function to update the chat title */\n    setTitle: (title: string) => void;\n    /** Generate a new title based on conversation content */\n    generateTitle: () => Promise<string>;\n    /** Currently active AI provider */\n    currentProvider: ProviderId;\n    /** Currently active model within the provider */\n    currentModel: string;\n    /** Whether we're currently using a fallback provider */\n    isUsingFallback: boolean;\n    /** Retry the last failed message */\n    retryLastMessage: () => Promise<void>;\n    /** Whether retry is available for the last message */\n    canRetry: boolean;\n    /** Error message for display when stream fails */\n    errorMessage: string | null;\n}\n\n// =============================================================================\n// MAIN HOOK IMPLEMENTATION\n// =============================================================================\n\n/**\n * Main useChat hook - orchestrates all chat functionality\n * \n * This hook serves as the central hub for chat operations, combining message\n * management, AI provider handling, streaming responses, and error recovery into\n * a cohesive interface.\n * \n * @param options - Configuration options for the chat instance\n * @returns Complete chat interface with state and actions\n */\nexport default function useChat(options: UseChatOptions = {}): UseChatReturn {\n    // =============================================================================\n    // OPTIONS DESTRUCTURING AND DEFAULTS\n    // =============================================================================\n    // \n    // Extract all options with sensible defaults. The hook is designed to work\n    // out-of-the-box with minimal configuration while allowing deep customization.\n    \n    const {\n        initialMessages = [],              // Start with empty message history\n        initialText = \"\",                  // Start with empty input field\n        placeholder = true,                // Enable placeholder for AI responses\n        providerId: legacyProviderId,      // Deprecated: use chatId instead\n        modelId: legacyModelId,           // Deprecated: use chatId instead\n        chatId,                           // Modern unified state management\n        model: providedModel,             // Direct model injection (testing)\n        onChunk,                          // Callback for streaming chunks\n        onThinkingChunk,                  // Callback for streaming thinking chunks\n        enableThinking = true,            // Enable thinking output updates\n        thinkingLevel,                    // Control reasoning effort when supported\n        onError,                          // Error handling callback\n        onComplete,                       // Completion callback\n        onFallback,                       // Provider fallback notification\n        enableFallback = true,            // Enable automatic fallback\n        enableRetry = true,               // Enable automatic retry\n        retryConfig = {},                 // Custom retry configuration\n    } = options;\n\n    // =============================================================================\n    // CHAT STATE MANAGEMENT\n    // =============================================================================\n    // \n    // Initialize chat state management. This handles both the new unified approach\n    // (using chatId) and legacy providerId/modelId for backward compatibility.\n    \n    const chatState = useChatState(chatId || null);\n    \n    // Resolve effective provider/model based on whether we're using unified state\n    // or legacy direct provider specification\n    const effectiveProviderId = chatId \n        ? chatState.provider                    // Use unified chat state\n        : (legacyProviderId || \"apple\");       // Fallback to legacy or default\n    const effectiveModelId = chatId \n        ? chatState.model                      // Use unified chat state  \n        : (legacyModelId || \"system-default\"); // Fallback to legacy or default\n\n    // =============================================================================\n    // CORE REACT STATE\n    // =============================================================================\n    // \n    // These are the fundamental React state variables that drive the chat interface.\n    // Each piece of state has a specific responsibility in the chat flow.\n    \n    const [text, setText] = useState<string>(initialText);           // Input field content\n    const [messages, setMessages] = useState<ModelMessage[]>(initialMessages); // Message history\n    const [thinkingOutput, setThinkingOutput] = useState<string[]>(\n        () => initialMessages.map(() => \"\")\n    );\n    const [isThinking, setIsThinking] = useState<boolean>(false);\n    const [isStreaming, setIsStreaming] = useState<boolean>(false);  // Streaming status\n    \n    // =============================================================================\n    // PROVIDER AND FALLBACK STATE\n    // =============================================================================\n    // \n    // These state variables manage the AI provider ecosystem, including fallback\n    // handling and provider switching during failures.\n    \n    const [activeProvider, setActiveProvider] = useState<ProviderId>(effectiveProviderId);\n    const [activeModel, setActiveModel] = useState<string>(effectiveModelId);\n    const [isUsingFallback, setIsUsingFallback] = useState<boolean>(false);\n    \n    // =============================================================================\n    // REFERENCES FOR STABLE OPERATIONS\n    // =============================================================================\n    // \n    // useRef values that persist across re-renders without triggering them.\n    // These are used for tracking operation state and maintaining data integrity.\n    \n    const failedProvidersRef = useRef<ProviderId[]>([]);     // Track failed providers for fallback\n    \n    // Retry and cancellation tracking\n    const lastUserMessageRef = useRef<string | null>(null); // Store last user message for retry\n    const [canRetry, setCanRetry] = useState<boolean>(false); // Whether retry is available\n    const [errorMessage, setErrorMessage] = useState<string | null>(null); // Error message for display\n    const canceledRef = useRef<boolean>(false);             // Track if streaming was canceled\n    const messagesRef = useRef<ModelMessage[]>(initialMessages);\n    const sendSequenceGuardRef = useRef(createSequenceGuard(`chat-send-${chatId ?? \"default\"}`));\n    const retryOperationRegistryRef = useRef(createIdempotencyRegistry<void>());\n    const lastRetryableOperationRef = useRef<RetryableOperation | null>(null);\n\n    useEffect(() => {\n        messagesRef.current = messages;\n    }, [messages]);\n\n    // =============================================================================\n    // CONFIGURATION MERGING\n    // =============================================================================\n    // \n    // Merge user-provided retry configuration with system defaults to create\n    // the final configuration used throughout the hook.\n    \n    const mergedRetryConfig: RetryConfig = { ...DEFAULT_RETRY_CONFIG, ...retryConfig };\n    const placeholderText = placeholder ? DEFAULT_PLACEHOLDER_TEXT : \"\";\n\n        // =============================================================================\n    // MODEL RESOLUTION AND CACHING\n    // =============================================================================\n    // \n    // Resolve the actual AI model to use for chat operations. This involves:\n    // 1. Using directly provided model (for testing/special cases)\n    // 2. Looking up cached model for performance\n    // 3. Creating new model instance if needed\n    // \n    // The useMemo ensures we only recompute when provider/model actually changes.\n    \n    const model: LanguageModel | null = useMemo(() => {\n        // Direct model injection takes precedence (useful for testing)\n        if (providedModel) {\n            return providedModel as LanguageModel;\n        }\n\n        // Try to get cached model for performance\n        const cachedModel = getCachedModel(\n            activeProvider,\n            activeModel,\n            () => getProviderModel(activeProvider, activeModel).model\n        );\n\n        return cachedModel || null;\n    }, [providedModel, activeProvider, activeModel]);\n\n    // =============================================================================\n    // TITLE GENERATION INTEGRATION\n    // =============================================================================\n    // \n    // Connect to the title generation subsystem. Titles are automatically\n    // generated based on conversation content and used for chat identification\n    // in the UI and database storage.\n    \n    const { title, setTitle, generateTitle } = useTitleGeneration(\n        messages.map(m => ({ role: m.role, content: typeof m.content === 'string' ? m.content : '' })),\n        model,\n        enableRetry,\n        mergedRetryConfig\n    );\n\n    // =============================================================================\n    // STREAMING INFRASTRUCTURE\n    // =============================================================================\n    // \n    // Connect to the streaming subsystem that handles real-time AI responses.\n    // This provides the core functionality for streaming text from AI providers.\n    \n    const { executeStreaming, handleStreamingError } = useChatStreaming();\n\n    // =============================================================================\n    // STREAM LIFECYCLE MANAGEMENT\n    // =============================================================================\n    // \n    // Manages stream state transitions, timeout detection, and cleanup.\n    // Ensures streams always complete fully and handles edge cases like\n    // app backgrounding and navigation away.\n    \n    const {\n        streamState,\n        isStreaming: isStreamLifecycleStreaming,\n        abortController,\n        initializeStream,\n        markChunkReceived,\n        markDoneSignalReceived,\n        markCompleting,\n        markCompleted,\n        markError,\n        cancelStream,\n    } = useStreamLifecycle({\n        timeoutMs: 30000, // 30 second fallback timeout\n        backgroundBehavior: \"cancel\",\n        enableLogging: __DEV__,\n        onError: (error) => {\n            console.error(\"[StreamLifecycle] Error:\", error.message);\n            onError?.(error);\n        },\n    });\n\n        // =============================================================================\n    // PROVIDER RESET EFFECT\n    // =============================================================================\n    // \n    // This effect ensures that when streaming completes (either successfully or\n    // with failure), we reset the provider state to the originally intended\n    // provider/model. This prevents fallback state from persisting between\n    // messages.\n    \n    useEffect(() => {\n        // Only reset when not actively streaming to avoid race conditions\n        if (!isStreaming) {\n            setActiveProvider(effectiveProviderId);\n            setActiveModel(effectiveModelId);\n            setIsUsingFallback(false);\n            failedProvidersRef.current = [];\n        }\n    }, [effectiveProviderId, effectiveModelId, isStreaming]);\n\n    // =============================================================================\n    // UTILITY FUNCTIONS\n    // =============================================================================\n    // \n    // Core utility functions that control chat state and flow. These are\n    // memoized with useCallback to maintain referential stability and prevent\n    // unnecessary re-renders in child components.\n\n    /**\n     * Reset all chat state to initial values\n     * \n     * This function completely clears the chat history, resets the input field,\n     * restores the original title, and resets all provider and fallback state.\n     * It's typically used when starting a new chat conversation.\n     */\n    const reset = useCallback(() => {\n        setText(\"\");                              // Clear input field\n        setMessages([]);                          // Clear message history\n        setThinkingOutput([]);                    // Clear reasoning output\n        setIsThinking(false);                     // Clear thinking state\n        setTitle(\"Chat\");                         // Reset to default title\n        setActiveProvider(effectiveProviderId);   // Reset to intended provider\n        setActiveModel(effectiveModelId);        // Reset to intended model\n        setIsUsingFallback(false);                // Clear fallback state\n        failedProvidersRef.current = [];         // Clear failed providers list\n        lastUserMessageRef.current = null;       // Clear retry message\n        setCanRetry(false);                      // Disable retry capability\n        setErrorMessage(null);                   // Clear error message\n        lastRetryableOperationRef.current = null;\n        retryOperationRegistryRef.current.clear();\n    }, [effectiveProviderId, effectiveModelId, setTitle]);\n\n    /**\n     * Cancel the current streaming operation\n     *\n     * Sets a flag that the streaming loop checks to determine if it should\n     * stop processing chunks. This provides a clean way to interrupt AI responses.\n     */\n    const cancel = useCallback(() => {\n        canceledRef.current = true;\n        sendSequenceGuardRef.current.next();\n        setIsStreaming(false);\n        setIsThinking(false);\n        cancelStream(); // Use stream lifecycle cancel for comprehensive cancellation\n    }, [cancelStream]);\n\n        // =============================================================================\n    // CORE MESSAGE SENDING LOGIC\n    // =============================================================================\n    // \n    // This is the heart of the chat functionality. The sendMessage function:\n    // 1. Validates and prepares the user message\n    // 2. Updates the message history\n    // 3. Initiates streaming with the AI provider\n    // 4. Handles fallback and retry logic\n    // 5. Manages the complete message flow lifecycle\n\n    /**\n     * Send a message to the AI and initiate streaming response\n     * \n     * @param overrideText - Optional text to send instead of current input\n     * \n     * This function orchestrates the complete message sending flow:\n     * 1. Input validation and preprocessing\n     * 2. Message history updates\n     * 3. AI provider streaming initiation\n     * 4. Error handling with fallback mechanisms\n     * 5. Completion callbacks\n     */\n    const sendMessage = useCallback(\n        async (overrideText?: string) => {\n            // ────────────────────────────────────────────────────────────────\n            // INPUT VALIDATION AND PREPARATION\n            // ────────────────────────────────────────────────────────────────\n            const rawValue: unknown = overrideText ?? (text as unknown);\n            const content = typeof rawValue === \"string\" ? rawValue.trim() : \"\";\n            \n            // Exit early if no valid content to send\n            if (!content) return;\n\n            const sendToken = sendSequenceGuardRef.current.next();\n            const sendOperationKey = createIdempotencyKey(\"chat-send\", [\n                chatId ?? \"default\",\n                sendToken.sequence,\n                content,\n            ]);\n\n            // ────────────────────────────────────────────────────────────────\n            // STATE INITIALIZATION\n            // ────────────────────────────────────────────────────────────────\n            setIsStreaming(true);                    // Start streaming state\n            setIsThinking(false);                    // Reset thinking state\n            canceledRef.current = false;            // Clear cancellation flag\n            setCanRetry(false);                     // Disable retry until needed\n            lastRetryableOperationRef.current = null;\n            lastUserMessageRef.current = content;   // Store for retry capability\n            \n            // Initialize stream lifecycle management\n            const streamController = initializeStream();\n            const abortSignal = streamController.signal;\n            const canMutateForCurrentSend = (): boolean => (\n                sendSequenceGuardRef.current.isCurrent(sendToken)\n                && !canceledRef.current\n                && !abortSignal.aborted\n            );\n\n            // ────────────────────────────────────────────────────────────────\n            // MESSAGE HISTORY MANAGEMENT\n            // ────────────────────────────────────────────────────────────────\n            const userMessage: ModelMessage = { role: \"user\", content };\n            const updatedMessages = [...messagesRef.current, userMessage];\n            setMessages(updatedMessages);\n            setThinkingOutput((prev) => [...prev, \"\"]);\n\n            // Clear input field if we're using the current text (not override)\n            if (overrideText === undefined) {\n                setText(\"\");\n            }\n\n            // Add placeholder for assistant response\n            const assistantIndex = updatedMessages.length;\n            setMessages((prev) => [\n                ...prev,\n                {\n                    role: \"assistant\",\n                    content: placeholderText,\n                },\n            ]);\n            setThinkingOutput((prev) => [...prev, \"\"]);\n\n            // ────────────────────────────────────────────────────────────────\n            // MODEL VALIDATION\n            // ────────────────────────────────────────────────────────────────\n            if (!model) {\n                // Show helpful error message when no provider is configured\n                setMessages((prev) => {\n                    const next = [...prev];\n                    next[assistantIndex] = {\n                        role: \"assistant\",\n                        content: \"**Setup Required**\\n\\nNo AI provider configured. Please set up a provider in settings.\\n\\n*Go to Settings to configure an AI provider.*\",\n                    };\n                    return next;\n                });\n                \n                onError?.(new Error(\"No AI provider configured\"));\n                setIsStreaming(false);\n                setIsThinking(false);\n                onComplete?.();\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // STREAMING CONFIGURATION\n            // ────────────────────────────────────────────────────────────────\n            const handleThinkingChunk = enableThinking\n                ? (chunk: string, accumulated: string) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    setIsThinking(true);\n                    setThinkingOutput((prev) => {\n                        const next = [...prev];\n                        next[assistantIndex] = accumulated;\n                        return next;\n                    });\n                    onThinkingChunk?.(chunk, accumulated);\n                }\n                : undefined;\n\n            const streamingOptions = {\n                model: {\n                    model,\n                    provider: activeProvider,\n                    modelId: activeModel,\n                    isOriginal: !isUsingFallback,\n                    attemptedProviders: failedProvidersRef.current,\n                } as FallbackResult,\n                enableRetry,\n                retryConfig: mergedRetryConfig,\n                enableFallback,\n                activeProvider,\n                effectiveProviderId,\n                thinkingLevel,\n                abortSignal,\n                onChunk,\n                onThinkingChunk: handleThinkingChunk,\n                canMutateState: canMutateForCurrentSend,\n                onError: (error: unknown) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    if (error instanceof Error) {\n                        markError(error);\n                        setErrorMessage(error.message);\n                        setCanRetry(true);\n                        lastRetryableOperationRef.current = {\n                            operationKey: sendOperationKey,\n                            content,\n                        };\n                        onError?.(error);\n                    } else {\n                        const wrappedError = new Error(String(error));\n                        markError(wrappedError);\n                        setErrorMessage(wrappedError.message);\n                        setCanRetry(true);\n                        lastRetryableOperationRef.current = {\n                            operationKey: sendOperationKey,\n                            content,\n                        };\n                        onError?.(wrappedError);\n                    }\n                },\n                onFallback,\n                onProviderChange: (provider: ProviderId, model: string, isFallback: boolean) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    setActiveProvider(provider);\n                    setActiveModel(model);\n                    setIsUsingFallback(isFallback);\n                },\n            };\n\n            // ────────────────────────────────────────────────────────────────\n            // STREAMING EXECUTION\n            // ────────────────────────────────────────────────────────────────\n            const result = await executeStreaming(\n                streamingOptions,\n                updatedMessages,\n                setMessages,\n                assistantIndex,\n                failedProvidersRef\n            );\n\n            if (!sendSequenceGuardRef.current.isCurrent(sendToken)) {\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // FALLBACK RETRY LOGIC\n            // ────────────────────────────────────────────────────────────────\n            if (result.shouldRetryWithFallback && !canceledRef.current) {\n                setIsStreaming(false);\n                setIsThinking(false);\n                // Small delay to ensure clean state transition\n                await new Promise(resolve => setTimeout(resolve, 100));\n                await sendMessage(content);\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // COMPLETION\n            // ────────────────────────────────────────────────────────────────\n            if (canMutateForCurrentSend()) {\n                setIsStreaming(false);\n                setIsThinking(false);\n                onComplete?.();\n            }\n        },\n        [\n            text, \n            placeholderText, \n            model, \n            activeProvider, \n            activeModel, \n            isUsingFallback,\n            enableRetry, \n            mergedRetryConfig,\n            executeStreaming,\n            onChunk, \n            onThinkingChunk,\n            onComplete, \n            onError, \n            onFallback,\n            chatId,\n            enableFallback,\n            effectiveProviderId,\n            initializeStream,\n            markError,\n            enableThinking,\n            thinkingLevel,\n            onThinkingChunk\n        ],\n    );\n\n        // =============================================================================\n    // RETRY FUNCTIONALITY\n    // =============================================================================\n    // \n    // Retry functionality allows users to resend their last message when the\n    // AI response failed or was incomplete. This involves:\n    // 1. Removing the failed assistant response\n    // 2. Optionally removing the user message (if they want to edit)\n    // 3. Resending the original message with fresh state\n\n    /**\n     * Retry the last failed message\n     * \n     * This function enables users to retry their last message when the AI\n     * response failed or was cut off. It cleans up the conversation history\n     * and resends the original message with fresh streaming state.\n     */\n    const retryLastMessage = useCallback(async () => {\n        const retryableOperation = lastRetryableOperationRef.current;\n\n        // Guard against invalid retry attempts\n        if (!lastUserMessageRef.current || !canRetry || !retryableOperation) return;\n\n        const retryOperationKey = createIdempotencyKey(\"chat-retry\", [\n            retryableOperation.operationKey,\n            retryableOperation.content,\n        ]);\n\n        await retryOperationRegistryRef.current.run(retryOperationKey, async () => {\n            const currentMessages = messagesRef.current;\n            let nextMessages = [...currentMessages];\n            let removedCount = 0;\n\n            if (nextMessages.length > 0 && nextMessages[nextMessages.length - 1].role === \"assistant\") {\n                nextMessages = nextMessages.slice(0, -1);\n                removedCount += 1;\n            }\n\n            const lastMessage = nextMessages[nextMessages.length - 1];\n            if (\n                lastMessage\n                && lastMessage.role === \"user\"\n                && typeof lastMessage.content === \"string\"\n                && lastMessage.content === retryableOperation.content\n            ) {\n                nextMessages = nextMessages.slice(0, -1);\n                removedCount += 1;\n            }\n\n            messagesRef.current = nextMessages;\n            setMessages(nextMessages);\n            setThinkingOutput((prev) => prev.slice(0, Math.max(0, prev.length - removedCount)));\n\n            // Reset retry state and clear error message\n            setCanRetry(false);\n            setErrorMessage(null);\n            lastRetryableOperationRef.current = null;\n\n            await sendMessage(retryableOperation.content);\n        });\n    }, [canRetry, sendMessage]);\n\n    // =============================================================================\n    // PUBLIC INTERFACE\n    // =============================================================================\n    // \n    // Return the complete chat interface. All values are stable references\n    // where appropriate to prevent unnecessary re-renders in consuming components.\n    // The interface provides both state accessors and action functions.\n\n    return {\n        // ────────────────────────────────────────────────────────────────\n        // CORE CHAT STATE\n        // ────────────────────────────────────────────────────────────────\n        text,                           // Current input text\n        setText,                        // Update input text\n        messages,                       // Message history\n        setMessages,                    // Update message history\n        thinkingOutput,                 // Reasoning output\n        setThinkingOutput,              // Update reasoning output\n        isThinking,                     // Thinking status\n        isStreaming,                    // Streaming status\n        streamState,                    // Stream lifecycle state (streaming | completing | completed | error)\n\n        // ────────────────────────────────────────────────────────────────\n        // ACTIONS\n        // ────────────────────────────────────────────────────────────────\n        sendMessage,                    // Send message\n        cancel,                         // Cancel streaming\n        reset,                          // Reset all state\n\n        // ────────────────────────────────────────────────────────────────\n        // TITLE MANAGEMENT\n        // ────────────────────────────────────────────────────────────────\n        title,                          // Current title\n        setTitle,                       // Update title\n        generateTitle,                  // Generate new title\n\n        // ────────────────────────────────────────────────────────────────\n        // PROVIDER STATE\n        // ────────────────────────────────────────────────────────────────\n        currentProvider: activeProvider, // Active AI provider\n        currentModel: activeModel,      // Active model\n        isUsingFallback,                // Fallback status\n\n        // ────────────────────────────────────────────────────────────────\n        // RETRY FUNCTIONALITY\n        // ────────────────────────────────────────────────────────────────\n        retryLastMessage,               // Retry last message\n        canRetry,                       // Whether retry is available\n        errorMessage,                   // Error message for display\n    };\n}\n\n/*\n * =============================================================================\n * HOOK COMPREHENSIVE DOCUMENTATION\n * =============================================================================\n * \n * ARCHITECTURAL SUMMARY:\n * ────────────────────────────────────────────────────────────────────────\n * useChat is a sophisticated hook that combines multiple concerns into a\n * cohesive chat interface. It follows the composition pattern, building upon\n * specialized hooks for different aspects of chat functionality.\n * \n * KEY PRINCIPLES:\n * ────────────────────────────────────────────────────────────────────────\n * 1. Separation of Concerns: Different aspects (streaming, title generation,\n *    state management) are handled by dedicated hooks\n * 2. Referential Stability: useCallback and useMemo prevent unnecessary re-renders\n * 3. Unidirectional Data Flow: State flows down, actions flow up\n * 4. Error Resilience: Multiple layers of error handling and fallback\n * 5. Performance Optimization: Caching, memoization, and efficient updates\n * \n * PROVIDER ECOSYSTEM INTEGRATION:\n * ────────────────────────────────────────────────────────────────────────\n * The hook integrates with a robust provider system that supports:\n * • Multiple AI providers (Apple, OpenAI, OpenRouter, Ollama)\n * • Automatic fallback on failures\n * • Model caching for performance\n * • Per-chat provider overrides\n * • Retry with exponential backoff\n * \n * STATE MANAGEMENT STRATEGY:\n * ────────────────────────────────────────────────────────────────────────\n * • Local React state for immediate UI updates\n * • Zustand stores for persistent data\n * • Refs for operation tracking without re-renders\n * • Unified chat state system for consistency\n * \n * ERROR HANDLING APPROACH:\n * ────────────────────────────────────────────────────────────────────────\n * • Graceful degradation when providers fail\n * • User-friendly error messages\n * • Automatic retry with configurable backoff\n * • Fallback chain through multiple providers\n * • Recovery mechanisms for common failure scenarios\n * \n * PERFORMANCE OPTIMIZATIONS:\n * ────────────────────────────────────────────────────────────────────────\n * • Model caching to avoid repeated initialization\n * • Memoized callbacks to prevent child re-renders\n * • Efficient state updates with minimal re-renders\n * • Lazy loading of provider resources\n * • Streaming to provide immediate feedback\n * \n * =============================================================================\n */\n","after":"/**\n * @file useChat.ts\n * @purpose Main chat orchestrator with comprehensive state management\n * @connects-to useChatStreaming, useTitleGeneration, useChatState\n * \n * =============================================================================\n * COMPREHENSIVE HOOK OVERVIEW\n * =============================================================================\n * \n * useChat is the central hook that manages all chat functionality in the seabreeze\n * application. It orchestrates message handling, streaming responses, provider\n * management, fallback mechanisms, title generation, and error recovery.\n * \n * KEY RESPONSIBILITIES:\n * ────────────────────────────────────────────────────────────────────────\n * • Message state management (input text, message history)\n * • Streaming response handling with real-time updates\n * • AI provider and model management with fallback support\n * • Error handling with automatic retry mechanisms\n * • Chat title generation based on conversation content\n * • Persistent chat state across app sessions\n * \n * ARCHITECTURAL PATTERNS:\n * ────────────────────────────────────────────────────────────────────────\n * • Composition over inheritance - combines specialized hooks\n * • Unidirectional data flow - state flows down, actions flow up\n * • Immutable state updates - ensures React re-renders correctly\n * • Referential stability - uses useCallback/useMemo for performance\n * \n * PROVIDER ECOSYSTEM:\n * ────────────────────────────────────────────────────────────────────────\n * Supports Apple Intelligence, OpenAI, OpenRouter, and Ollama providers with:\n * • Automatic fallback on failures\n * • Model caching for performance\n * • Per-chat provider overrides\n * • Retry with exponential backoff\n * \n * =============================================================================\n */\n\nimport { useCallback, useState, useRef, useEffect, useMemo } from \"react\";\nimport type { LanguageModel, ModelMessage } from \"ai\";\nimport { ProviderId } from \"@/types/provider.types\";\nimport { getProviderModel } from \"@/providers/provider-factory\";\nimport { getCachedModel } from \"@/providers/provider-cache\";\nimport { type FallbackResult } from \"@/providers/fallback-chain\";\nimport { executeWithRetry, DEFAULT_RETRY_CONFIG, type RetryConfig } from \"@/hooks/useErrorRecovery\";\nimport { useChatState } from \"@/hooks/useChatState\";\nimport { useTitleGeneration } from \"./useTitleGeneration\";\nimport { useChatStreaming } from \"./useChatStreaming\";\nimport { useStreamLifecycle } from \"./useStreamLifecycle\";\nimport type { UseChatOptions, StreamState } from \"@/types/chat.types\";\nimport {\n    createIdempotencyKey,\n    createIdempotencyRegistry,\n    createSequenceGuard,\n} from \"@/lib/concurrency\";\n\ntype ChunkHandler = (chunk: string, accumulated: string) => void;\n\ninterface RetryableOperation {\n    operationKey: string;\n    content: string;\n}\n\nconst DEFAULT_PLACEHOLDER_TEXT = \"...\";\n\n// =============================================================================\n// TYPE DEFINITIONS\n// =============================================================================\n// \n// These types define the public interface of the useChat hook, ensuring type\n// safety for all returned values and callbacks.\n\n/**\n * Return type for the useChat hook\n * \n * This interface defines all the values and functions that the hook exposes to\n * consuming components. Each property serves a specific purpose in the chat\n * interaction flow.\n */\nexport interface UseChatReturn {\n    /** Current input text in the chat field */\n    text: string;\n    /** Function to update the input text */\n    setText: (value: string) => void;\n    /** Array of all messages in the conversation */\n    messages: ModelMessage[];\n    /** Function to update the messages array */\n    setMessages: React.Dispatch<React.SetStateAction<ModelMessage[]>>;\n    /** Array of reasoning output aligned with messages */\n    thinkingOutput: string[];\n    /** Function to update the thinking output array */\n    setThinkingOutput: React.Dispatch<React.SetStateAction<string[]>>;\n    /** Whether the AI is currently streaming reasoning text */\n    isThinking: boolean;\n    /** Whether the AI is currently streaming a response */\n    isStreaming: boolean;\n    /** Current stream state for lifecycle tracking */\n    streamState: StreamState;\n    /** Send a message to the AI (optionally override current text) */\n    sendMessage: (overrideText?: string) => Promise<void>;\n    /** Cancel the current streaming response */\n    cancel: () => void;\n    /** Reset all chat state to initial values */\n    reset: () => void;\n    /** Current chat title (generated from conversation) */\n    title: string;\n    /** Function to update the chat title */\n    setTitle: (title: string) => void;\n    /** Generate a new title based on conversation content */\n    generateTitle: () => Promise<string>;\n    /** Currently active AI provider */\n    currentProvider: ProviderId;\n    /** Currently active model within the provider */\n    currentModel: string;\n    /** Whether we're currently using a fallback provider */\n    isUsingFallback: boolean;\n    /** Retry the last failed message */\n    retryLastMessage: () => Promise<void>;\n    /** Whether retry is available for the last message */\n    canRetry: boolean;\n    /** Error message for display when stream fails */\n    errorMessage: string | null;\n}\n\n// =============================================================================\n// MAIN HOOK IMPLEMENTATION\n// =============================================================================\n\n/**\n * Main useChat hook - orchestrates all chat functionality\n * \n * This hook serves as the central hub for chat operations, combining message\n * management, AI provider handling, streaming responses, and error recovery into\n * a cohesive interface.\n * \n * @param options - Configuration options for the chat instance\n * @returns Complete chat interface with state and actions\n */\nexport default function useChat(options: UseChatOptions = {}): UseChatReturn {\n    // =============================================================================\n    // OPTIONS DESTRUCTURING AND DEFAULTS\n    // =============================================================================\n    // \n    // Extract all options with sensible defaults. The hook is designed to work\n    // out-of-the-box with minimal configuration while allowing deep customization.\n    \n    const {\n        initialMessages = [],              // Start with empty message history\n        initialText = \"\",                  // Start with empty input field\n        placeholder = true,                // Enable placeholder for AI responses\n        providerId: legacyProviderId,      // Deprecated: use chatId instead\n        modelId: legacyModelId,           // Deprecated: use chatId instead\n        chatId,                           // Modern unified state management\n        model: providedModel,             // Direct model injection (testing)\n        onChunk,                          // Callback for streaming chunks\n        onThinkingChunk,                  // Callback for streaming thinking chunks\n        enableThinking = true,            // Enable thinking output updates\n        thinkingLevel,                    // Control reasoning effort when supported\n        onError,                          // Error handling callback\n        onComplete,                       // Completion callback\n        onFallback,                       // Provider fallback notification\n        enableFallback = true,            // Enable automatic fallback\n        enableRetry = true,               // Enable automatic retry\n        retryConfig = {},                 // Custom retry configuration\n    } = options;\n\n    // =============================================================================\n    // CHAT STATE MANAGEMENT\n    // =============================================================================\n    // \n    // Initialize chat state management. This handles both the new unified approach\n    // (using chatId) and legacy providerId/modelId for backward compatibility.\n    \n    const chatState = useChatState(chatId || null);\n    \n    // Resolve effective provider/model based on whether we're using unified state\n    // or legacy direct provider specification\n    const effectiveProviderId = chatId \n        ? chatState.provider                    // Use unified chat state\n        : (legacyProviderId || \"apple\");       // Fallback to legacy or default\n    const effectiveModelId = chatId \n        ? chatState.model                      // Use unified chat state  \n        : (legacyModelId || \"system-default\"); // Fallback to legacy or default\n\n    // =============================================================================\n    // CORE REACT STATE\n    // =============================================================================\n    // \n    // These are the fundamental React state variables that drive the chat interface.\n    // Each piece of state has a specific responsibility in the chat flow.\n    \n    const [text, setText] = useState<string>(initialText);           // Input field content\n    const [messages, setMessages] = useState<ModelMessage[]>(initialMessages); // Message history\n    const [thinkingOutput, setThinkingOutput] = useState<string[]>(\n        () => initialMessages.map(() => \"\")\n    );\n    const [isThinking, setIsThinking] = useState<boolean>(false);\n    const [isStreaming, setIsStreaming] = useState<boolean>(false);  // Streaming status\n    \n    // =============================================================================\n    // PROVIDER AND FALLBACK STATE\n    // =============================================================================\n    // \n    // These state variables manage the AI provider ecosystem, including fallback\n    // handling and provider switching during failures.\n    \n    const [activeProvider, setActiveProvider] = useState<ProviderId>(effectiveProviderId);\n    const [activeModel, setActiveModel] = useState<string>(effectiveModelId);\n    const [isUsingFallback, setIsUsingFallback] = useState<boolean>(false);\n    \n    // =============================================================================\n    // REFERENCES FOR STABLE OPERATIONS\n    // =============================================================================\n    // \n    // useRef values that persist across re-renders without triggering them.\n    // These are used for tracking operation state and maintaining data integrity.\n    \n    const failedProvidersRef = useRef<ProviderId[]>([]);     // Track failed providers for fallback\n    \n    // Retry and cancellation tracking\n    const lastUserMessageRef = useRef<string | null>(null); // Store last user message for retry\n    const [canRetry, setCanRetry] = useState<boolean>(false); // Whether retry is available\n    const [errorMessage, setErrorMessage] = useState<string | null>(null); // Error message for display\n    const canceledRef = useRef<boolean>(false);             // Track if streaming was canceled\n    const messagesRef = useRef<ModelMessage[]>(initialMessages);\n    const sendSequenceGuardRef = useRef(createSequenceGuard(`chat-send-${chatId ?? \"default\"}`));\n    const retryOperationRegistryRef = useRef(createIdempotencyRegistry<void>());\n    const lastRetryableOperationRef = useRef<RetryableOperation | null>(null);\n\n    useEffect(() => {\n        messagesRef.current = messages;\n    }, [messages]);\n\n    // =============================================================================\n    // CONFIGURATION MERGING\n    // =============================================================================\n    // \n    // Merge user-provided retry configuration with system defaults to create\n    // the final configuration used throughout the hook.\n    \n    const mergedRetryConfig: RetryConfig = { ...DEFAULT_RETRY_CONFIG, ...retryConfig };\n    const placeholderText = placeholder ? DEFAULT_PLACEHOLDER_TEXT : \"\";\n\n        // =============================================================================\n    // MODEL RESOLUTION AND CACHING\n    // =============================================================================\n    // \n    // Resolve the actual AI model to use for chat operations. This involves:\n    // 1. Using directly provided model (for testing/special cases)\n    // 2. Looking up cached model for performance\n    // 3. Creating new model instance if needed\n    // \n    // The useMemo ensures we only recompute when provider/model actually changes.\n    \n    const model: LanguageModel | null = useMemo(() => {\n        // Direct model injection takes precedence (useful for testing)\n        if (providedModel) {\n            return providedModel as LanguageModel;\n        }\n\n        // Try to get cached model for performance\n        const cachedModel = getCachedModel(\n            activeProvider,\n            activeModel,\n            () => getProviderModel(activeProvider, activeModel).model\n        );\n\n        return cachedModel || null;\n    }, [providedModel, activeProvider, activeModel]);\n\n    // =============================================================================\n    // TITLE GENERATION INTEGRATION\n    // =============================================================================\n    // \n    // Connect to the title generation subsystem. Titles are automatically\n    // generated based on conversation content and used for chat identification\n    // in the UI and database storage.\n    \n    const { title, setTitle, generateTitle } = useTitleGeneration(\n        messages.map(m => ({ role: m.role, content: typeof m.content === 'string' ? m.content : '' })),\n        model,\n        enableRetry,\n        mergedRetryConfig\n    );\n\n    // =============================================================================\n    // STREAMING INFRASTRUCTURE\n    // =============================================================================\n    // \n    // Connect to the streaming subsystem that handles real-time AI responses.\n    // This provides the core functionality for streaming text from AI providers.\n    \n    const { executeStreaming, handleStreamingError } = useChatStreaming();\n\n    // =============================================================================\n    // STREAM LIFECYCLE MANAGEMENT\n    // =============================================================================\n    // \n    // Manages stream state transitions, timeout detection, and cleanup.\n    // Ensures streams always complete fully and handles edge cases like\n    // app backgrounding and navigation away.\n    \n    const {\n        streamState,\n        isStreaming: isStreamLifecycleStreaming,\n        abortController,\n        initializeStream,\n        markChunkReceived,\n        markDoneSignalReceived,\n        markCompleting,\n        markCompleted,\n        markError,\n        cancelStream,\n    } = useStreamLifecycle({\n        timeoutMs: 30000, // 30 second fallback timeout\n        backgroundBehavior: \"cancel\",\n        enableLogging: __DEV__,\n        onError: (error) => {\n            console.error(\"[StreamLifecycle] Error:\", error.message);\n            onError?.(error);\n        },\n    });\n\n        // =============================================================================\n    // PROVIDER RESET EFFECT\n    // =============================================================================\n    // \n    // This effect ensures that when streaming completes (either successfully or\n    // with failure), we reset the provider state to the originally intended\n    // provider/model. This prevents fallback state from persisting between\n    // messages.\n    \n    useEffect(() => {\n        // Only reset when not actively streaming to avoid race conditions\n        if (!isStreaming) {\n            setActiveProvider(effectiveProviderId);\n            setActiveModel(effectiveModelId);\n            setIsUsingFallback(false);\n            failedProvidersRef.current = [];\n        }\n    }, [effectiveProviderId, effectiveModelId, isStreaming]);\n\n    // =============================================================================\n    // UTILITY FUNCTIONS\n    // =============================================================================\n    // \n    // Core utility functions that control chat state and flow. These are\n    // memoized with useCallback to maintain referential stability and prevent\n    // unnecessary re-renders in child components.\n\n    /**\n     * Reset all chat state to initial values\n     * \n     * This function completely clears the chat history, resets the input field,\n     * restores the original title, and resets all provider and fallback state.\n     * It's typically used when starting a new chat conversation.\n     */\n    const reset = useCallback(() => {\n        setText(\"\");                              // Clear input field\n        setMessages([]);                          // Clear message history\n        setThinkingOutput([]);                    // Clear reasoning output\n        setIsThinking(false);                     // Clear thinking state\n        setTitle(\"Chat\");                         // Reset to default title\n        setActiveProvider(effectiveProviderId);   // Reset to intended provider\n        setActiveModel(effectiveModelId);        // Reset to intended model\n        setIsUsingFallback(false);                // Clear fallback state\n        failedProvidersRef.current = [];         // Clear failed providers list\n        lastUserMessageRef.current = null;       // Clear retry message\n        setCanRetry(false);                      // Disable retry capability\n        setErrorMessage(null);                   // Clear error message\n        lastRetryableOperationRef.current = null;\n        retryOperationRegistryRef.current.clear();\n    }, [effectiveProviderId, effectiveModelId, setTitle]);\n\n    /**\n     * Cancel the current streaming operation\n     *\n     * Sets a flag that the streaming loop checks to determine if it should\n     * stop processing chunks. This provides a clean way to interrupt AI responses.\n     */\n    const cancel = useCallback(() => {\n        canceledRef.current = true;\n        sendSequenceGuardRef.current.next();\n        setIsStreaming(false);\n        setIsThinking(false);\n        cancelStream(); // Use stream lifecycle cancel for comprehensive cancellation\n    }, [cancelStream]);\n\n        // =============================================================================\n    // CORE MESSAGE SENDING LOGIC\n    // =============================================================================\n    // \n    // This is the heart of the chat functionality. The sendMessage function:\n    // 1. Validates and prepares the user message\n    // 2. Updates the message history\n    // 3. Initiates streaming with the AI provider\n    // 4. Handles fallback and retry logic\n    // 5. Manages the complete message flow lifecycle\n\n    /**\n     * Send a message to the AI and initiate streaming response\n     * \n     * @param overrideText - Optional text to send instead of current input\n     * \n     * This function orchestrates the complete message sending flow:\n     * 1. Input validation and preprocessing\n     * 2. Message history updates\n     * 3. AI provider streaming initiation\n     * 4. Error handling with fallback mechanisms\n     * 5. Completion callbacks\n     */\n    const sendMessage = useCallback(\n        async (overrideText?: string) => {\n            // ────────────────────────────────────────────────────────────────\n            // INPUT VALIDATION AND PREPARATION\n            // ────────────────────────────────────────────────────────────────\n            const rawValue: unknown = overrideText ?? (text as unknown);\n            const content = typeof rawValue === \"string\" ? rawValue.trim() : \"\";\n            \n            // Exit early if no valid content to send\n            if (!content) return;\n\n            const sendToken = sendSequenceGuardRef.current.next();\n            const sendOperationKey = createIdempotencyKey(\"chat-send\", [\n                chatId ?? \"default\",\n                sendToken.sequence,\n                content,\n            ]);\n\n            // ────────────────────────────────────────────────────────────────\n            // STATE INITIALIZATION\n            // ────────────────────────────────────────────────────────────────\n            setIsStreaming(true);                    // Start streaming state\n            setIsThinking(false);                    // Reset thinking state\n            canceledRef.current = false;            // Clear cancellation flag\n            setCanRetry(false);                     // Disable retry until needed\n            lastRetryableOperationRef.current = null;\n            lastUserMessageRef.current = content;   // Store for retry capability\n            \n            // Initialize stream lifecycle management\n            const streamController = initializeStream();\n            const abortSignal = streamController.signal;\n            const canMutateForCurrentSend = (): boolean => (\n                sendSequenceGuardRef.current.isCurrent(sendToken)\n                && !canceledRef.current\n                && !abortSignal.aborted\n            );\n\n            // ────────────────────────────────────────────────────────────────\n            // MESSAGE HISTORY MANAGEMENT\n            // ────────────────────────────────────────────────────────────────\n            const userMessage: ModelMessage = { role: \"user\", content };\n            const updatedMessages = [...messagesRef.current, userMessage];\n            setMessages(updatedMessages);\n            setThinkingOutput((prev) => [...prev, \"\"]);\n\n            // Clear input field if we're using the current text (not override)\n            if (overrideText === undefined) {\n                setText(\"\");\n            }\n\n            // Add placeholder for assistant response\n            const assistantIndex = updatedMessages.length;\n            setMessages((prev) => [\n                ...prev,\n                {\n                    role: \"assistant\",\n                    content: placeholderText,\n                },\n            ]);\n            setThinkingOutput((prev) => [...prev, \"\"]);\n\n            // ────────────────────────────────────────────────────────────────\n            // MODEL VALIDATION\n            // ────────────────────────────────────────────────────────────────\n            if (!model) {\n                // Show helpful error message when no provider is configured\n                setMessages((prev) => {\n                    const next = [...prev];\n                    next[assistantIndex] = {\n                        role: \"assistant\",\n                        content: \"**Setup Required**\\n\\nNo AI provider configured. Please set up a provider in settings.\\n\\n*Go to Settings to configure an AI provider.*\",\n                    };\n                    return next;\n                });\n                \n                onError?.(new Error(\"No AI provider configured\"));\n                setIsStreaming(false);\n                setIsThinking(false);\n                onComplete?.();\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // STREAMING CONFIGURATION\n            // ────────────────────────────────────────────────────────────────\n            const handleThinkingChunk = enableThinking\n                ? (chunk: string, accumulated: string) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    setIsThinking(true);\n                    setThinkingOutput((prev) => {\n                        const next = [...prev];\n                        next[assistantIndex] = accumulated;\n                        return next;\n                    });\n                    onThinkingChunk?.(chunk, accumulated);\n                }\n                : undefined;\n\n            const streamingOptions = {\n                model: {\n                    model,\n                    provider: activeProvider,\n                    modelId: activeModel,\n                    isOriginal: !isUsingFallback,\n                    attemptedProviders: failedProvidersRef.current,\n                } as FallbackResult,\n                enableRetry,\n                retryConfig: mergedRetryConfig,\n                enableFallback,\n                activeProvider,\n                effectiveProviderId,\n                thinkingLevel,\n                abortSignal,\n                onChunk,\n                onThinkingChunk: handleThinkingChunk,\n                canMutateState: canMutateForCurrentSend,\n                onError: (error: unknown) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    if (error instanceof Error) {\n                        markError(error);\n                        setErrorMessage(error.message);\n                        setCanRetry(true);\n                        lastRetryableOperationRef.current = {\n                            operationKey: sendOperationKey,\n                            content,\n                        };\n                        onError?.(error);\n                    } else {\n                        const wrappedError = new Error(String(error));\n                        markError(wrappedError);\n                        setErrorMessage(wrappedError.message);\n                        setCanRetry(true);\n                        lastRetryableOperationRef.current = {\n                            operationKey: sendOperationKey,\n                            content,\n                        };\n                        onError?.(wrappedError);\n                    }\n                },\n                onFallback,\n                onProviderChange: (provider: ProviderId, model: string, isFallback: boolean) => {\n                    if (!canMutateForCurrentSend()) {\n                        return;\n                    }\n\n                    setActiveProvider(provider);\n                    setActiveModel(model);\n                    setIsUsingFallback(isFallback);\n                },\n            };\n\n            // ────────────────────────────────────────────────────────────────\n            // STREAMING EXECUTION\n            // ────────────────────────────────────────────────────────────────\n            const result = await executeStreaming(\n                streamingOptions,\n                updatedMessages,\n                setMessages,\n                assistantIndex,\n                failedProvidersRef\n            );\n\n            if (!sendSequenceGuardRef.current.isCurrent(sendToken)) {\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // FALLBACK RETRY LOGIC\n            // ────────────────────────────────────────────────────────────────\n            if (result.shouldRetryWithFallback && !canceledRef.current) {\n                setIsStreaming(false);\n                setIsThinking(false);\n                // Small delay to ensure clean state transition\n                await new Promise(resolve => setTimeout(resolve, 100));\n                await sendMessage(content);\n                return;\n            }\n\n            // ────────────────────────────────────────────────────────────────\n            // COMPLETION\n            // ────────────────────────────────────────────────────────────────\n            if (canMutateForCurrentSend()) {\n                setIsStreaming(false);\n                setIsThinking(false);\n                onComplete?.();\n            }\n        },\n        [\n            text, \n            placeholderText, \n            model, \n            activeProvider, \n            activeModel, \n            isUsingFallback,\n            enableRetry, \n            mergedRetryConfig,\n            executeStreaming,\n            onChunk, \n            onComplete, \n            onError, \n            onFallback,\n            chatId,\n            enableFallback,\n            effectiveProviderId,\n            initializeStream,\n            markError,\n            enableThinking,\n            thinkingLevel,\n            onThinkingChunk\n        ],\n    );\n\n        // =============================================================================\n    // RETRY FUNCTIONALITY\n    // =============================================================================\n    // \n    // Retry functionality allows users to resend their last message when the\n    // AI response failed or was incomplete. This involves:\n    // 1. Removing the failed assistant response\n    // 2. Optionally removing the user message (if they want to edit)\n    // 3. Resending the original message with fresh state\n\n    /**\n     * Retry the last failed message\n     * \n     * This function enables users to retry their last message when the AI\n     * response failed or was cut off. It cleans up the conversation history\n     * and resends the original message with fresh streaming state.\n     */\n    const retryLastMessage = useCallback(async () => {\n        const retryableOperation = lastRetryableOperationRef.current;\n\n        // Guard against invalid retry attempts\n        if (!lastUserMessageRef.current || !canRetry || !retryableOperation) return;\n\n        const retryOperationKey = createIdempotencyKey(\"chat-retry\", [\n            retryableOperation.operationKey,\n            retryableOperation.content,\n        ]);\n\n        await retryOperationRegistryRef.current.run(retryOperationKey, async () => {\n            const currentMessages = messagesRef.current;\n            let nextMessages = [...currentMessages];\n            let removedCount = 0;\n\n            if (nextMessages.length > 0 && nextMessages[nextMessages.length - 1].role === \"assistant\") {\n                nextMessages = nextMessages.slice(0, -1);\n                removedCount += 1;\n            }\n\n            const lastMessage = nextMessages[nextMessages.length - 1];\n            if (\n                lastMessage\n                && lastMessage.role === \"user\"\n                && typeof lastMessage.content === \"string\"\n                && lastMessage.content === retryableOperation.content\n            ) {\n                nextMessages = nextMessages.slice(0, -1);\n                removedCount += 1;\n            }\n\n            messagesRef.current = nextMessages;\n            setMessages(nextMessages);\n            setThinkingOutput((prev) => prev.slice(0, Math.max(0, prev.length - removedCount)));\n\n            // Reset retry state and clear error message\n            setCanRetry(false);\n            setErrorMessage(null);\n            lastRetryableOperationRef.current = null;\n\n            await sendMessage(retryableOperation.content);\n        });\n    }, [canRetry, sendMessage]);\n\n    // =============================================================================\n    // PUBLIC INTERFACE\n    // =============================================================================\n    // \n    // Return the complete chat interface. All values are stable references\n    // where appropriate to prevent unnecessary re-renders in consuming components.\n    // The interface provides both state accessors and action functions.\n\n    return {\n        // ────────────────────────────────────────────────────────────────\n        // CORE CHAT STATE\n        // ────────────────────────────────────────────────────────────────\n        text,                           // Current input text\n        setText,                        // Update input text\n        messages,                       // Message history\n        setMessages,                    // Update message history\n        thinkingOutput,                 // Reasoning output\n        setThinkingOutput,              // Update reasoning output\n        isThinking,                     // Thinking status\n        isStreaming,                    // Streaming status\n        streamState,                    // Stream lifecycle state (streaming | completing | completed | error)\n\n        // ────────────────────────────────────────────────────────────────\n        // ACTIONS\n        // ────────────────────────────────────────────────────────────────\n        sendMessage,                    // Send message\n        cancel,                         // Cancel streaming\n        reset,                          // Reset all state\n\n        // ────────────────────────────────────────────────────────────────\n        // TITLE MANAGEMENT\n        // ────────────────────────────────────────────────────────────────\n        title,                          // Current title\n        setTitle,                       // Update title\n        generateTitle,                  // Generate new title\n\n        // ────────────────────────────────────────────────────────────────\n        // PROVIDER STATE\n        // ────────────────────────────────────────────────────────────────\n        currentProvider: activeProvider, // Active AI provider\n        currentModel: activeModel,      // Active model\n        isUsingFallback,                // Fallback status\n\n        // ────────────────────────────────────────────────────────────────\n        // RETRY FUNCTIONALITY\n        // ────────────────────────────────────────────────────────────────\n        retryLastMessage,               // Retry last message\n        canRetry,                       // Whether retry is available\n        errorMessage,                   // Error message for display\n    };\n}\n\n/*\n * =============================================================================\n * HOOK COMPREHENSIVE DOCUMENTATION\n * =============================================================================\n * \n * ARCHITECTURAL SUMMARY:\n * ────────────────────────────────────────────────────────────────────────\n * useChat is a sophisticated hook that combines multiple concerns into a\n * cohesive chat interface. It follows the composition pattern, building upon\n * specialized hooks for different aspects of chat functionality.\n * \n * KEY PRINCIPLES:\n * ────────────────────────────────────────────────────────────────────────\n * 1. Separation of Concerns: Different aspects (streaming, title generation,\n *    state management) are handled by dedicated hooks\n * 2. Referential Stability: useCallback and useMemo prevent unnecessary re-renders\n * 3. Unidirectional Data Flow: State flows down, actions flow up\n * 4. Error Resilience: Multiple layers of error handling and fallback\n * 5. Performance Optimization: Caching, memoization, and efficient updates\n * \n * PROVIDER ECOSYSTEM INTEGRATION:\n * ────────────────────────────────────────────────────────────────────────\n * The hook integrates with a robust provider system that supports:\n * • Multiple AI providers (Apple, OpenAI, OpenRouter, Ollama)\n * • Automatic fallback on failures\n * • Model caching for performance\n * • Per-chat provider overrides\n * • Retry with exponential backoff\n * \n * STATE MANAGEMENT STRATEGY:\n * ────────────────────────────────────────────────────────────────────────\n * • Local React state for immediate UI updates\n * • Zustand stores for persistent data\n * • Refs for operation tracking without re-renders\n * • Unified chat state system for consistency\n * \n * ERROR HANDLING APPROACH:\n * ────────────────────────────────────────────────────────────────────────\n * • Graceful degradation when providers fail\n * • User-friendly error messages\n * • Automatic retry with configurable backoff\n * • Fallback chain through multiple providers\n * • Recovery mechanisms for common failure scenarios\n * \n * PERFORMANCE OPTIMIZATIONS:\n * ────────────────────────────────────────────────────────────────────────\n * • Model caching to avoid repeated initialization\n * • Memoized callbacks to prevent child re-renders\n * • Efficient state updates with minimal re-renders\n * • Lazy loading of provider resources\n * • Streaming to provide immediate feedback\n * \n * =============================================================================\n */\n","additions":0,"deletions":1}],"diagnostics":{"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts":[{"range":{"start":{"line":46,"character":9},"end":{"line":46,"character":25}},"message":"'executeWithRetry' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":58,"character":5},"end":{"line":58,"character":17}},"message":"'ChunkHandler' is declared but never used.","severity":4,"code":6196,"source":"typescript"},{"range":{"start":{"line":152,"character":8},"end":{"line":152,"character":18}},"message":"'providerId' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/chat.types.ts","range":{"start":{"line":20,"character":6},"end":{"line":20,"character":66}}},"message":"The declaration was marked as deprecated here."}]},{"range":{"start":{"line":153,"character":8},"end":{"line":153,"character":15}},"message":"'modelId' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/chat.types.ts","range":{"start":{"line":22,"character":6},"end":{"line":22,"character":66}}},"message":"The declaration was marked as deprecated here."}]},{"range":{"start":{"line":294,"character":30},"end":{"line":294,"character":50}},"message":"'handleStreamingError' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":306,"character":21},"end":{"line":306,"character":47}},"message":"'isStreamLifecycleStreaming' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":307,"character":8},"end":{"line":307,"character":23}},"message":"'abortController' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":309,"character":8},"end":{"line":309,"character":25}},"message":"'markChunkReceived' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":310,"character":8},"end":{"line":310,"character":30}},"message":"'markDoneSignalReceived' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":311,"character":8},"end":{"line":311,"character":22}},"message":"'markCompleting' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":312,"character":8},"end":{"line":312,"character":21}},"message":"'markCompleted' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"}],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/types/concurrency.types.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/lib/concurrency.ts":[],"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChatStreaming.ts":[{"range":{"start":{"line":104,"character":26},"end":{"line":104,"character":39}},"message":"'LanguageModel' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":109,"character":9},"end":{"line":109,"character":29}},"message":"'getModelWithFallback' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":109,"character":71},"end":{"line":109,"character":91}},"message":"'hasFallbackAvailable' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":111,"character":51},"end":{"line":111,"character":66}},"message":"'shouldShowRetry' is declared but its value is never read.","severity":4,"code":6133,"source":"typescript"},{"range":{"start":{"line":246,"character":34},"end":{"line":246,"character":50}},"message":"'MutableRefObject' is deprecated.","severity":4,"code":6385,"source":"typescript","relatedInformation":[{"location":{"uri":"file:///Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/node_modules/%40types/react/index.d.ts","range":{"start":{"line":1658,"character":7},"end":{"line":1659,"character":5}}},"message":"The declaration was marked as deprecated here."}]}]},"truncated":false},"time":{"start":1770429144965,"end":1770429148000}},"metadata":{"openai":{"itemId":"fc_02d2ab3c7a8849c30169869ad7d9e481978c55ef16e1f478de"}}}}
{"type":"step_finish","timestamp":1770429148059,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cceb62001EDwtHvl8ocgLJk","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35ccd14c0016DmF3OceIXQ1YI","type":"step-finish","reason":"tool-calls","snapshot":"d71ed4098794c7ca8c32d5b684fa1b748c019a87","cost":0,"tokens":{"input":4973,"output":151,"reasoning":60,"cache":{"read":39424,"write":0}}}}
{"type":"step_start","timestamp":1770429148701,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35ccee1c001s5i3t84udRr575","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35ccebdc00171WBSlhABiQwuT","type":"step-start","snapshot":"d71ed4098794c7ca8c32d5b684fa1b748c019a87"}}
{"type":"tool_use","timestamp":1770429153035,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35ccf2a9001EVDjYpiXkx3O41","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35ccebdc00171WBSlhABiQwuT","type":"tool","callID":"call_zICTSjbLhx9uPxsQUzvSKlXo","tool":"bash","state":{"status":"completed","input":{"command":"npx eslint hooks/chat/useChat.ts hooks/chat/__tests__/useChat.test.ts","workdir":"/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2","description":"Confirm lint warnings after dependency cleanup"},"output":"\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n  332:38  warning  A `require()` style import is forbidden  @typescript-eslint/no-require-imports\n  344:38  warning  A `require()` style import is forbidden  @typescript-eslint/no-require-imports\n\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n   47:10  warning  'executeWithRetry' is defined but never used                                                                                                                                                           @typescript-eslint/no-unused-vars\n   59:6   warning  'ChunkHandler' is defined but never used                                                                                                                                                               @typescript-eslint/no-unused-vars\n  243:11  warning  The 'mergedRetryConfig' object makes the dependencies of useCallback Hook (at line 607) change on every render. To fix this, wrap the initialization of 'mergedRetryConfig' in its own useMemo() Hook  react-hooks/exhaustive-deps\n  295:31  warning  'handleStreamingError' is assigned a value but never used                                                                                                                                              @typescript-eslint/no-unused-vars\n  307:22  warning  'isStreamLifecycleStreaming' is assigned a value but never used                                                                                                                                        @typescript-eslint/no-unused-vars\n  308:9   warning  'abortController' is assigned a value but never used                                                                                                                                                   @typescript-eslint/no-unused-vars\n  310:9   warning  'markChunkReceived' is assigned a value but never used                                                                                                                                                 @typescript-eslint/no-unused-vars\n  311:9   warning  'markDoneSignalReceived' is assigned a value but never used                                                                                                                                            @typescript-eslint/no-unused-vars\n  312:9   warning  'markCompleting' is assigned a value but never used                                                                                                                                                    @typescript-eslint/no-unused-vars\n  313:9   warning  'markCompleted' is assigned a value but never used                                                                                                                                                     @typescript-eslint/no-unused-vars\n\n✖ 12 problems (0 errors, 12 warnings)\n\n","title":"Confirm lint warnings after dependency cleanup","metadata":{"output":"\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/__tests__/useChat.test.ts\n  332:38  warning  A `require()` style import is forbidden  @typescript-eslint/no-require-imports\n  344:38  warning  A `require()` style import is forbidden  @typescript-eslint/no-require-imports\n\n/Users/davidfanaro/Documents/CodingProjects/Seabreeze-v2/hooks/chat/useChat.ts\n   47:10  warning  'executeWithRetry' is defined but never used                                                                                                                                                           @typescript-eslint/no-unused-vars\n   59:6   warning  'ChunkHandler' is defined but never used                                                                                                                                                               @typescript-eslint/no-unused-vars\n  243:11  warning  The 'mergedRetryConfig' object makes the dependencies of useCallback Hook (at line 607) change on every render. To fix this, wrap the initialization of 'mergedRetryConfig' in its own useMemo() Hook  react-hooks/exhaustive-deps\n  295:31  warning  'handleStreamingError' is assigned a value but never used                                                                                                                                              @typescript-eslint/no-unused-vars\n  307:22  warning  'isStreamLifecycleStreaming' is assigned a value but never used                                                                                                                                        @typescript-eslint/no-unused-vars\n  308:9   warning  'abortController' is assigned a value but never used                                                                                                                                                   @typescript-eslint/no-unused-vars\n  310:9   warning  'markChunkReceived' is assigned a value but never used                                                                                                                                                 @typescript-eslint/no-unused-vars\n  311:9   warning  'markDoneSignalReceived' is assigned a value but never used                                                                                                                                            @typescript-eslint/no-unused-vars\n  312:9   warning  'markCompleting' is assigned a value but never used                                                                                                                                                    @typescript-eslint/no-unused-vars\n  313:9   warning  'markCompleted' is assigned a value but never used                                                                                                                                                     @typescript-eslint/no-unused-vars\n\n✖ 12 problems (0 errors, 12 warnings)\n\n","exit":0,"description":"Confirm lint warnings after dependency cleanup","truncated":false},"time":{"start":1770429150663,"end":1770429153034}},"metadata":{"openai":{"itemId":"fc_018b599efbbe0a0f0169869addd7848197ab5c29a827abf735"}}}}
{"type":"step_finish","timestamp":1770429153081,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35ccff0b001JTe8lvNZqFh1EQ","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35ccebdc00171WBSlhABiQwuT","type":"step-finish","reason":"tool-calls","snapshot":"d71ed4098794c7ca8c32d5b684fa1b748c019a87","cost":0,"tokens":{"input":1485,"output":98,"reasoning":33,"cache":{"read":43520,"write":0}}}}
{"type":"step_start","timestamp":1770429154027,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cd02eb001AQk1aqmQekpV7F","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35ccff79001zDdiBB49iMz6iJ","type":"step-start","snapshot":"d71ed4098794c7ca8c32d5b684fa1b748c019a87"}}
{"type":"tool_use","timestamp":1770429158486,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cd0cac001pDpoqdNwMY8CSn","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35ccff79001zDdiBB49iMz6iJ","type":"tool","callID":"call_3eoOOOj9tG5dVQtlRlLZa3K2","tool":"todowrite","state":{"status":"completed","input":{"todos":[{"id":"t1","content":"Review progress context and existing retry/send flow for idempotency gaps","status":"completed","priority":"high"},{"id":"t2","content":"Implement idempotent retry/re-send semantics and inflight protection","status":"completed","priority":"high"},{"id":"t3","content":"Add tests for repeated retries, quick taps, and network flap recovery","status":"completed","priority":"high"},{"id":"t4","content":"Run lint, typecheck, and test suite","status":"completed","priority":"high"},{"id":"t5","content":"Append US-004 update and learnings to .ralph-tui/progress.md","status":"completed","priority":"medium"}]},"output":"[\n  {\n    \"id\": \"t1\",\n    \"content\": \"Review progress context and existing retry/send flow for idempotency gaps\",\n    \"status\": \"completed\",\n    \"priority\": \"high\"\n  },\n  {\n    \"id\": \"t2\",\n    \"content\": \"Implement idempotent retry/re-send semantics and inflight protection\",\n    \"status\": \"completed\",\n    \"priority\": \"high\"\n  },\n  {\n    \"id\": \"t3\",\n    \"content\": \"Add tests for repeated retries, quick taps, and network flap recovery\",\n    \"status\": \"completed\",\n    \"priority\": \"high\"\n  },\n  {\n    \"id\": \"t4\",\n    \"content\": \"Run lint, typecheck, and test suite\",\n    \"status\": \"completed\",\n    \"priority\": \"high\"\n  },\n  {\n    \"id\": \"t5\",\n    \"content\": \"Append US-004 update and learnings to .ralph-tui/progress.md\",\n    \"status\": \"completed\",\n    \"priority\": \"medium\"\n  }\n]","title":"0 todos","metadata":{"todos":[{"id":"t1","content":"Review progress context and existing retry/send flow for idempotency gaps","status":"completed","priority":"high"},{"id":"t2","content":"Implement idempotent retry/re-send semantics and inflight protection","status":"completed","priority":"high"},{"id":"t3","content":"Add tests for repeated retries, quick taps, and network flap recovery","status":"completed","priority":"high"},{"id":"t4","content":"Run lint, typecheck, and test suite","status":"completed","priority":"high"},{"id":"t5","content":"Append US-004 update and learnings to .ralph-tui/progress.md","status":"completed","priority":"medium"}],"truncated":false},"time":{"start":1770429158483,"end":1770429158485}},"metadata":{"openai":{"itemId":"fc_0fa635f15605631f0169869ae46fc08194a6aa45e7f84eb7af"}}}}
{"type":"step_finish","timestamp":1770429158536,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cd1455001qDd355vvim35jP","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35ccff79001zDdiBB49iMz6iJ","type":"step-finish","reason":"tool-calls","snapshot":"d71ed4098794c7ca8c32d5b684fa1b748c019a87","cost":0,"tokens":{"input":1272,"output":268,"reasoning":102,"cache":{"read":44288,"write":0}}}}
{"type":"step_start","timestamp":1770429159249,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cd174f001xSrhRX7bPxyp0M","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cd14ca001AaNa1YNfDk6QSU","type":"step-start","snapshot":"d71ed4098794c7ca8c32d5b684fa1b748c019a87"}}
{"type":"text","timestamp":1770429169192,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cd2b86001jwWpIJ3u4gpFZo","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cd14ca001AaNa1YNfDk6QSU","type":"text","text":"Implemented idempotent retry/re-send handling so a single logical retry operation cannot create duplicate chat entries, even under rapid taps or overlapping retry attempts.\n\n- Added retry-operation identity + in-flight dedupe in `hooks/chat/useChat.ts`:\n  - track failure as a retryable logical operation key (`chat-send` key),\n  - execute retry through an idempotency registry (`chat-retry` key),\n  - collapse concurrent retry taps into one in-flight retry promise.\n- Hardened retry cleanup in `hooks/chat/useChat.ts:646` so failed tail entries are pruned deterministically before re-send:\n  - remove trailing failed assistant,\n  - remove trailing matching user message,\n  - trim `thinkingOutput` by the same removal count,\n  - clear retry metadata before re-sending.\n- Added US-004 coverage in `hooks/chat/__tests__/useChat.test.ts`:\n  - quick double-tap retry deduplication,\n  - retry press while prior retry is still in-flight,\n  - repeated network-flap failures followed by successful retry without duplicate rows.\n- Appended progress and learnings in `.ralph-tui/progress.md`, and added a reusable retry-idempotency pattern under `## Codebase Patterns`.\n\nValidation run:\n\n- `npx jest hooks/chat/__tests__/useChat.test.ts` passes (23/23).\n- `npm run lint` executed (no blocking lint errors surfaced).\n- `npx tsc --noEmit` fails due existing repo-wide baseline issues unrelated to US-004 (e.g. `app/index.tsx`, several legacy test typing files).\n- `npm test -- --watch=false` fails due existing unrelated suites (database name expectation mismatch, missing test IDs in settings/theme tests, gesture-handler runtime in `ChatListItem` tests).\n\nNo git commit was created.\n\n<promise>COMPLETE</promise>","time":{"start":1770429169191,"end":1770429169191},"metadata":{"openai":{"itemId":"msg_088950ff339985560169869aec4e4881968cddab24611dcb09"}}}}
{"type":"step_finish","timestamp":1770429169266,"sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","part":{"id":"prt_c35cd3e45001Gt7HytgeHvGlCd","sessionID":"ses_3ca3b479dffeWNTvAKs9SJ97HW","messageID":"msg_c35cd14ca001AaNa1YNfDk6QSU","type":"step-finish","reason":"stop","snapshot":"d71ed4098794c7ca8c32d5b684fa1b748c019a87","cost":0,"tokens":{"input":2547,"output":636,"reasoning":250,"cache":{"read":43520,"write":0}}}}
